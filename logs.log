2025-05-07 14:02:54,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-07 14:02:54,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-07 14:02:54,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-07 14:02:54,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-07 14:02:54,978:INFO:PyCaret RegressionExperiment
2025-05-07 14:02:54,989:INFO:Logging name: reg-default-name
2025-05-07 14:02:54,989:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-07 14:02:54,989:INFO:version 3.3.2
2025-05-07 14:02:54,990:INFO:Initializing setup()
2025-05-07 14:02:54,990:INFO:self.USI: cd08
2025-05-07 14:02:54,990:INFO:self._variable_keys: {'data', 'X_test', 'pipeline', 'n_jobs_param', 'gpu_param', 'exp_name_log', 'logging_param', '_ml_usecase', 'log_plots_param', 'USI', 'gpu_n_jobs_param', 'transform_target_param', 'y_test', 'y', 'fold_groups_param', 'target_param', 'exp_id', 'memory', 'fold_generator', 'y_train', 'html_param', 'idx', 'X', 'seed', 'X_train', 'fold_shuffle_param', '_available_plots'}
2025-05-07 14:02:54,990:INFO:Checking environment
2025-05-07 14:02:54,991:INFO:python_version: 3.11.7
2025-05-07 14:02:54,991:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2025-05-07 14:02:54,991:INFO:machine: AMD64
2025-05-07 14:02:54,991:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-07 14:02:54,999:INFO:Memory: svmem(total=34281660416, available=17016528896, percent=50.4, used=17265131520, free=17016528896)
2025-05-07 14:02:54,999:INFO:Physical Core: 8
2025-05-07 14:02:54,999:INFO:Logical Core: 16
2025-05-07 14:02:54,999:INFO:Checking libraries
2025-05-07 14:02:55,000:INFO:System:
2025-05-07 14:02:55,000:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2025-05-07 14:02:55,000:INFO:executable: c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Scripts\python.exe
2025-05-07 14:02:55,000:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-07 14:02:55,000:INFO:PyCaret required dependencies:
2025-05-07 14:02:55,056:INFO:                 pip: 23.2.1
2025-05-07 14:02:55,056:INFO:          setuptools: 65.5.0
2025-05-07 14:02:55,057:INFO:             pycaret: 3.3.2
2025-05-07 14:02:55,057:INFO:             IPython: 9.2.0
2025-05-07 14:02:55,057:INFO:          ipywidgets: 8.1.7
2025-05-07 14:02:55,057:INFO:                tqdm: 4.67.1
2025-05-07 14:02:55,058:INFO:               numpy: 1.26.4
2025-05-07 14:02:55,058:INFO:              pandas: 2.1.4
2025-05-07 14:02:55,058:INFO:              jinja2: 3.1.6
2025-05-07 14:02:55,058:INFO:               scipy: 1.11.4
2025-05-07 14:02:55,058:INFO:              joblib: 1.3.2
2025-05-07 14:02:55,058:INFO:             sklearn: 1.4.2
2025-05-07 14:02:55,059:INFO:                pyod: 2.0.5
2025-05-07 14:02:55,059:INFO:            imblearn: 0.13.0
2025-05-07 14:02:55,059:INFO:   category_encoders: 2.7.0
2025-05-07 14:02:55,059:INFO:            lightgbm: 4.6.0
2025-05-07 14:02:55,059:INFO:               numba: 0.61.2
2025-05-07 14:02:55,059:INFO:            requests: 2.32.3
2025-05-07 14:02:55,060:INFO:          matplotlib: 3.7.5
2025-05-07 14:02:55,060:INFO:          scikitplot: 0.3.7
2025-05-07 14:02:55,060:INFO:         yellowbrick: 1.5
2025-05-07 14:02:55,060:INFO:              plotly: 5.24.1
2025-05-07 14:02:55,060:INFO:    plotly-resampler: Not installed
2025-05-07 14:02:55,060:INFO:             kaleido: 0.2.1
2025-05-07 14:02:55,061:INFO:           schemdraw: 0.15
2025-05-07 14:02:55,061:INFO:         statsmodels: 0.14.4
2025-05-07 14:02:55,061:INFO:              sktime: 0.26.0
2025-05-07 14:02:55,061:INFO:               tbats: 1.1.3
2025-05-07 14:02:55,061:INFO:            pmdarima: 2.0.4
2025-05-07 14:02:55,062:INFO:              psutil: 7.0.0
2025-05-07 14:02:55,062:INFO:          markupsafe: 3.0.2
2025-05-07 14:02:55,062:INFO:             pickle5: Not installed
2025-05-07 14:02:55,062:INFO:         cloudpickle: 3.1.1
2025-05-07 14:02:55,062:INFO:         deprecation: 2.1.0
2025-05-07 14:02:55,062:INFO:              xxhash: 3.5.0
2025-05-07 14:02:55,063:INFO:           wurlitzer: Not installed
2025-05-07 14:02:55,063:INFO:PyCaret optional dependencies:
2025-05-07 14:02:55,081:INFO:                shap: Not installed
2025-05-07 14:02:55,081:INFO:           interpret: Not installed
2025-05-07 14:02:55,081:INFO:                umap: Not installed
2025-05-07 14:02:55,081:INFO:     ydata_profiling: Not installed
2025-05-07 14:02:55,083:INFO:  explainerdashboard: Not installed
2025-05-07 14:02:55,083:INFO:             autoviz: Not installed
2025-05-07 14:02:55,083:INFO:           fairlearn: Not installed
2025-05-07 14:02:55,083:INFO:          deepchecks: Not installed
2025-05-07 14:02:55,083:INFO:             xgboost: Not installed
2025-05-07 14:02:55,083:INFO:            catboost: Not installed
2025-05-07 14:02:55,083:INFO:              kmodes: Not installed
2025-05-07 14:02:55,084:INFO:             mlxtend: Not installed
2025-05-07 14:02:55,084:INFO:       statsforecast: Not installed
2025-05-07 14:02:55,084:INFO:        tune_sklearn: Not installed
2025-05-07 14:02:55,084:INFO:                 ray: Not installed
2025-05-07 14:02:55,084:INFO:            hyperopt: Not installed
2025-05-07 14:02:55,084:INFO:              optuna: Not installed
2025-05-07 14:02:55,084:INFO:               skopt: Not installed
2025-05-07 14:02:55,085:INFO:              mlflow: Not installed
2025-05-07 14:02:55,085:INFO:              gradio: Not installed
2025-05-07 14:02:55,085:INFO:             fastapi: Not installed
2025-05-07 14:02:55,085:INFO:             uvicorn: Not installed
2025-05-07 14:02:55,085:INFO:              m2cgen: Not installed
2025-05-07 14:02:55,085:INFO:           evidently: Not installed
2025-05-07 14:02:55,086:INFO:               fugue: Not installed
2025-05-07 14:02:55,086:INFO:           streamlit: Not installed
2025-05-07 14:02:55,086:INFO:             prophet: Not installed
2025-05-07 14:02:55,086:INFO:None
2025-05-07 14:02:55,086:INFO:Set up data.
2025-05-07 14:04:09,767:INFO:PyCaret RegressionExperiment
2025-05-07 14:04:09,791:INFO:Logging name: reg-default-name
2025-05-07 14:04:09,791:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-07 14:04:09,792:INFO:version 3.3.2
2025-05-07 14:04:09,792:INFO:Initializing setup()
2025-05-07 14:04:09,792:INFO:self.USI: 69c9
2025-05-07 14:04:09,792:INFO:self._variable_keys: {'data', 'X_test', 'pipeline', 'n_jobs_param', 'gpu_param', 'exp_name_log', 'logging_param', '_ml_usecase', 'log_plots_param', 'USI', 'gpu_n_jobs_param', 'transform_target_param', 'y_test', 'y', 'fold_groups_param', 'target_param', 'exp_id', 'memory', 'fold_generator', 'y_train', 'html_param', 'idx', 'X', 'seed', 'X_train', 'fold_shuffle_param', '_available_plots'}
2025-05-07 14:04:09,792:INFO:Checking environment
2025-05-07 14:04:09,793:INFO:python_version: 3.11.7
2025-05-07 14:04:09,793:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2025-05-07 14:04:09,793:INFO:machine: AMD64
2025-05-07 14:04:09,793:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-07 14:04:09,800:INFO:Memory: svmem(total=34281660416, available=17127817216, percent=50.0, used=17153843200, free=17127817216)
2025-05-07 14:04:09,801:INFO:Physical Core: 8
2025-05-07 14:04:09,801:INFO:Logical Core: 16
2025-05-07 14:04:09,801:INFO:Checking libraries
2025-05-07 14:04:09,801:INFO:System:
2025-05-07 14:04:09,801:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2025-05-07 14:04:09,801:INFO:executable: c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Scripts\python.exe
2025-05-07 14:04:09,802:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-07 14:04:09,802:INFO:PyCaret required dependencies:
2025-05-07 14:04:09,802:INFO:                 pip: 23.2.1
2025-05-07 14:04:09,802:INFO:          setuptools: 65.5.0
2025-05-07 14:04:09,802:INFO:             pycaret: 3.3.2
2025-05-07 14:04:09,803:INFO:             IPython: 9.2.0
2025-05-07 14:04:09,803:INFO:          ipywidgets: 8.1.7
2025-05-07 14:04:09,803:INFO:                tqdm: 4.67.1
2025-05-07 14:04:09,803:INFO:               numpy: 1.26.4
2025-05-07 14:04:09,803:INFO:              pandas: 2.1.4
2025-05-07 14:04:09,803:INFO:              jinja2: 3.1.6
2025-05-07 14:04:09,804:INFO:               scipy: 1.11.4
2025-05-07 14:04:09,804:INFO:              joblib: 1.3.2
2025-05-07 14:04:09,804:INFO:             sklearn: 1.4.2
2025-05-07 14:04:09,804:INFO:                pyod: 2.0.5
2025-05-07 14:04:09,804:INFO:            imblearn: 0.13.0
2025-05-07 14:04:09,804:INFO:   category_encoders: 2.7.0
2025-05-07 14:04:09,804:INFO:            lightgbm: 4.6.0
2025-05-07 14:04:09,805:INFO:               numba: 0.61.2
2025-05-07 14:04:09,805:INFO:            requests: 2.32.3
2025-05-07 14:04:09,805:INFO:          matplotlib: 3.7.5
2025-05-07 14:04:09,805:INFO:          scikitplot: 0.3.7
2025-05-07 14:04:09,805:INFO:         yellowbrick: 1.5
2025-05-07 14:04:09,806:INFO:              plotly: 5.24.1
2025-05-07 14:04:09,806:INFO:    plotly-resampler: Not installed
2025-05-07 14:04:09,806:INFO:             kaleido: 0.2.1
2025-05-07 14:04:09,806:INFO:           schemdraw: 0.15
2025-05-07 14:04:09,806:INFO:         statsmodels: 0.14.4
2025-05-07 14:04:09,806:INFO:              sktime: 0.26.0
2025-05-07 14:04:09,806:INFO:               tbats: 1.1.3
2025-05-07 14:04:09,807:INFO:            pmdarima: 2.0.4
2025-05-07 14:04:09,807:INFO:              psutil: 7.0.0
2025-05-07 14:04:09,807:INFO:          markupsafe: 3.0.2
2025-05-07 14:04:09,807:INFO:             pickle5: Not installed
2025-05-07 14:04:09,807:INFO:         cloudpickle: 3.1.1
2025-05-07 14:04:09,807:INFO:         deprecation: 2.1.0
2025-05-07 14:04:09,807:INFO:              xxhash: 3.5.0
2025-05-07 14:04:09,807:INFO:           wurlitzer: Not installed
2025-05-07 14:04:09,807:INFO:PyCaret optional dependencies:
2025-05-07 14:04:09,807:INFO:                shap: Not installed
2025-05-07 14:04:09,809:INFO:           interpret: Not installed
2025-05-07 14:04:09,809:INFO:                umap: Not installed
2025-05-07 14:04:09,809:INFO:     ydata_profiling: Not installed
2025-05-07 14:04:09,809:INFO:  explainerdashboard: Not installed
2025-05-07 14:04:09,809:INFO:             autoviz: Not installed
2025-05-07 14:04:09,809:INFO:           fairlearn: Not installed
2025-05-07 14:04:09,809:INFO:          deepchecks: Not installed
2025-05-07 14:04:09,809:INFO:             xgboost: Not installed
2025-05-07 14:04:09,809:INFO:            catboost: Not installed
2025-05-07 14:04:09,810:INFO:              kmodes: Not installed
2025-05-07 14:04:09,810:INFO:             mlxtend: Not installed
2025-05-07 14:04:09,810:INFO:       statsforecast: Not installed
2025-05-07 14:04:09,810:INFO:        tune_sklearn: Not installed
2025-05-07 14:04:09,810:INFO:                 ray: Not installed
2025-05-07 14:04:09,810:INFO:            hyperopt: Not installed
2025-05-07 14:04:09,811:INFO:              optuna: Not installed
2025-05-07 14:04:09,811:INFO:               skopt: Not installed
2025-05-07 14:04:09,811:INFO:              mlflow: Not installed
2025-05-07 14:04:09,811:INFO:              gradio: Not installed
2025-05-07 14:04:09,811:INFO:             fastapi: Not installed
2025-05-07 14:04:09,811:INFO:             uvicorn: Not installed
2025-05-07 14:04:09,812:INFO:              m2cgen: Not installed
2025-05-07 14:04:09,812:INFO:           evidently: Not installed
2025-05-07 14:04:09,812:INFO:               fugue: Not installed
2025-05-07 14:04:09,812:INFO:           streamlit: Not installed
2025-05-07 14:04:09,812:INFO:             prophet: Not installed
2025-05-07 14:04:09,812:INFO:None
2025-05-07 14:04:09,812:INFO:Set up data.
2025-05-07 14:04:09,840:INFO:Set up folding strategy.
2025-05-07 14:04:09,841:INFO:Set up train/test split.
2025-05-07 14:04:09,882:INFO:Set up index.
2025-05-07 14:04:09,884:INFO:Assigning column types.
2025-05-07 14:04:09,901:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-07 14:04:09,901:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-07 14:04:09,904:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-07 14:04:09,908:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-07 14:04:09,962:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-07 14:04:09,993:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-07 14:04:09,994:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:09,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:09,995:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-07 14:04:09,998:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,001:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,055:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,085:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,086:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,086:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-07 14:04:10,090:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,094:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,146:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,177:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,177:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,177:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,181:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,184:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,235:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,265:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,266:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,266:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,266:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-07 14:04:10,273:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,325:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,355:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,356:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,356:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,363:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,415:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,445:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,447:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-07 14:04:10,505:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,536:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,537:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,537:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,595:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,624:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,625:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,626:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-07 14:04:10,684:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,714:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,772:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-07 14:04:10,802:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,802:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,802:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-07 14:04:10,890:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,890:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,977:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:10,981:INFO:Preparing preprocessing pipeline...
2025-05-07 14:04:10,981:INFO:Set up simple imputation.
2025-05-07 14:04:10,992:INFO:Set up encoding of categorical features.
2025-05-07 14:04:11,226:INFO:Finished creating preprocessing pipeline.
2025-05-07 14:04:11,230:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LINW~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['postCode', 'habitableSurface',
                                             'buildingConstructionYear',
                                             'facedeCount', 'toiletCount',
                                             'bedroomCount_scaled',
                                             'bathroomCount_scaled'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['bu...
                                             'kitchenType', 'epcScore'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['buildingCondition',
                                             'floodZoneType', 'heatingType',
                                             'kitchenType', 'epcScore'],
                                    transformer=OneHotEncoder(cols=['buildingCondition',
                                                                    'floodZoneType',
                                                                    'heatingType',
                                                                    'kitchenType',
                                                                    'epcScore'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2025-05-07 14:04:11,230:INFO:Creating final display dataframe.
2025-05-07 14:04:11,711:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             price
2                   Target type        Regression
3           Original data shape       (62099, 26)
4        Transformed data shape       (62099, 61)
5   Transformed train set shape       (43469, 61)
6    Transformed test set shape       (18630, 61)
7              Numeric features                 7
8          Categorical features                 5
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              69c9
2025-05-07 14:04:11,807:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:11,807:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:11,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:11,896:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 14:04:11,896:INFO:setup() successfully completed in 2.13s...............
2025-05-07 14:04:39,060:INFO:Initializing compare_models()
2025-05-07 14:04:39,060:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-07 14:04:39,061:INFO:Checking exceptions
2025-05-07 14:04:39,069:INFO:Preparing display monitor
2025-05-07 14:04:39,088:INFO:Initializing Linear Regression
2025-05-07 14:04:39,088:INFO:Total runtime is 2.5065739949544272e-05 minutes
2025-05-07 14:04:39,091:INFO:SubProcess create_model() called ==================================
2025-05-07 14:04:39,091:INFO:Initializing create_model()
2025-05-07 14:04:39,091:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002421863B490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 14:04:39,093:INFO:Checking exceptions
2025-05-07 14:04:39,093:INFO:Importing libraries
2025-05-07 14:04:39,093:INFO:Copying training dataset
2025-05-07 14:04:39,121:INFO:Defining folds
2025-05-07 14:04:39,121:INFO:Declaring metric variables
2025-05-07 14:04:39,126:INFO:Importing untrained model
2025-05-07 14:04:39,129:INFO:Linear Regression Imported successfully
2025-05-07 14:04:39,133:INFO:Starting cross validation
2025-05-07 14:04:39,139:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 14:04:44,134:INFO:Calculating mean and std
2025-05-07 14:04:44,137:INFO:Creating metrics dataframe
2025-05-07 14:04:44,140:INFO:Uploading results into container
2025-05-07 14:04:44,143:INFO:Uploading model into container now
2025-05-07 14:04:44,144:INFO:_master_model_container: 1
2025-05-07 14:04:44,145:INFO:_display_container: 2
2025-05-07 14:04:44,145:INFO:LinearRegression(n_jobs=-1)
2025-05-07 14:04:44,145:INFO:create_model() successfully completed......................................
2025-05-07 14:04:44,312:INFO:SubProcess create_model() end ==================================
2025-05-07 14:04:44,312:INFO:Creating metrics dataframe
2025-05-07 14:04:44,317:INFO:Initializing Lasso Regression
2025-05-07 14:04:44,317:INFO:Total runtime is 0.08716172377268475 minutes
2025-05-07 14:04:44,319:INFO:SubProcess create_model() called ==================================
2025-05-07 14:04:44,319:INFO:Initializing create_model()
2025-05-07 14:04:44,320:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002421863B490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 14:04:44,320:INFO:Checking exceptions
2025-05-07 14:04:44,320:INFO:Importing libraries
2025-05-07 14:04:44,320:INFO:Copying training dataset
2025-05-07 14:04:44,346:INFO:Defining folds
2025-05-07 14:04:44,346:INFO:Declaring metric variables
2025-05-07 14:04:44,349:INFO:Importing untrained model
2025-05-07 14:04:44,352:INFO:Lasso Regression Imported successfully
2025-05-07 14:04:44,357:INFO:Starting cross validation
2025-05-07 14:04:44,359:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 14:04:52,005:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.847e+15, tolerance: 9.820e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-07 14:04:52,277:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.813e+15, tolerance: 9.796e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-07 14:04:52,310:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.838e+15, tolerance: 9.959e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-07 14:04:52,797:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.820e+15, tolerance: 9.769e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-07 14:04:59,916:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.833e+15, tolerance: 9.867e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-07 14:05:00,362:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.826e+15, tolerance: 9.979e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-07 14:05:00,509:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.887e+15, tolerance: 9.937e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-07 14:05:00,581:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.821e+15, tolerance: 9.869e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-07 14:05:00,597:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.899e+15, tolerance: 1.006e+12
  model = cd_fast.enet_coordinate_descent(

2025-05-07 14:05:00,625:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.760e+15, tolerance: 9.682e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-07 14:05:00,678:INFO:Calculating mean and std
2025-05-07 14:05:00,678:INFO:Creating metrics dataframe
2025-05-07 14:05:00,680:INFO:Uploading results into container
2025-05-07 14:05:00,681:INFO:Uploading model into container now
2025-05-07 14:05:00,681:INFO:_master_model_container: 2
2025-05-07 14:05:00,682:INFO:_display_container: 2
2025-05-07 14:05:00,682:INFO:Lasso(random_state=123)
2025-05-07 14:05:00,682:INFO:create_model() successfully completed......................................
2025-05-07 14:05:00,783:INFO:SubProcess create_model() end ==================================
2025-05-07 14:05:00,783:INFO:Creating metrics dataframe
2025-05-07 14:05:00,789:INFO:Initializing Ridge Regression
2025-05-07 14:05:00,789:INFO:Total runtime is 0.3617083152135213 minutes
2025-05-07 14:05:00,792:INFO:SubProcess create_model() called ==================================
2025-05-07 14:05:00,792:INFO:Initializing create_model()
2025-05-07 14:05:00,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002421863B490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 14:05:00,793:INFO:Checking exceptions
2025-05-07 14:05:00,793:INFO:Importing libraries
2025-05-07 14:05:00,793:INFO:Copying training dataset
2025-05-07 14:05:00,830:INFO:Defining folds
2025-05-07 14:05:00,831:INFO:Declaring metric variables
2025-05-07 14:05:00,836:INFO:Importing untrained model
2025-05-07 14:05:00,845:INFO:Ridge Regression Imported successfully
2025-05-07 14:05:00,854:INFO:Starting cross validation
2025-05-07 14:05:00,857:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 14:05:02,079:INFO:Calculating mean and std
2025-05-07 14:05:02,081:INFO:Creating metrics dataframe
2025-05-07 14:05:02,083:INFO:Uploading results into container
2025-05-07 14:05:02,084:INFO:Uploading model into container now
2025-05-07 14:05:02,084:INFO:_master_model_container: 3
2025-05-07 14:05:02,085:INFO:_display_container: 2
2025-05-07 14:05:02,086:INFO:Ridge(random_state=123)
2025-05-07 14:05:02,086:INFO:create_model() successfully completed......................................
2025-05-07 14:05:02,212:INFO:SubProcess create_model() end ==================================
2025-05-07 14:05:02,212:INFO:Creating metrics dataframe
2025-05-07 14:05:02,218:INFO:Initializing Elastic Net
2025-05-07 14:05:02,219:INFO:Total runtime is 0.3855297287305196 minutes
2025-05-07 14:05:02,223:INFO:SubProcess create_model() called ==================================
2025-05-07 14:05:02,223:INFO:Initializing create_model()
2025-05-07 14:05:02,223:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002421863B490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 14:05:02,223:INFO:Checking exceptions
2025-05-07 14:05:02,224:INFO:Importing libraries
2025-05-07 14:05:02,224:INFO:Copying training dataset
2025-05-07 14:05:02,264:INFO:Defining folds
2025-05-07 14:05:02,265:INFO:Declaring metric variables
2025-05-07 14:05:02,271:INFO:Importing untrained model
2025-05-07 14:05:02,275:INFO:Elastic Net Imported successfully
2025-05-07 14:05:02,283:INFO:Starting cross validation
2025-05-07 14:05:02,285:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 14:05:04,117:INFO:Calculating mean and std
2025-05-07 14:05:04,118:INFO:Creating metrics dataframe
2025-05-07 14:05:04,120:INFO:Uploading results into container
2025-05-07 14:05:04,121:INFO:Uploading model into container now
2025-05-07 14:05:04,121:INFO:_master_model_container: 4
2025-05-07 14:05:04,121:INFO:_display_container: 2
2025-05-07 14:05:04,122:INFO:ElasticNet(random_state=123)
2025-05-07 14:05:04,122:INFO:create_model() successfully completed......................................
2025-05-07 14:05:04,260:INFO:SubProcess create_model() end ==================================
2025-05-07 14:05:04,260:INFO:Creating metrics dataframe
2025-05-07 14:05:04,266:INFO:Initializing Least Angle Regression
2025-05-07 14:05:04,266:INFO:Total runtime is 0.419659157594045 minutes
2025-05-07 14:05:04,271:INFO:SubProcess create_model() called ==================================
2025-05-07 14:05:04,271:INFO:Initializing create_model()
2025-05-07 14:05:04,272:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002421863B490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 14:05:04,272:INFO:Checking exceptions
2025-05-07 14:05:04,272:INFO:Importing libraries
2025-05-07 14:05:04,272:INFO:Copying training dataset
2025-05-07 14:05:04,312:INFO:Defining folds
2025-05-07 14:05:04,312:INFO:Declaring metric variables
2025-05-07 14:05:04,316:INFO:Importing untrained model
2025-05-07 14:05:04,319:INFO:Least Angle Regression Imported successfully
2025-05-07 14:05:04,327:INFO:Starting cross validation
2025-05-07 14:05:04,329:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 14:05:05,234:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=5.614e+02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,243:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=4.296e+02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,246:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=2.859e+02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,248:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=2.096e+02, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,249:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.451e+02, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,250:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=1.424e+02, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,253:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=1.291e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,254:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=1.461e+02, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,257:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=5.995e+01, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,296:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=1.439e+04, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,304:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=1.035e+04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,338:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=7.673e+02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,345:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=8.488e+02, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,362:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=6.032e+03, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,373:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=4.328e+03, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,389:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=4.144e+03, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,390:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=4.011e+03, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,396:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=1.410e+03, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,417:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=4.009e+02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,419:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=5.539e+02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,422:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=4.723e+02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,424:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=5.302e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,426:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=6.481e+02, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,427:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=3.896e+02, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,428:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=2.089e+02, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 14:05:05,505:INFO:Calculating mean and std
2025-05-07 14:05:05,506:INFO:Creating metrics dataframe
2025-05-07 14:05:05,508:INFO:Uploading results into container
2025-05-07 14:05:05,509:INFO:Uploading model into container now
2025-05-07 14:05:05,509:INFO:_master_model_container: 5
2025-05-07 14:05:05,509:INFO:_display_container: 2
2025-05-07 14:05:05,510:INFO:Lars(random_state=123)
2025-05-07 14:05:05,510:INFO:create_model() successfully completed......................................
2025-05-07 14:05:05,651:INFO:SubProcess create_model() end ==================================
2025-05-07 14:05:05,651:INFO:Creating metrics dataframe
2025-05-07 14:05:05,659:INFO:Initializing Lasso Least Angle Regression
2025-05-07 14:05:05,659:INFO:Total runtime is 0.4428718566894531 minutes
2025-05-07 14:05:05,663:INFO:SubProcess create_model() called ==================================
2025-05-07 14:05:05,663:INFO:Initializing create_model()
2025-05-07 14:05:05,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002421863B490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 14:05:05,664:INFO:Checking exceptions
2025-05-07 14:05:05,664:INFO:Importing libraries
2025-05-07 14:05:05,664:INFO:Copying training dataset
2025-05-07 14:05:05,702:INFO:Defining folds
2025-05-07 14:05:05,703:INFO:Declaring metric variables
2025-05-07 14:05:05,708:INFO:Importing untrained model
2025-05-07 14:05:05,713:INFO:Lasso Least Angle Regression Imported successfully
2025-05-07 14:05:05,721:INFO:Starting cross validation
2025-05-07 14:05:05,724:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 14:05:06,959:INFO:Calculating mean and std
2025-05-07 14:05:06,963:INFO:Creating metrics dataframe
2025-05-07 14:05:06,967:INFO:Uploading results into container
2025-05-07 14:05:06,968:INFO:Uploading model into container now
2025-05-07 14:05:06,969:INFO:_master_model_container: 6
2025-05-07 14:05:06,970:INFO:_display_container: 2
2025-05-07 14:05:06,971:INFO:LassoLars(random_state=123)
2025-05-07 14:05:06,972:INFO:create_model() successfully completed......................................
2025-05-07 14:05:07,092:INFO:SubProcess create_model() end ==================================
2025-05-07 14:05:07,093:INFO:Creating metrics dataframe
2025-05-07 14:05:07,100:INFO:Initializing Orthogonal Matching Pursuit
2025-05-07 14:05:07,100:INFO:Total runtime is 0.46688962777455645 minutes
2025-05-07 14:05:07,104:INFO:SubProcess create_model() called ==================================
2025-05-07 14:05:07,104:INFO:Initializing create_model()
2025-05-07 14:05:07,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002421863B490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 14:05:07,104:INFO:Checking exceptions
2025-05-07 14:05:07,106:INFO:Importing libraries
2025-05-07 14:05:07,106:INFO:Copying training dataset
2025-05-07 14:05:07,142:INFO:Defining folds
2025-05-07 14:05:07,142:INFO:Declaring metric variables
2025-05-07 14:05:07,146:INFO:Importing untrained model
2025-05-07 14:05:07,150:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-07 14:05:07,158:INFO:Starting cross validation
2025-05-07 14:05:07,159:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 14:05:08,309:INFO:Calculating mean and std
2025-05-07 14:05:08,312:INFO:Creating metrics dataframe
2025-05-07 14:05:08,317:INFO:Uploading results into container
2025-05-07 14:05:08,317:INFO:Uploading model into container now
2025-05-07 14:05:08,318:INFO:_master_model_container: 7
2025-05-07 14:05:08,319:INFO:_display_container: 2
2025-05-07 14:05:08,320:INFO:OrthogonalMatchingPursuit()
2025-05-07 14:05:08,320:INFO:create_model() successfully completed......................................
2025-05-07 14:05:08,422:INFO:SubProcess create_model() end ==================================
2025-05-07 14:05:08,423:INFO:Creating metrics dataframe
2025-05-07 14:05:08,428:INFO:Initializing Bayesian Ridge
2025-05-07 14:05:08,428:INFO:Total runtime is 0.48902333577473955 minutes
2025-05-07 14:05:08,431:INFO:SubProcess create_model() called ==================================
2025-05-07 14:05:08,432:INFO:Initializing create_model()
2025-05-07 14:05:08,432:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002421863B490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 14:05:08,432:INFO:Checking exceptions
2025-05-07 14:05:08,432:INFO:Importing libraries
2025-05-07 14:05:08,433:INFO:Copying training dataset
2025-05-07 14:05:08,465:INFO:Defining folds
2025-05-07 14:05:08,465:INFO:Declaring metric variables
2025-05-07 14:05:08,470:INFO:Importing untrained model
2025-05-07 14:05:08,474:INFO:Bayesian Ridge Imported successfully
2025-05-07 14:05:08,480:INFO:Starting cross validation
2025-05-07 14:05:08,482:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 14:05:10,855:INFO:Calculating mean and std
2025-05-07 14:05:10,856:INFO:Creating metrics dataframe
2025-05-07 14:05:10,857:INFO:Uploading results into container
2025-05-07 14:05:10,858:INFO:Uploading model into container now
2025-05-07 14:05:10,859:INFO:_master_model_container: 8
2025-05-07 14:05:10,859:INFO:_display_container: 2
2025-05-07 14:05:10,859:INFO:BayesianRidge()
2025-05-07 14:05:10,859:INFO:create_model() successfully completed......................................
2025-05-07 14:05:10,968:INFO:SubProcess create_model() end ==================================
2025-05-07 14:05:10,969:INFO:Creating metrics dataframe
2025-05-07 14:05:10,975:INFO:Initializing Passive Aggressive Regressor
2025-05-07 14:05:10,976:INFO:Total runtime is 0.5314633170763651 minutes
2025-05-07 14:05:10,979:INFO:SubProcess create_model() called ==================================
2025-05-07 14:05:10,980:INFO:Initializing create_model()
2025-05-07 14:05:10,980:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002421863B490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 14:05:10,980:INFO:Checking exceptions
2025-05-07 14:05:10,980:INFO:Importing libraries
2025-05-07 14:05:10,980:INFO:Copying training dataset
2025-05-07 14:05:11,020:INFO:Defining folds
2025-05-07 14:05:11,020:INFO:Declaring metric variables
2025-05-07 14:05:11,025:INFO:Importing untrained model
2025-05-07 14:05:11,030:INFO:Passive Aggressive Regressor Imported successfully
2025-05-07 14:05:11,036:INFO:Starting cross validation
2025-05-07 14:05:11,039:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 14:05:12,632:INFO:Calculating mean and std
2025-05-07 14:05:12,633:INFO:Creating metrics dataframe
2025-05-07 14:05:12,635:INFO:Uploading results into container
2025-05-07 14:05:12,635:INFO:Uploading model into container now
2025-05-07 14:05:12,635:INFO:_master_model_container: 9
2025-05-07 14:05:12,636:INFO:_display_container: 2
2025-05-07 14:05:12,636:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-07 14:05:12,636:INFO:create_model() successfully completed......................................
2025-05-07 14:05:12,731:INFO:SubProcess create_model() end ==================================
2025-05-07 14:05:12,732:INFO:Creating metrics dataframe
2025-05-07 14:05:12,737:INFO:Initializing Huber Regressor
2025-05-07 14:05:12,737:INFO:Total runtime is 0.5608370701471964 minutes
2025-05-07 14:05:12,741:INFO:SubProcess create_model() called ==================================
2025-05-07 14:05:12,742:INFO:Initializing create_model()
2025-05-07 14:05:12,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002421863B490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 14:05:12,742:INFO:Checking exceptions
2025-05-07 14:05:12,742:INFO:Importing libraries
2025-05-07 14:05:12,743:INFO:Copying training dataset
2025-05-07 14:05:12,774:INFO:Defining folds
2025-05-07 14:05:12,774:INFO:Declaring metric variables
2025-05-07 14:05:12,779:INFO:Importing untrained model
2025-05-07 14:05:12,782:INFO:Huber Regressor Imported successfully
2025-05-07 14:05:12,787:INFO:Starting cross validation
2025-05-07 14:05:12,790:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 14:05:20,811:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-05-07 14:05:20,911:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-05-07 14:05:20,938:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-05-07 14:05:21,033:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-05-07 14:05:21,053:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-05-07 14:05:21,115:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-05-07 14:05:21,251:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-05-07 14:05:21,376:INFO:Calculating mean and std
2025-05-07 14:05:21,378:INFO:Creating metrics dataframe
2025-05-07 14:05:21,379:INFO:Uploading results into container
2025-05-07 14:05:21,380:INFO:Uploading model into container now
2025-05-07 14:05:21,380:INFO:_master_model_container: 10
2025-05-07 14:05:21,381:INFO:_display_container: 2
2025-05-07 14:05:21,381:INFO:HuberRegressor()
2025-05-07 14:05:21,381:INFO:create_model() successfully completed......................................
2025-05-07 14:05:21,473:INFO:SubProcess create_model() end ==================================
2025-05-07 14:05:21,473:INFO:Creating metrics dataframe
2025-05-07 14:05:21,480:INFO:Initializing K Neighbors Regressor
2025-05-07 14:05:21,480:INFO:Total runtime is 0.7065468907356262 minutes
2025-05-07 14:05:21,483:INFO:SubProcess create_model() called ==================================
2025-05-07 14:05:21,484:INFO:Initializing create_model()
2025-05-07 14:05:21,484:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002421863B490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 14:05:21,484:INFO:Checking exceptions
2025-05-07 14:05:21,484:INFO:Importing libraries
2025-05-07 14:05:21,484:INFO:Copying training dataset
2025-05-07 14:05:21,515:INFO:Defining folds
2025-05-07 14:05:21,515:INFO:Declaring metric variables
2025-05-07 14:05:21,519:INFO:Importing untrained model
2025-05-07 14:05:21,523:INFO:K Neighbors Regressor Imported successfully
2025-05-07 14:05:21,530:INFO:Starting cross validation
2025-05-07 14:05:21,533:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 14:05:23,993:INFO:Calculating mean and std
2025-05-07 14:05:23,995:INFO:Creating metrics dataframe
2025-05-07 14:05:23,996:INFO:Uploading results into container
2025-05-07 14:05:23,997:INFO:Uploading model into container now
2025-05-07 14:05:23,997:INFO:_master_model_container: 11
2025-05-07 14:05:23,998:INFO:_display_container: 2
2025-05-07 14:05:23,998:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-07 14:05:23,998:INFO:create_model() successfully completed......................................
2025-05-07 14:05:24,099:INFO:SubProcess create_model() end ==================================
2025-05-07 14:05:24,099:INFO:Creating metrics dataframe
2025-05-07 14:05:24,105:INFO:Initializing Decision Tree Regressor
2025-05-07 14:05:24,105:INFO:Total runtime is 0.7503100752830505 minutes
2025-05-07 14:05:24,110:INFO:SubProcess create_model() called ==================================
2025-05-07 14:05:24,110:INFO:Initializing create_model()
2025-05-07 14:05:24,110:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002421863B490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 14:05:24,111:INFO:Checking exceptions
2025-05-07 14:05:24,111:INFO:Importing libraries
2025-05-07 14:05:24,111:INFO:Copying training dataset
2025-05-07 14:05:24,141:INFO:Defining folds
2025-05-07 14:05:24,141:INFO:Declaring metric variables
2025-05-07 14:05:24,145:INFO:Importing untrained model
2025-05-07 14:05:24,148:INFO:Decision Tree Regressor Imported successfully
2025-05-07 14:05:24,155:INFO:Starting cross validation
2025-05-07 14:05:24,156:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 14:05:25,719:INFO:Calculating mean and std
2025-05-07 14:05:25,720:INFO:Creating metrics dataframe
2025-05-07 14:05:25,722:INFO:Uploading results into container
2025-05-07 14:05:25,723:INFO:Uploading model into container now
2025-05-07 14:05:25,724:INFO:_master_model_container: 12
2025-05-07 14:05:25,724:INFO:_display_container: 2
2025-05-07 14:05:25,724:INFO:DecisionTreeRegressor(random_state=123)
2025-05-07 14:05:25,724:INFO:create_model() successfully completed......................................
2025-05-07 14:05:25,830:INFO:SubProcess create_model() end ==================================
2025-05-07 14:05:25,831:INFO:Creating metrics dataframe
2025-05-07 14:05:25,839:INFO:Initializing Random Forest Regressor
2025-05-07 14:05:25,840:INFO:Total runtime is 0.7792148152987162 minutes
2025-05-07 14:05:25,843:INFO:SubProcess create_model() called ==================================
2025-05-07 14:05:25,843:INFO:Initializing create_model()
2025-05-07 14:05:25,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002421863B490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 14:05:25,844:INFO:Checking exceptions
2025-05-07 14:05:25,844:INFO:Importing libraries
2025-05-07 14:05:25,844:INFO:Copying training dataset
2025-05-07 14:05:25,876:INFO:Defining folds
2025-05-07 14:05:25,877:INFO:Declaring metric variables
2025-05-07 14:05:25,880:INFO:Importing untrained model
2025-05-07 14:05:25,884:INFO:Random Forest Regressor Imported successfully
2025-05-07 14:05:25,889:INFO:Starting cross validation
2025-05-07 14:05:25,891:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 14:05:51,062:INFO:Calculating mean and std
2025-05-07 14:05:51,063:INFO:Creating metrics dataframe
2025-05-07 14:05:51,065:INFO:Uploading results into container
2025-05-07 14:05:51,066:INFO:Uploading model into container now
2025-05-07 14:05:51,066:INFO:_master_model_container: 13
2025-05-07 14:05:51,066:INFO:_display_container: 2
2025-05-07 14:05:51,067:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-07 14:05:51,067:INFO:create_model() successfully completed......................................
2025-05-07 14:05:51,197:INFO:SubProcess create_model() end ==================================
2025-05-07 14:05:51,199:INFO:Creating metrics dataframe
2025-05-07 14:05:51,206:INFO:Initializing Extra Trees Regressor
2025-05-07 14:05:51,206:INFO:Total runtime is 1.2019835789998372 minutes
2025-05-07 14:05:51,209:INFO:SubProcess create_model() called ==================================
2025-05-07 14:05:51,210:INFO:Initializing create_model()
2025-05-07 14:05:51,210:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002421863B490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 14:05:51,210:INFO:Checking exceptions
2025-05-07 14:05:51,210:INFO:Importing libraries
2025-05-07 14:05:51,211:INFO:Copying training dataset
2025-05-07 14:05:51,246:INFO:Defining folds
2025-05-07 14:05:51,246:INFO:Declaring metric variables
2025-05-07 14:05:51,249:INFO:Importing untrained model
2025-05-07 14:05:51,253:INFO:Extra Trees Regressor Imported successfully
2025-05-07 14:05:51,260:INFO:Starting cross validation
2025-05-07 14:05:51,262:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 14:06:22,460:INFO:Calculating mean and std
2025-05-07 14:06:22,461:INFO:Creating metrics dataframe
2025-05-07 14:06:22,463:INFO:Uploading results into container
2025-05-07 14:06:22,464:INFO:Uploading model into container now
2025-05-07 14:06:22,464:INFO:_master_model_container: 14
2025-05-07 14:06:22,464:INFO:_display_container: 2
2025-05-07 14:06:22,465:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-07 14:06:22,465:INFO:create_model() successfully completed......................................
2025-05-07 14:06:22,581:INFO:SubProcess create_model() end ==================================
2025-05-07 14:06:22,581:INFO:Creating metrics dataframe
2025-05-07 14:06:22,589:INFO:Initializing AdaBoost Regressor
2025-05-07 14:06:22,589:INFO:Total runtime is 1.7250390887260436 minutes
2025-05-07 14:06:22,593:INFO:SubProcess create_model() called ==================================
2025-05-07 14:06:22,594:INFO:Initializing create_model()
2025-05-07 14:06:22,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002421863B490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 14:06:22,594:INFO:Checking exceptions
2025-05-07 14:06:22,594:INFO:Importing libraries
2025-05-07 14:06:22,595:INFO:Copying training dataset
2025-05-07 14:06:22,624:INFO:Defining folds
2025-05-07 14:06:22,624:INFO:Declaring metric variables
2025-05-07 14:06:22,627:INFO:Importing untrained model
2025-05-07 14:06:22,631:INFO:AdaBoost Regressor Imported successfully
2025-05-07 14:06:22,637:INFO:Starting cross validation
2025-05-07 14:06:22,639:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 14:06:34,656:INFO:Calculating mean and std
2025-05-07 14:06:34,657:INFO:Creating metrics dataframe
2025-05-07 14:06:34,658:INFO:Uploading results into container
2025-05-07 14:06:34,659:INFO:Uploading model into container now
2025-05-07 14:06:34,660:INFO:_master_model_container: 15
2025-05-07 14:06:34,660:INFO:_display_container: 2
2025-05-07 14:06:34,660:INFO:AdaBoostRegressor(random_state=123)
2025-05-07 14:06:34,660:INFO:create_model() successfully completed......................................
2025-05-07 14:06:34,759:INFO:SubProcess create_model() end ==================================
2025-05-07 14:06:34,759:INFO:Creating metrics dataframe
2025-05-07 14:06:34,765:INFO:Initializing Gradient Boosting Regressor
2025-05-07 14:06:34,766:INFO:Total runtime is 1.9279864112536111 minutes
2025-05-07 14:06:34,769:INFO:SubProcess create_model() called ==================================
2025-05-07 14:06:34,769:INFO:Initializing create_model()
2025-05-07 14:06:34,770:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002421863B490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 14:06:34,770:INFO:Checking exceptions
2025-05-07 14:06:34,770:INFO:Importing libraries
2025-05-07 14:06:34,770:INFO:Copying training dataset
2025-05-07 14:06:34,796:INFO:Defining folds
2025-05-07 14:06:34,796:INFO:Declaring metric variables
2025-05-07 14:06:34,799:INFO:Importing untrained model
2025-05-07 14:06:34,802:INFO:Gradient Boosting Regressor Imported successfully
2025-05-07 14:06:34,808:INFO:Starting cross validation
2025-05-07 14:06:34,810:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 14:06:41,465:INFO:Calculating mean and std
2025-05-07 14:06:41,467:INFO:Creating metrics dataframe
2025-05-07 14:06:41,468:INFO:Uploading results into container
2025-05-07 14:06:41,469:INFO:Uploading model into container now
2025-05-07 14:06:41,469:INFO:_master_model_container: 16
2025-05-07 14:06:41,469:INFO:_display_container: 2
2025-05-07 14:06:41,469:INFO:GradientBoostingRegressor(random_state=123)
2025-05-07 14:06:41,470:INFO:create_model() successfully completed......................................
2025-05-07 14:06:41,568:INFO:SubProcess create_model() end ==================================
2025-05-07 14:06:41,568:INFO:Creating metrics dataframe
2025-05-07 14:06:41,576:INFO:Initializing Light Gradient Boosting Machine
2025-05-07 14:06:41,576:INFO:Total runtime is 2.0414808909098308 minutes
2025-05-07 14:06:41,579:INFO:SubProcess create_model() called ==================================
2025-05-07 14:06:41,579:INFO:Initializing create_model()
2025-05-07 14:06:41,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002421863B490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 14:06:41,580:INFO:Checking exceptions
2025-05-07 14:06:41,580:INFO:Importing libraries
2025-05-07 14:06:41,580:INFO:Copying training dataset
2025-05-07 14:06:41,612:INFO:Defining folds
2025-05-07 14:06:41,612:INFO:Declaring metric variables
2025-05-07 14:06:41,614:INFO:Importing untrained model
2025-05-07 14:06:41,618:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-07 14:06:41,623:INFO:Starting cross validation
2025-05-07 14:06:41,624:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 14:06:43,941:INFO:Calculating mean and std
2025-05-07 14:06:43,942:INFO:Creating metrics dataframe
2025-05-07 14:06:43,944:INFO:Uploading results into container
2025-05-07 14:06:43,945:INFO:Uploading model into container now
2025-05-07 14:06:43,945:INFO:_master_model_container: 17
2025-05-07 14:06:43,945:INFO:_display_container: 2
2025-05-07 14:06:43,946:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-07 14:06:43,946:INFO:create_model() successfully completed......................................
2025-05-07 14:06:44,063:INFO:SubProcess create_model() end ==================================
2025-05-07 14:06:44,065:INFO:Creating metrics dataframe
2025-05-07 14:06:44,071:INFO:Initializing Dummy Regressor
2025-05-07 14:06:44,072:INFO:Total runtime is 2.0830913265546163 minutes
2025-05-07 14:06:44,075:INFO:SubProcess create_model() called ==================================
2025-05-07 14:06:44,075:INFO:Initializing create_model()
2025-05-07 14:06:44,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002421863B490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 14:06:44,076:INFO:Checking exceptions
2025-05-07 14:06:44,076:INFO:Importing libraries
2025-05-07 14:06:44,076:INFO:Copying training dataset
2025-05-07 14:06:44,101:INFO:Defining folds
2025-05-07 14:06:44,102:INFO:Declaring metric variables
2025-05-07 14:06:44,105:INFO:Importing untrained model
2025-05-07 14:06:44,116:INFO:Dummy Regressor Imported successfully
2025-05-07 14:06:44,130:INFO:Starting cross validation
2025-05-07 14:06:44,135:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 14:06:45,103:INFO:Calculating mean and std
2025-05-07 14:06:45,106:INFO:Creating metrics dataframe
2025-05-07 14:06:45,107:INFO:Uploading results into container
2025-05-07 14:06:45,108:INFO:Uploading model into container now
2025-05-07 14:06:45,108:INFO:_master_model_container: 18
2025-05-07 14:06:45,108:INFO:_display_container: 2
2025-05-07 14:06:45,109:INFO:DummyRegressor()
2025-05-07 14:06:45,109:INFO:create_model() successfully completed......................................
2025-05-07 14:06:45,280:INFO:SubProcess create_model() end ==================================
2025-05-07 14:06:45,280:INFO:Creating metrics dataframe
2025-05-07 14:06:45,290:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-07 14:06:45,297:INFO:Initializing create_model()
2025-05-07 14:06:45,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 14:06:45,297:INFO:Checking exceptions
2025-05-07 14:06:45,299:INFO:Importing libraries
2025-05-07 14:06:45,299:INFO:Copying training dataset
2025-05-07 14:06:45,326:INFO:Defining folds
2025-05-07 14:06:45,327:INFO:Declaring metric variables
2025-05-07 14:06:45,327:INFO:Importing untrained model
2025-05-07 14:06:45,327:INFO:Declaring custom model
2025-05-07 14:06:45,328:INFO:Random Forest Regressor Imported successfully
2025-05-07 14:06:45,329:INFO:Cross validation set to False
2025-05-07 14:06:45,329:INFO:Fitting Model
2025-05-07 14:06:48,112:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-07 14:06:48,113:INFO:create_model() successfully completed......................................
2025-05-07 14:06:48,224:INFO:_master_model_container: 18
2025-05-07 14:06:48,224:INFO:_display_container: 2
2025-05-07 14:06:48,224:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-07 14:06:48,224:INFO:compare_models() successfully completed......................................
2025-05-07 14:09:55,835:INFO:Initializing evaluate_model()
2025-05-07 14:09:55,835:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-07 14:09:55,852:INFO:Initializing plot_model()
2025-05-07 14:09:55,852:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-07 14:09:55,852:INFO:Checking exceptions
2025-05-07 14:09:55,890:INFO:Preloading libraries
2025-05-07 14:09:56,142:INFO:Copying training dataset
2025-05-07 14:09:56,143:INFO:Plot type: pipeline
2025-05-07 14:09:56,348:INFO:Visual Rendered Successfully
2025-05-07 14:09:56,448:INFO:plot_model() successfully completed......................................
2025-05-07 14:10:14,366:INFO:Initializing evaluate_model()
2025-05-07 14:10:14,366:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-07 14:10:14,384:INFO:Initializing plot_model()
2025-05-07 14:10:14,384:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-07 14:10:14,384:INFO:Checking exceptions
2025-05-07 14:10:14,423:INFO:Preloading libraries
2025-05-07 14:10:14,662:INFO:Copying training dataset
2025-05-07 14:10:14,663:INFO:Plot type: pipeline
2025-05-07 14:10:14,721:INFO:Visual Rendered Successfully
2025-05-07 14:10:14,823:INFO:plot_model() successfully completed......................................
2025-05-07 14:10:47,040:INFO:Initializing plot_model()
2025-05-07 14:10:47,041:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), plot=residuals, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-07 14:10:47,041:INFO:Checking exceptions
2025-05-07 14:10:47,083:INFO:Preloading libraries
2025-05-07 14:10:47,329:INFO:Copying training dataset
2025-05-07 14:10:47,330:INFO:Plot type: residuals
2025-05-07 14:10:47,687:INFO:Fitting Model
2025-05-07 14:10:47,688:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2025-05-07 14:10:48,041:INFO:Scoring test/hold-out set
2025-05-07 14:10:48,832:INFO:Visual Rendered Successfully
2025-05-07 14:10:48,940:INFO:plot_model() successfully completed......................................
2025-05-07 14:10:52,153:INFO:Initializing plot_model()
2025-05-07 14:10:52,153:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), plot=learning, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-07 14:10:52,153:INFO:Checking exceptions
2025-05-07 14:10:52,195:INFO:Preloading libraries
2025-05-07 14:10:52,441:INFO:Copying training dataset
2025-05-07 14:10:52,442:INFO:Plot type: learning
2025-05-07 14:10:52,787:INFO:Fitting Model
2025-05-07 14:13:32,744:INFO:Initializing plot_model()
2025-05-07 14:13:32,744:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), plot=error, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-07 14:13:32,745:INFO:Checking exceptions
2025-05-07 14:13:32,787:INFO:Preloading libraries
2025-05-07 14:13:33,039:INFO:Copying training dataset
2025-05-07 14:13:33,040:INFO:Plot type: error
2025-05-07 14:13:33,476:INFO:Fitting Model
2025-05-07 14:13:33,477:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2025-05-07 14:13:33,477:INFO:Scoring test/hold-out set
2025-05-07 14:13:33,877:INFO:Visual Rendered Successfully
2025-05-07 14:13:34,007:INFO:plot_model() successfully completed......................................
2025-05-07 14:13:52,300:INFO:Initializing predict_model()
2025-05-07 14:13:52,300:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002427310AE90>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000242731E8B80>)
2025-05-07 14:13:52,300:INFO:Checking exceptions
2025-05-07 14:13:52,301:INFO:Preloading libraries
2025-05-07 14:13:52,659:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-07 14:16:50,476:INFO:Initializing save_model()
2025-05-07 14:16:50,477:INFO:save_model(model=RandomForestRegressor(n_jobs=-1, random_state=123), model_name=random_forest_regressor_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\LINW~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['postCode', 'habitableSurface',
                                             'buildingConstructionYear',
                                             'facedeCount', 'toiletCount',
                                             'bedroomCount_scaled',
                                             'bathroomCount_scaled'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['bu...
                                             'kitchenType', 'epcScore'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['buildingCondition',
                                             'floodZoneType', 'heatingType',
                                             'kitchenType', 'epcScore'],
                                    transformer=OneHotEncoder(cols=['buildingCondition',
                                                                    'floodZoneType',
                                                                    'heatingType',
                                                                    'kitchenType',
                                                                    'epcScore'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-05-07 14:16:50,477:INFO:Adding model into prep_pipe
2025-05-07 14:16:51,017:INFO:random_forest_regressor_pipeline.pkl saved in current working directory
2025-05-07 14:16:51,022:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['postCode', 'habitableSurface',
                                             'buildingConstructionYear',
                                             'facedeCount', 'toiletCount',
                                             'bedroomCount_scaled',
                                             'bathroomCount_scaled'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['buildingCondition',
                                             'floodZoneType', 'heating...
                ('onehot_encoding',
                 TransformerWrapper(include=['buildingCondition',
                                             'floodZoneType', 'heatingType',
                                             'kitchenType', 'epcScore'],
                                    transformer=OneHotEncoder(cols=['buildingCondition',
                                                                    'floodZoneType',
                                                                    'heatingType',
                                                                    'kitchenType',
                                                                    'epcScore'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 RandomForestRegressor(n_jobs=-1, random_state=123))])
2025-05-07 14:16:51,022:INFO:save_model() successfully completed......................................
2025-05-07 16:10:08,073:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-07 16:10:08,075:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-07 16:10:08,076:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-07 16:10:08,076:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-07 16:10:08,213:INFO:PyCaret RegressionExperiment
2025-05-07 16:10:08,235:INFO:Logging name: reg-default-name
2025-05-07 16:10:08,236:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-07 16:10:08,236:INFO:version 3.3.2
2025-05-07 16:10:08,236:INFO:Initializing setup()
2025-05-07 16:10:08,236:INFO:self.USI: 7452
2025-05-07 16:10:08,236:INFO:self._variable_keys: {'memory', 'X_test', 'y_test', 'html_param', 'transform_target_param', 'n_jobs_param', 'X_train', 'target_param', 'idx', '_available_plots', 'gpu_n_jobs_param', 'USI', 'pipeline', 'log_plots_param', 'fold_generator', 'data', 'seed', '_ml_usecase', 'fold_shuffle_param', 'exp_name_log', 'gpu_param', 'X', 'exp_id', 'y_train', 'y', 'logging_param', 'fold_groups_param'}
2025-05-07 16:10:08,236:INFO:Checking environment
2025-05-07 16:10:08,236:INFO:python_version: 3.11.7
2025-05-07 16:10:08,236:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2025-05-07 16:10:08,236:INFO:machine: AMD64
2025-05-07 16:10:08,238:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-07 16:10:08,245:INFO:Memory: svmem(total=34281660416, available=17568849920, percent=48.8, used=16712810496, free=17568849920)
2025-05-07 16:10:08,246:INFO:Physical Core: 8
2025-05-07 16:10:08,246:INFO:Logical Core: 16
2025-05-07 16:10:08,246:INFO:Checking libraries
2025-05-07 16:10:08,246:INFO:System:
2025-05-07 16:10:08,246:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2025-05-07 16:10:08,246:INFO:executable: c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Scripts\python.exe
2025-05-07 16:10:08,246:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-07 16:10:08,246:INFO:PyCaret required dependencies:
2025-05-07 16:10:08,283:INFO:                 pip: 23.2.1
2025-05-07 16:10:08,284:INFO:          setuptools: 65.5.0
2025-05-07 16:10:08,284:INFO:             pycaret: 3.3.2
2025-05-07 16:10:08,284:INFO:             IPython: 9.2.0
2025-05-07 16:10:08,284:INFO:          ipywidgets: 8.1.7
2025-05-07 16:10:08,284:INFO:                tqdm: 4.67.1
2025-05-07 16:10:08,284:INFO:               numpy: 1.26.4
2025-05-07 16:10:08,285:INFO:              pandas: 2.1.4
2025-05-07 16:10:08,285:INFO:              jinja2: 3.1.6
2025-05-07 16:10:08,285:INFO:               scipy: 1.11.4
2025-05-07 16:10:08,285:INFO:              joblib: 1.3.2
2025-05-07 16:10:08,285:INFO:             sklearn: 1.4.2
2025-05-07 16:10:08,285:INFO:                pyod: 2.0.5
2025-05-07 16:10:08,286:INFO:            imblearn: 0.13.0
2025-05-07 16:10:08,286:INFO:   category_encoders: 2.7.0
2025-05-07 16:10:08,286:INFO:            lightgbm: 4.6.0
2025-05-07 16:10:08,286:INFO:               numba: 0.61.2
2025-05-07 16:10:08,286:INFO:            requests: 2.32.3
2025-05-07 16:10:08,286:INFO:          matplotlib: 3.7.5
2025-05-07 16:10:08,286:INFO:          scikitplot: 0.3.7
2025-05-07 16:10:08,287:INFO:         yellowbrick: 1.5
2025-05-07 16:10:08,287:INFO:              plotly: 5.24.1
2025-05-07 16:10:08,287:INFO:    plotly-resampler: Not installed
2025-05-07 16:10:08,287:INFO:             kaleido: 0.2.1
2025-05-07 16:10:08,287:INFO:           schemdraw: 0.15
2025-05-07 16:10:08,287:INFO:         statsmodels: 0.14.4
2025-05-07 16:10:08,287:INFO:              sktime: 0.26.0
2025-05-07 16:10:08,288:INFO:               tbats: 1.1.3
2025-05-07 16:10:08,288:INFO:            pmdarima: 2.0.4
2025-05-07 16:10:08,288:INFO:              psutil: 7.0.0
2025-05-07 16:10:08,288:INFO:          markupsafe: 3.0.2
2025-05-07 16:10:08,288:INFO:             pickle5: Not installed
2025-05-07 16:10:08,288:INFO:         cloudpickle: 3.1.1
2025-05-07 16:10:08,289:INFO:         deprecation: 2.1.0
2025-05-07 16:10:08,289:INFO:              xxhash: 3.5.0
2025-05-07 16:10:08,289:INFO:           wurlitzer: Not installed
2025-05-07 16:10:08,289:INFO:PyCaret optional dependencies:
2025-05-07 16:10:08,310:INFO:                shap: Not installed
2025-05-07 16:10:08,310:INFO:           interpret: Not installed
2025-05-07 16:10:08,310:INFO:                umap: Not installed
2025-05-07 16:10:08,310:INFO:     ydata_profiling: Not installed
2025-05-07 16:10:08,310:INFO:  explainerdashboard: Not installed
2025-05-07 16:10:08,311:INFO:             autoviz: Not installed
2025-05-07 16:10:08,311:INFO:           fairlearn: Not installed
2025-05-07 16:10:08,311:INFO:          deepchecks: Not installed
2025-05-07 16:10:08,311:INFO:             xgboost: Not installed
2025-05-07 16:10:08,312:INFO:            catboost: Not installed
2025-05-07 16:10:08,312:INFO:              kmodes: Not installed
2025-05-07 16:10:08,312:INFO:             mlxtend: Not installed
2025-05-07 16:10:08,312:INFO:       statsforecast: Not installed
2025-05-07 16:10:08,312:INFO:        tune_sklearn: Not installed
2025-05-07 16:10:08,312:INFO:                 ray: Not installed
2025-05-07 16:10:08,313:INFO:            hyperopt: Not installed
2025-05-07 16:10:08,313:INFO:              optuna: Not installed
2025-05-07 16:10:08,313:INFO:               skopt: Not installed
2025-05-07 16:10:08,313:INFO:              mlflow: Not installed
2025-05-07 16:10:08,313:INFO:              gradio: Not installed
2025-05-07 16:10:08,313:INFO:             fastapi: Not installed
2025-05-07 16:10:08,314:INFO:             uvicorn: Not installed
2025-05-07 16:10:08,314:INFO:              m2cgen: Not installed
2025-05-07 16:10:08,314:INFO:           evidently: Not installed
2025-05-07 16:10:08,314:INFO:               fugue: Not installed
2025-05-07 16:10:08,314:INFO:           streamlit: Not installed
2025-05-07 16:10:08,314:INFO:             prophet: Not installed
2025-05-07 16:10:08,314:INFO:None
2025-05-07 16:10:08,314:INFO:Set up data.
2025-05-07 16:10:08,356:INFO:Set up folding strategy.
2025-05-07 16:10:08,358:INFO:Set up train/test split.
2025-05-07 16:10:08,374:INFO:Set up index.
2025-05-07 16:10:08,375:INFO:Assigning column types.
2025-05-07 16:10:08,384:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-07 16:10:08,385:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,389:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,392:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,442:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,472:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,473:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:08,473:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:08,474:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,478:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,481:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,530:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,561:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,562:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:08,562:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:08,563:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-07 16:10:08,565:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,569:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,616:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,648:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,648:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:08,648:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:08,652:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,655:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,705:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,734:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:08,735:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:08,736:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-07 16:10:08,743:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,792:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,822:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,823:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:08,823:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:08,831:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,880:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,909:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-07 16:10:08,910:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:08,910:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:08,910:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-07 16:10:08,963:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-07 16:10:09,000:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-07 16:10:09,001:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:09,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:09,059:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-07 16:10:09,090:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-07 16:10:09,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:09,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:09,092:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-07 16:10:09,146:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-07 16:10:09,178:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:09,178:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:09,236:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-07 16:10:09,266:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:09,268:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:09,268:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-07 16:10:09,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:09,352:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:09,439:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:09,439:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:09,441:INFO:Preparing preprocessing pipeline...
2025-05-07 16:10:09,442:INFO:Set up simple imputation.
2025-05-07 16:10:09,462:INFO:Set up encoding of ordinal features.
2025-05-07 16:10:09,466:INFO:Set up encoding of categorical features.
2025-05-07 16:10:10,181:INFO:Finished creating preprocessing pipeline.
2025-05-07 16:10:10,196:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LINW~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['bedroomCount', 'bathroomCount',
                                             'postCode', 'habitableSurface',
                                             'buildingConstructionYear',
                                             'facedeCount', 'toiletCount'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['type', 'subtype',...
                                             'floodZoneType', 'heatingType',
                                             'kitchenType', 'epcScore'],
                                    transformer=OneHotEncoder(cols=['subtype',
                                                                    'buildingCondition',
                                                                    'floodZoneType',
                                                                    'heatingType',
                                                                    'kitchenType',
                                                                    'epcScore'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['locality'],
                                    transformer=TargetEncoder(cols=['locality'],
                                                              handle_missing='return_nan')))])
2025-05-07 16:10:10,196:INFO:Creating final display dataframe.
2025-05-07 16:10:10,866:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             price
2                   Target type        Regression
3           Original data shape       (62099, 20)
4        Transformed data shape       (62099, 77)
5   Transformed train set shape       (43469, 77)
6    Transformed test set shape       (18630, 77)
7              Numeric features                 7
8          Categorical features                 8
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              7452
2025-05-07 16:10:10,958:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:10,959:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:11,073:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:11,074:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-07 16:10:11,074:INFO:setup() successfully completed in 2.87s...............
2025-05-07 16:10:33,335:INFO:Initializing compare_models()
2025-05-07 16:10:33,336:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-07 16:10:33,336:INFO:Checking exceptions
2025-05-07 16:10:33,344:INFO:Preparing display monitor
2025-05-07 16:10:33,363:INFO:Initializing Linear Regression
2025-05-07 16:10:33,363:INFO:Total runtime is 0.0 minutes
2025-05-07 16:10:33,366:INFO:SubProcess create_model() called ==================================
2025-05-07 16:10:33,367:INFO:Initializing create_model()
2025-05-07 16:10:33,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002671F3ABF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 16:10:33,367:INFO:Checking exceptions
2025-05-07 16:10:33,367:INFO:Importing libraries
2025-05-07 16:10:33,367:INFO:Copying training dataset
2025-05-07 16:10:33,386:INFO:Defining folds
2025-05-07 16:10:33,386:INFO:Declaring metric variables
2025-05-07 16:10:33,389:INFO:Importing untrained model
2025-05-07 16:10:33,392:INFO:Linear Regression Imported successfully
2025-05-07 16:10:33,399:INFO:Starting cross validation
2025-05-07 16:10:33,409:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 16:10:39,525:INFO:Calculating mean and std
2025-05-07 16:10:39,527:INFO:Creating metrics dataframe
2025-05-07 16:10:39,532:INFO:Uploading results into container
2025-05-07 16:10:39,533:INFO:Uploading model into container now
2025-05-07 16:10:39,534:INFO:_master_model_container: 1
2025-05-07 16:10:39,534:INFO:_display_container: 2
2025-05-07 16:10:39,535:INFO:LinearRegression(n_jobs=-1)
2025-05-07 16:10:39,535:INFO:create_model() successfully completed......................................
2025-05-07 16:10:39,710:INFO:SubProcess create_model() end ==================================
2025-05-07 16:10:39,711:INFO:Creating metrics dataframe
2025-05-07 16:10:39,722:INFO:Initializing Lasso Regression
2025-05-07 16:10:39,723:INFO:Total runtime is 0.10599202712376912 minutes
2025-05-07 16:10:39,731:INFO:SubProcess create_model() called ==================================
2025-05-07 16:10:39,732:INFO:Initializing create_model()
2025-05-07 16:10:39,732:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002671F3ABF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 16:10:39,733:INFO:Checking exceptions
2025-05-07 16:10:39,733:INFO:Importing libraries
2025-05-07 16:10:39,734:INFO:Copying training dataset
2025-05-07 16:10:39,771:INFO:Defining folds
2025-05-07 16:10:39,772:INFO:Declaring metric variables
2025-05-07 16:10:39,779:INFO:Importing untrained model
2025-05-07 16:10:39,788:INFO:Lasso Regression Imported successfully
2025-05-07 16:10:39,802:INFO:Starting cross validation
2025-05-07 16:10:39,807:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 16:10:52,968:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.211e+15, tolerance: 9.820e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-07 16:10:53,054:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.575e+15, tolerance: 9.769e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-07 16:10:53,274:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.228e+15, tolerance: 9.959e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-07 16:10:53,398:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.900e+15, tolerance: 9.796e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-07 16:11:01,060:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+15, tolerance: 9.937e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-07 16:11:01,144:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.087e+15, tolerance: 1.006e+12
  model = cd_fast.enet_coordinate_descent(

2025-05-07 16:11:01,146:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.235e+15, tolerance: 9.867e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-07 16:11:01,401:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e+15, tolerance: 9.869e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-07 16:11:01,410:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.928e+14, tolerance: 9.979e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-07 16:11:01,491:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e+15, tolerance: 9.682e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-07 16:11:01,558:INFO:Calculating mean and std
2025-05-07 16:11:01,559:INFO:Creating metrics dataframe
2025-05-07 16:11:01,561:INFO:Uploading results into container
2025-05-07 16:11:01,562:INFO:Uploading model into container now
2025-05-07 16:11:01,562:INFO:_master_model_container: 2
2025-05-07 16:11:01,562:INFO:_display_container: 2
2025-05-07 16:11:01,563:INFO:Lasso(random_state=123)
2025-05-07 16:11:01,563:INFO:create_model() successfully completed......................................
2025-05-07 16:11:01,651:INFO:SubProcess create_model() end ==================================
2025-05-07 16:11:01,652:INFO:Creating metrics dataframe
2025-05-07 16:11:01,657:INFO:Initializing Ridge Regression
2025-05-07 16:11:01,657:INFO:Total runtime is 0.4715638677279155 minutes
2025-05-07 16:11:01,660:INFO:SubProcess create_model() called ==================================
2025-05-07 16:11:01,660:INFO:Initializing create_model()
2025-05-07 16:11:01,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002671F3ABF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 16:11:01,661:INFO:Checking exceptions
2025-05-07 16:11:01,661:INFO:Importing libraries
2025-05-07 16:11:01,661:INFO:Copying training dataset
2025-05-07 16:11:01,678:INFO:Defining folds
2025-05-07 16:11:01,679:INFO:Declaring metric variables
2025-05-07 16:11:01,682:INFO:Importing untrained model
2025-05-07 16:11:01,684:INFO:Ridge Regression Imported successfully
2025-05-07 16:11:01,689:INFO:Starting cross validation
2025-05-07 16:11:01,692:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 16:11:03,492:INFO:Calculating mean and std
2025-05-07 16:11:03,495:INFO:Creating metrics dataframe
2025-05-07 16:11:03,499:INFO:Uploading results into container
2025-05-07 16:11:03,500:INFO:Uploading model into container now
2025-05-07 16:11:03,501:INFO:_master_model_container: 3
2025-05-07 16:11:03,501:INFO:_display_container: 2
2025-05-07 16:11:03,502:INFO:Ridge(random_state=123)
2025-05-07 16:11:03,502:INFO:create_model() successfully completed......................................
2025-05-07 16:11:03,694:INFO:SubProcess create_model() end ==================================
2025-05-07 16:11:03,695:INFO:Creating metrics dataframe
2025-05-07 16:11:03,707:INFO:Initializing Elastic Net
2025-05-07 16:11:03,707:INFO:Total runtime is 0.5057242433230082 minutes
2025-05-07 16:11:03,715:INFO:SubProcess create_model() called ==================================
2025-05-07 16:11:03,716:INFO:Initializing create_model()
2025-05-07 16:11:03,716:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002671F3ABF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 16:11:03,717:INFO:Checking exceptions
2025-05-07 16:11:03,717:INFO:Importing libraries
2025-05-07 16:11:03,718:INFO:Copying training dataset
2025-05-07 16:11:03,757:INFO:Defining folds
2025-05-07 16:11:03,758:INFO:Declaring metric variables
2025-05-07 16:11:03,764:INFO:Importing untrained model
2025-05-07 16:11:03,772:INFO:Elastic Net Imported successfully
2025-05-07 16:11:03,784:INFO:Starting cross validation
2025-05-07 16:11:03,788:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 16:11:06,407:INFO:Calculating mean and std
2025-05-07 16:11:06,409:INFO:Creating metrics dataframe
2025-05-07 16:11:06,413:INFO:Uploading results into container
2025-05-07 16:11:06,415:INFO:Uploading model into container now
2025-05-07 16:11:06,415:INFO:_master_model_container: 4
2025-05-07 16:11:06,417:INFO:_display_container: 2
2025-05-07 16:11:06,418:INFO:ElasticNet(random_state=123)
2025-05-07 16:11:06,418:INFO:create_model() successfully completed......................................
2025-05-07 16:11:06,614:INFO:SubProcess create_model() end ==================================
2025-05-07 16:11:06,615:INFO:Creating metrics dataframe
2025-05-07 16:11:06,625:INFO:Initializing Least Angle Regression
2025-05-07 16:11:06,626:INFO:Total runtime is 0.5543793797492981 minutes
2025-05-07 16:11:06,633:INFO:SubProcess create_model() called ==================================
2025-05-07 16:11:06,634:INFO:Initializing create_model()
2025-05-07 16:11:06,634:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002671F3ABF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 16:11:06,635:INFO:Checking exceptions
2025-05-07 16:11:06,635:INFO:Importing libraries
2025-05-07 16:11:06,635:INFO:Copying training dataset
2025-05-07 16:11:06,673:INFO:Defining folds
2025-05-07 16:11:06,674:INFO:Declaring metric variables
2025-05-07 16:11:06,682:INFO:Importing untrained model
2025-05-07 16:11:06,690:INFO:Least Angle Regression Imported successfully
2025-05-07 16:11:06,705:INFO:Starting cross validation
2025-05-07 16:11:06,709:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 16:11:08,445:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=3.438e+02, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 16:11:08,451:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=1.059e+03, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 16:11:08,453:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=7.755e+02, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 16:11:08,464:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:812: RuntimeWarning: overflow encountered in multiply
  coef[active] = prev_coef[active] + gamma_ * least_squares

2025-05-07 16:11:08,465:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:771: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2025-05-07 16:11:08,466:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:775: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2025-05-07 16:11:08,466:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:776: RuntimeWarning: overflow encountered in scalar divide
  gamma_ = min(g1, g2, C / AA)

2025-05-07 16:11:08,468:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:780: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2025-05-07 16:11:08,602:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py:501: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2025-05-07 16:11:08,604:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py:501: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2025-05-07 16:11:08,605:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py:1196: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2025-05-07 16:11:08,614:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\extmath.py:208: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b

2025-05-07 16:11:08,722:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-07 16:11:08,725:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-07 16:11:08,727:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-07 16:11:08,728:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-07 16:11:08,728:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-07 16:11:08,729:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-07 16:11:08,737:INFO:Calculating mean and std
2025-05-07 16:11:08,758:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\numpy\core\_methods.py:176: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-05-07 16:11:08,760:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\numpy\core\_methods.py:173: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)

2025-05-07 16:11:08,762:INFO:Creating metrics dataframe
2025-05-07 16:11:08,765:INFO:Uploading results into container
2025-05-07 16:11:08,767:INFO:Uploading model into container now
2025-05-07 16:11:08,768:INFO:_master_model_container: 5
2025-05-07 16:11:08,769:INFO:_display_container: 2
2025-05-07 16:11:08,770:INFO:Lars(random_state=123)
2025-05-07 16:11:08,770:INFO:create_model() successfully completed......................................
2025-05-07 16:11:08,963:WARNING:create_model() for Lars(random_state=123) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-05-07 16:11:08,965:WARNING:Traceback (most recent call last):
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-05-07 16:11:08,967:INFO:Initializing create_model()
2025-05-07 16:11:08,968:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002671F3ABF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 16:11:08,968:INFO:Checking exceptions
2025-05-07 16:11:08,969:INFO:Importing libraries
2025-05-07 16:11:08,969:INFO:Copying training dataset
2025-05-07 16:11:09,005:INFO:Defining folds
2025-05-07 16:11:09,005:INFO:Declaring metric variables
2025-05-07 16:11:09,015:INFO:Importing untrained model
2025-05-07 16:11:09,022:INFO:Least Angle Regression Imported successfully
2025-05-07 16:11:09,036:INFO:Starting cross validation
2025-05-07 16:11:09,040:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 16:11:10,542:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=3.438e+02, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 16:11:10,554:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=1.059e+03, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 16:11:10,557:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=7.755e+02, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-07 16:11:10,634:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:812: RuntimeWarning: overflow encountered in multiply
  coef[active] = prev_coef[active] + gamma_ * least_squares

2025-05-07 16:11:10,635:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:771: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2025-05-07 16:11:10,636:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:775: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2025-05-07 16:11:10,637:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:776: RuntimeWarning: overflow encountered in scalar divide
  gamma_ = min(g1, g2, C / AA)

2025-05-07 16:11:10,638:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:780: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2025-05-07 16:11:10,762:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\extmath.py:208: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b

2025-05-07 16:11:10,775:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-07 16:11:10,778:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-07 16:11:10,780:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-07 16:11:10,781:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-07 16:11:10,782:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-07 16:11:10,782:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-07 16:11:10,785:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py:501: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2025-05-07 16:11:10,788:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py:501: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2025-05-07 16:11:10,790:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py:1196: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2025-05-07 16:11:10,852:INFO:Calculating mean and std
2025-05-07 16:11:10,853:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\numpy\core\_methods.py:176: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-05-07 16:11:10,854:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\numpy\core\_methods.py:173: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)

2025-05-07 16:11:10,857:INFO:Creating metrics dataframe
2025-05-07 16:11:10,861:INFO:Uploading results into container
2025-05-07 16:11:10,862:INFO:Uploading model into container now
2025-05-07 16:11:10,863:INFO:_master_model_container: 6
2025-05-07 16:11:10,864:INFO:_display_container: 2
2025-05-07 16:11:10,865:INFO:Lars(random_state=123)
2025-05-07 16:11:10,865:INFO:create_model() successfully completed......................................
2025-05-07 16:11:11,062:ERROR:create_model() for Lars(random_state=123) raised an exception or returned all 0.0:
2025-05-07 16:11:11,063:ERROR:Traceback (most recent call last):
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-05-07 16:11:11,064:INFO:Initializing Lasso Least Angle Regression
2025-05-07 16:11:11,065:INFO:Total runtime is 0.6283479849497478 minutes
2025-05-07 16:11:11,071:INFO:SubProcess create_model() called ==================================
2025-05-07 16:11:11,072:INFO:Initializing create_model()
2025-05-07 16:11:11,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002671F3ABF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 16:11:11,073:INFO:Checking exceptions
2025-05-07 16:11:11,074:INFO:Importing libraries
2025-05-07 16:11:11,074:INFO:Copying training dataset
2025-05-07 16:11:11,112:INFO:Defining folds
2025-05-07 16:11:11,113:INFO:Declaring metric variables
2025-05-07 16:11:11,120:INFO:Importing untrained model
2025-05-07 16:11:11,127:INFO:Lasso Least Angle Regression Imported successfully
2025-05-07 16:11:11,141:INFO:Starting cross validation
2025-05-07 16:11:11,150:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 16:11:13,118:INFO:Calculating mean and std
2025-05-07 16:11:13,122:INFO:Creating metrics dataframe
2025-05-07 16:11:13,126:INFO:Uploading results into container
2025-05-07 16:11:13,127:INFO:Uploading model into container now
2025-05-07 16:11:13,128:INFO:_master_model_container: 7
2025-05-07 16:11:13,129:INFO:_display_container: 2
2025-05-07 16:11:13,130:INFO:LassoLars(random_state=123)
2025-05-07 16:11:13,130:INFO:create_model() successfully completed......................................
2025-05-07 16:11:13,326:INFO:SubProcess create_model() end ==================================
2025-05-07 16:11:13,327:INFO:Creating metrics dataframe
2025-05-07 16:11:13,338:INFO:Initializing Orthogonal Matching Pursuit
2025-05-07 16:11:13,339:INFO:Total runtime is 0.6662662347157796 minutes
2025-05-07 16:11:13,347:INFO:SubProcess create_model() called ==================================
2025-05-07 16:11:13,348:INFO:Initializing create_model()
2025-05-07 16:11:13,348:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002671F3ABF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 16:11:13,349:INFO:Checking exceptions
2025-05-07 16:11:13,349:INFO:Importing libraries
2025-05-07 16:11:13,349:INFO:Copying training dataset
2025-05-07 16:11:13,389:INFO:Defining folds
2025-05-07 16:11:13,389:INFO:Declaring metric variables
2025-05-07 16:11:13,398:INFO:Importing untrained model
2025-05-07 16:11:13,405:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-07 16:11:13,419:INFO:Starting cross validation
2025-05-07 16:11:13,423:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 16:11:15,284:INFO:Calculating mean and std
2025-05-07 16:11:15,287:INFO:Creating metrics dataframe
2025-05-07 16:11:15,290:INFO:Uploading results into container
2025-05-07 16:11:15,292:INFO:Uploading model into container now
2025-05-07 16:11:15,293:INFO:_master_model_container: 8
2025-05-07 16:11:15,293:INFO:_display_container: 2
2025-05-07 16:11:15,294:INFO:OrthogonalMatchingPursuit()
2025-05-07 16:11:15,295:INFO:create_model() successfully completed......................................
2025-05-07 16:11:15,487:INFO:SubProcess create_model() end ==================================
2025-05-07 16:11:15,488:INFO:Creating metrics dataframe
2025-05-07 16:11:15,500:INFO:Initializing Bayesian Ridge
2025-05-07 16:11:15,502:INFO:Total runtime is 0.7023089090983072 minutes
2025-05-07 16:11:15,508:INFO:SubProcess create_model() called ==================================
2025-05-07 16:11:15,509:INFO:Initializing create_model()
2025-05-07 16:11:15,509:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002671F3ABF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 16:11:15,510:INFO:Checking exceptions
2025-05-07 16:11:15,510:INFO:Importing libraries
2025-05-07 16:11:15,510:INFO:Copying training dataset
2025-05-07 16:11:15,548:INFO:Defining folds
2025-05-07 16:11:15,549:INFO:Declaring metric variables
2025-05-07 16:11:15,557:INFO:Importing untrained model
2025-05-07 16:11:15,564:INFO:Bayesian Ridge Imported successfully
2025-05-07 16:11:15,575:INFO:Starting cross validation
2025-05-07 16:11:15,580:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 16:11:19,652:INFO:Calculating mean and std
2025-05-07 16:11:19,653:INFO:Creating metrics dataframe
2025-05-07 16:11:19,655:INFO:Uploading results into container
2025-05-07 16:11:19,655:INFO:Uploading model into container now
2025-05-07 16:11:19,656:INFO:_master_model_container: 9
2025-05-07 16:11:19,656:INFO:_display_container: 2
2025-05-07 16:11:19,657:INFO:BayesianRidge()
2025-05-07 16:11:19,657:INFO:create_model() successfully completed......................................
2025-05-07 16:11:19,857:INFO:SubProcess create_model() end ==================================
2025-05-07 16:11:19,858:INFO:Creating metrics dataframe
2025-05-07 16:11:19,870:INFO:Initializing Passive Aggressive Regressor
2025-05-07 16:11:19,871:INFO:Total runtime is 0.7751261234283446 minutes
2025-05-07 16:11:19,879:INFO:SubProcess create_model() called ==================================
2025-05-07 16:11:19,880:INFO:Initializing create_model()
2025-05-07 16:11:19,880:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002671F3ABF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 16:11:19,881:INFO:Checking exceptions
2025-05-07 16:11:19,881:INFO:Importing libraries
2025-05-07 16:11:19,882:INFO:Copying training dataset
2025-05-07 16:11:19,924:INFO:Defining folds
2025-05-07 16:11:19,925:INFO:Declaring metric variables
2025-05-07 16:11:19,933:INFO:Importing untrained model
2025-05-07 16:11:19,941:INFO:Passive Aggressive Regressor Imported successfully
2025-05-07 16:11:19,956:INFO:Starting cross validation
2025-05-07 16:11:19,960:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 16:11:22,830:INFO:Calculating mean and std
2025-05-07 16:11:22,831:INFO:Creating metrics dataframe
2025-05-07 16:11:22,832:INFO:Uploading results into container
2025-05-07 16:11:22,833:INFO:Uploading model into container now
2025-05-07 16:11:22,833:INFO:_master_model_container: 10
2025-05-07 16:11:22,833:INFO:_display_container: 2
2025-05-07 16:11:22,834:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-07 16:11:22,834:INFO:create_model() successfully completed......................................
2025-05-07 16:11:22,915:INFO:SubProcess create_model() end ==================================
2025-05-07 16:11:22,917:INFO:Creating metrics dataframe
2025-05-07 16:11:22,921:INFO:Initializing Huber Regressor
2025-05-07 16:11:22,921:INFO:Total runtime is 0.8259580095609028 minutes
2025-05-07 16:11:22,925:INFO:SubProcess create_model() called ==================================
2025-05-07 16:11:22,926:INFO:Initializing create_model()
2025-05-07 16:11:22,926:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002671F3ABF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 16:11:22,927:INFO:Checking exceptions
2025-05-07 16:11:22,927:INFO:Importing libraries
2025-05-07 16:11:22,927:INFO:Copying training dataset
2025-05-07 16:11:22,945:INFO:Defining folds
2025-05-07 16:11:22,947:INFO:Declaring metric variables
2025-05-07 16:11:22,950:INFO:Importing untrained model
2025-05-07 16:11:22,952:INFO:Huber Regressor Imported successfully
2025-05-07 16:11:22,959:INFO:Starting cross validation
2025-05-07 16:11:22,961:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 16:11:28,667:INFO:Calculating mean and std
2025-05-07 16:11:28,669:INFO:Creating metrics dataframe
2025-05-07 16:11:28,671:INFO:Uploading results into container
2025-05-07 16:11:28,671:INFO:Uploading model into container now
2025-05-07 16:11:28,671:INFO:_master_model_container: 11
2025-05-07 16:11:28,672:INFO:_display_container: 2
2025-05-07 16:11:28,672:INFO:HuberRegressor()
2025-05-07 16:11:28,672:INFO:create_model() successfully completed......................................
2025-05-07 16:11:28,752:INFO:SubProcess create_model() end ==================================
2025-05-07 16:11:28,752:INFO:Creating metrics dataframe
2025-05-07 16:11:28,759:INFO:Initializing K Neighbors Regressor
2025-05-07 16:11:28,759:INFO:Total runtime is 0.923254350821177 minutes
2025-05-07 16:11:28,762:INFO:SubProcess create_model() called ==================================
2025-05-07 16:11:28,762:INFO:Initializing create_model()
2025-05-07 16:11:28,762:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002671F3ABF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 16:11:28,762:INFO:Checking exceptions
2025-05-07 16:11:28,763:INFO:Importing libraries
2025-05-07 16:11:28,763:INFO:Copying training dataset
2025-05-07 16:11:28,783:INFO:Defining folds
2025-05-07 16:11:28,783:INFO:Declaring metric variables
2025-05-07 16:11:28,785:INFO:Importing untrained model
2025-05-07 16:11:28,789:INFO:K Neighbors Regressor Imported successfully
2025-05-07 16:11:28,795:INFO:Starting cross validation
2025-05-07 16:11:28,797:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 16:11:32,095:INFO:Calculating mean and std
2025-05-07 16:11:32,095:INFO:Creating metrics dataframe
2025-05-07 16:11:32,098:INFO:Uploading results into container
2025-05-07 16:11:32,098:INFO:Uploading model into container now
2025-05-07 16:11:32,098:INFO:_master_model_container: 12
2025-05-07 16:11:32,099:INFO:_display_container: 2
2025-05-07 16:11:32,099:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-07 16:11:32,099:INFO:create_model() successfully completed......................................
2025-05-07 16:11:32,179:INFO:SubProcess create_model() end ==================================
2025-05-07 16:11:32,180:INFO:Creating metrics dataframe
2025-05-07 16:11:32,185:INFO:Initializing Decision Tree Regressor
2025-05-07 16:11:32,185:INFO:Total runtime is 0.9803650776545205 minutes
2025-05-07 16:11:32,188:INFO:SubProcess create_model() called ==================================
2025-05-07 16:11:32,188:INFO:Initializing create_model()
2025-05-07 16:11:32,188:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002671F3ABF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 16:11:32,189:INFO:Checking exceptions
2025-05-07 16:11:32,189:INFO:Importing libraries
2025-05-07 16:11:32,189:INFO:Copying training dataset
2025-05-07 16:11:32,207:INFO:Defining folds
2025-05-07 16:11:32,207:INFO:Declaring metric variables
2025-05-07 16:11:32,210:INFO:Importing untrained model
2025-05-07 16:11:32,213:INFO:Decision Tree Regressor Imported successfully
2025-05-07 16:11:32,218:INFO:Starting cross validation
2025-05-07 16:11:32,220:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 16:11:34,654:INFO:Calculating mean and std
2025-05-07 16:11:34,655:INFO:Creating metrics dataframe
2025-05-07 16:11:34,657:INFO:Uploading results into container
2025-05-07 16:11:34,657:INFO:Uploading model into container now
2025-05-07 16:11:34,658:INFO:_master_model_container: 13
2025-05-07 16:11:34,658:INFO:_display_container: 2
2025-05-07 16:11:34,658:INFO:DecisionTreeRegressor(random_state=123)
2025-05-07 16:11:34,659:INFO:create_model() successfully completed......................................
2025-05-07 16:11:34,748:INFO:SubProcess create_model() end ==================================
2025-05-07 16:11:34,749:INFO:Creating metrics dataframe
2025-05-07 16:11:34,754:INFO:Initializing Random Forest Regressor
2025-05-07 16:11:34,754:INFO:Total runtime is 1.0231831669807432 minutes
2025-05-07 16:11:34,758:INFO:SubProcess create_model() called ==================================
2025-05-07 16:11:34,759:INFO:Initializing create_model()
2025-05-07 16:11:34,759:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002671F3ABF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 16:11:34,759:INFO:Checking exceptions
2025-05-07 16:11:34,759:INFO:Importing libraries
2025-05-07 16:11:34,760:INFO:Copying training dataset
2025-05-07 16:11:34,778:INFO:Defining folds
2025-05-07 16:11:34,778:INFO:Declaring metric variables
2025-05-07 16:11:34,781:INFO:Importing untrained model
2025-05-07 16:11:34,783:INFO:Random Forest Regressor Imported successfully
2025-05-07 16:11:34,788:INFO:Starting cross validation
2025-05-07 16:11:34,791:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 16:12:06,300:INFO:Calculating mean and std
2025-05-07 16:12:06,304:INFO:Creating metrics dataframe
2025-05-07 16:12:06,307:INFO:Uploading results into container
2025-05-07 16:12:06,308:INFO:Uploading model into container now
2025-05-07 16:12:06,309:INFO:_master_model_container: 14
2025-05-07 16:12:06,310:INFO:_display_container: 2
2025-05-07 16:12:06,311:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-07 16:12:06,311:INFO:create_model() successfully completed......................................
2025-05-07 16:12:06,514:INFO:SubProcess create_model() end ==================================
2025-05-07 16:12:06,515:INFO:Creating metrics dataframe
2025-05-07 16:12:06,529:INFO:Initializing Extra Trees Regressor
2025-05-07 16:12:06,530:INFO:Total runtime is 1.5527749697367348 minutes
2025-05-07 16:12:06,537:INFO:SubProcess create_model() called ==================================
2025-05-07 16:12:06,537:INFO:Initializing create_model()
2025-05-07 16:12:06,538:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002671F3ABF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 16:12:06,539:INFO:Checking exceptions
2025-05-07 16:12:06,539:INFO:Importing libraries
2025-05-07 16:12:06,540:INFO:Copying training dataset
2025-05-07 16:12:06,580:INFO:Defining folds
2025-05-07 16:12:06,581:INFO:Declaring metric variables
2025-05-07 16:12:06,589:INFO:Importing untrained model
2025-05-07 16:12:06,596:INFO:Extra Trees Regressor Imported successfully
2025-05-07 16:12:06,610:INFO:Starting cross validation
2025-05-07 16:12:06,615:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 16:12:49,211:INFO:Calculating mean and std
2025-05-07 16:12:49,212:INFO:Creating metrics dataframe
2025-05-07 16:12:49,214:INFO:Uploading results into container
2025-05-07 16:12:49,216:INFO:Uploading model into container now
2025-05-07 16:12:49,216:INFO:_master_model_container: 15
2025-05-07 16:12:49,217:INFO:_display_container: 2
2025-05-07 16:12:49,217:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-07 16:12:49,217:INFO:create_model() successfully completed......................................
2025-05-07 16:12:49,319:INFO:SubProcess create_model() end ==================================
2025-05-07 16:12:49,319:INFO:Creating metrics dataframe
2025-05-07 16:12:49,326:INFO:Initializing AdaBoost Regressor
2025-05-07 16:12:49,326:INFO:Total runtime is 2.266042594114939 minutes
2025-05-07 16:12:49,329:INFO:SubProcess create_model() called ==================================
2025-05-07 16:12:49,329:INFO:Initializing create_model()
2025-05-07 16:12:49,330:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002671F3ABF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 16:12:49,330:INFO:Checking exceptions
2025-05-07 16:12:49,330:INFO:Importing libraries
2025-05-07 16:12:49,330:INFO:Copying training dataset
2025-05-07 16:12:49,355:INFO:Defining folds
2025-05-07 16:12:49,356:INFO:Declaring metric variables
2025-05-07 16:12:49,361:INFO:Importing untrained model
2025-05-07 16:12:49,364:INFO:AdaBoost Regressor Imported successfully
2025-05-07 16:12:49,370:INFO:Starting cross validation
2025-05-07 16:12:49,373:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 16:13:05,502:INFO:Calculating mean and std
2025-05-07 16:13:05,503:INFO:Creating metrics dataframe
2025-05-07 16:13:05,504:INFO:Uploading results into container
2025-05-07 16:13:05,505:INFO:Uploading model into container now
2025-05-07 16:13:05,505:INFO:_master_model_container: 16
2025-05-07 16:13:05,505:INFO:_display_container: 2
2025-05-07 16:13:05,506:INFO:AdaBoostRegressor(random_state=123)
2025-05-07 16:13:05,506:INFO:create_model() successfully completed......................................
2025-05-07 16:13:05,591:INFO:SubProcess create_model() end ==================================
2025-05-07 16:13:05,591:INFO:Creating metrics dataframe
2025-05-07 16:13:05,598:INFO:Initializing Gradient Boosting Regressor
2025-05-07 16:13:05,598:INFO:Total runtime is 2.5372392336527505 minutes
2025-05-07 16:13:05,601:INFO:SubProcess create_model() called ==================================
2025-05-07 16:13:05,601:INFO:Initializing create_model()
2025-05-07 16:13:05,602:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002671F3ABF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 16:13:05,602:INFO:Checking exceptions
2025-05-07 16:13:05,602:INFO:Importing libraries
2025-05-07 16:13:05,602:INFO:Copying training dataset
2025-05-07 16:13:05,619:INFO:Defining folds
2025-05-07 16:13:05,620:INFO:Declaring metric variables
2025-05-07 16:13:05,624:INFO:Importing untrained model
2025-05-07 16:13:05,626:INFO:Gradient Boosting Regressor Imported successfully
2025-05-07 16:13:05,632:INFO:Starting cross validation
2025-05-07 16:13:05,633:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 16:13:14,533:INFO:Calculating mean and std
2025-05-07 16:13:14,534:INFO:Creating metrics dataframe
2025-05-07 16:13:14,536:INFO:Uploading results into container
2025-05-07 16:13:14,536:INFO:Uploading model into container now
2025-05-07 16:13:14,537:INFO:_master_model_container: 17
2025-05-07 16:13:14,537:INFO:_display_container: 2
2025-05-07 16:13:14,537:INFO:GradientBoostingRegressor(random_state=123)
2025-05-07 16:13:14,538:INFO:create_model() successfully completed......................................
2025-05-07 16:13:14,627:INFO:SubProcess create_model() end ==================================
2025-05-07 16:13:14,628:INFO:Creating metrics dataframe
2025-05-07 16:13:14,634:INFO:Initializing Light Gradient Boosting Machine
2025-05-07 16:13:14,634:INFO:Total runtime is 2.687838057676951 minutes
2025-05-07 16:13:14,637:INFO:SubProcess create_model() called ==================================
2025-05-07 16:13:14,637:INFO:Initializing create_model()
2025-05-07 16:13:14,638:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002671F3ABF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 16:13:14,638:INFO:Checking exceptions
2025-05-07 16:13:14,638:INFO:Importing libraries
2025-05-07 16:13:14,638:INFO:Copying training dataset
2025-05-07 16:13:14,658:INFO:Defining folds
2025-05-07 16:13:14,658:INFO:Declaring metric variables
2025-05-07 16:13:14,661:INFO:Importing untrained model
2025-05-07 16:13:14,664:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-07 16:13:14,669:INFO:Starting cross validation
2025-05-07 16:13:14,671:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 16:13:17,805:INFO:Calculating mean and std
2025-05-07 16:13:17,807:INFO:Creating metrics dataframe
2025-05-07 16:13:17,809:INFO:Uploading results into container
2025-05-07 16:13:17,809:INFO:Uploading model into container now
2025-05-07 16:13:17,810:INFO:_master_model_container: 18
2025-05-07 16:13:17,810:INFO:_display_container: 2
2025-05-07 16:13:17,811:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-07 16:13:17,811:INFO:create_model() successfully completed......................................
2025-05-07 16:13:17,913:INFO:SubProcess create_model() end ==================================
2025-05-07 16:13:17,913:INFO:Creating metrics dataframe
2025-05-07 16:13:17,920:INFO:Initializing Dummy Regressor
2025-05-07 16:13:17,920:INFO:Total runtime is 2.742617921034495 minutes
2025-05-07 16:13:17,924:INFO:SubProcess create_model() called ==================================
2025-05-07 16:13:17,924:INFO:Initializing create_model()
2025-05-07 16:13:17,924:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002671F3ABF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 16:13:17,925:INFO:Checking exceptions
2025-05-07 16:13:17,925:INFO:Importing libraries
2025-05-07 16:13:17,925:INFO:Copying training dataset
2025-05-07 16:13:17,943:INFO:Defining folds
2025-05-07 16:13:17,944:INFO:Declaring metric variables
2025-05-07 16:13:17,946:INFO:Importing untrained model
2025-05-07 16:13:17,950:INFO:Dummy Regressor Imported successfully
2025-05-07 16:13:17,957:INFO:Starting cross validation
2025-05-07 16:13:17,959:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-07 16:13:19,869:INFO:Calculating mean and std
2025-05-07 16:13:19,873:INFO:Creating metrics dataframe
2025-05-07 16:13:19,875:INFO:Uploading results into container
2025-05-07 16:13:19,875:INFO:Uploading model into container now
2025-05-07 16:13:19,877:INFO:_master_model_container: 19
2025-05-07 16:13:19,877:INFO:_display_container: 2
2025-05-07 16:13:19,877:INFO:DummyRegressor()
2025-05-07 16:13:19,878:INFO:create_model() successfully completed......................................
2025-05-07 16:13:20,046:INFO:SubProcess create_model() end ==================================
2025-05-07 16:13:20,046:INFO:Creating metrics dataframe
2025-05-07 16:13:20,061:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-07 16:13:20,076:INFO:Initializing create_model()
2025-05-07 16:13:20,077:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-07 16:13:20,077:INFO:Checking exceptions
2025-05-07 16:13:20,080:INFO:Importing libraries
2025-05-07 16:13:20,081:INFO:Copying training dataset
2025-05-07 16:13:20,116:INFO:Defining folds
2025-05-07 16:13:20,117:INFO:Declaring metric variables
2025-05-07 16:13:20,118:INFO:Importing untrained model
2025-05-07 16:13:20,118:INFO:Declaring custom model
2025-05-07 16:13:20,120:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-07 16:13:20,126:INFO:Cross validation set to False
2025-05-07 16:13:20,127:INFO:Fitting Model
2025-05-07 16:13:20,821:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001458 seconds.
2025-05-07 16:13:20,822:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:13:20,822:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:13:20,822:INFO:[LightGBM] [Info] Total Bins 1128
2025-05-07 16:13:20,823:INFO:[LightGBM] [Info] Number of data points in the train set: 43469, number of used features: 71
2025-05-07 16:13:20,823:INFO:[LightGBM] [Info] Start training from score 437115.043893
2025-05-07 16:13:20,928:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-07 16:13:20,928:INFO:create_model() successfully completed......................................
2025-05-07 16:13:21,064:INFO:_master_model_container: 19
2025-05-07 16:13:21,064:INFO:_display_container: 2
2025-05-07 16:13:21,066:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-07 16:13:21,066:INFO:compare_models() successfully completed......................................
2025-05-07 16:14:02,313:INFO:Initializing evaluate_model()
2025-05-07 16:14:02,313:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-07 16:14:02,326:INFO:Initializing plot_model()
2025-05-07 16:14:02,327:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-07 16:14:02,327:INFO:Checking exceptions
2025-05-07 16:14:02,334:INFO:Preloading libraries
2025-05-07 16:14:02,338:INFO:Copying training dataset
2025-05-07 16:14:02,338:INFO:Plot type: pipeline
2025-05-07 16:14:02,500:INFO:Visual Rendered Successfully
2025-05-07 16:14:02,591:INFO:plot_model() successfully completed......................................
2025-05-07 16:14:17,384:INFO:Initializing plot_model()
2025-05-07 16:14:17,384:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), plot=error, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-07 16:14:17,384:INFO:Checking exceptions
2025-05-07 16:14:17,394:INFO:Preloading libraries
2025-05-07 16:14:17,397:INFO:Copying training dataset
2025-05-07 16:14:17,397:INFO:Plot type: error
2025-05-07 16:14:17,641:INFO:Fitting Model
2025-05-07 16:14:17,642:INFO:Scoring test/hold-out set
2025-05-07 16:14:18,018:INFO:Visual Rendered Successfully
2025-05-07 16:14:18,111:INFO:plot_model() successfully completed......................................
2025-05-07 16:14:21,889:INFO:Initializing plot_model()
2025-05-07 16:14:21,890:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), plot=residuals, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-07 16:14:21,890:INFO:Checking exceptions
2025-05-07 16:14:21,897:INFO:Preloading libraries
2025-05-07 16:14:21,901:INFO:Copying training dataset
2025-05-07 16:14:21,901:INFO:Plot type: residuals
2025-05-07 16:14:22,150:INFO:Fitting Model
2025-05-07 16:14:22,230:INFO:Scoring test/hold-out set
2025-05-07 16:14:22,845:INFO:Visual Rendered Successfully
2025-05-07 16:14:22,942:INFO:plot_model() successfully completed......................................
2025-05-07 16:14:27,275:INFO:Initializing plot_model()
2025-05-07 16:14:27,275:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), plot=rfe, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-07 16:14:27,275:INFO:Checking exceptions
2025-05-07 16:14:27,283:INFO:Preloading libraries
2025-05-07 16:14:27,287:INFO:Copying training dataset
2025-05-07 16:14:27,287:INFO:Plot type: rfe
2025-05-07 16:14:27,527:INFO:Fitting Model
2025-05-07 16:14:27,602:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001230 seconds.
2025-05-07 16:14:27,602:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:27,602:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:27,603:INFO:[LightGBM] [Info] Total Bins 1120
2025-05-07 16:14:27,603:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 68
2025-05-07 16:14:27,603:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:27,752:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001625 seconds.
2025-05-07 16:14:27,753:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:27,753:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:27,753:INFO:[LightGBM] [Info] Total Bins 1118
2025-05-07 16:14:27,753:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:14:27,755:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:27,941:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001217 seconds.
2025-05-07 16:14:27,942:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:27,942:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:27,942:INFO:[LightGBM] [Info] Total Bins 1116
2025-05-07 16:14:27,943:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:14:27,943:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:28,118:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001169 seconds.
2025-05-07 16:14:28,118:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:28,118:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:28,118:INFO:[LightGBM] [Info] Total Bins 1116
2025-05-07 16:14:28,120:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:14:28,120:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:28,287:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001616 seconds.
2025-05-07 16:14:28,288:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:28,288:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:28,288:INFO:[LightGBM] [Info] Total Bins 1114
2025-05-07 16:14:28,288:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:14:28,290:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:28,456:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001172 seconds.
2025-05-07 16:14:28,456:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:28,456:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:28,456:INFO:[LightGBM] [Info] Total Bins 1114
2025-05-07 16:14:28,457:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:14:28,458:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:28,617:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001233 seconds.
2025-05-07 16:14:28,618:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:28,618:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:28,618:INFO:[LightGBM] [Info] Total Bins 1112
2025-05-07 16:14:28,618:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:14:28,620:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:28,787:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001479 seconds.
2025-05-07 16:14:28,788:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:28,788:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:28,788:INFO:[LightGBM] [Info] Total Bins 1112
2025-05-07 16:14:28,788:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:14:28,790:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:28,970:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001302 seconds.
2025-05-07 16:14:28,970:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:28,970:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:28,971:INFO:[LightGBM] [Info] Total Bins 1112
2025-05-07 16:14:28,971:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:14:28,972:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:29,120:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001385 seconds.
2025-05-07 16:14:29,120:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:29,120:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:29,121:INFO:[LightGBM] [Info] Total Bins 1110
2025-05-07 16:14:29,121:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:14:29,122:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:29,273:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001289 seconds.
2025-05-07 16:14:29,273:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:29,274:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:29,274:INFO:[LightGBM] [Info] Total Bins 1110
2025-05-07 16:14:29,274:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:14:29,275:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:29,426:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001340 seconds.
2025-05-07 16:14:29,427:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:29,427:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:29,427:INFO:[LightGBM] [Info] Total Bins 1108
2025-05-07 16:14:29,428:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:14:29,428:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:29,587:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001223 seconds.
2025-05-07 16:14:29,587:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:29,588:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:29,588:INFO:[LightGBM] [Info] Total Bins 1108
2025-05-07 16:14:29,588:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:14:29,589:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:29,731:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001328 seconds.
2025-05-07 16:14:29,732:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:29,732:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:29,732:INFO:[LightGBM] [Info] Total Bins 1106
2025-05-07 16:14:29,733:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 61
2025-05-07 16:14:29,733:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:29,878:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001048 seconds.
2025-05-07 16:14:29,880:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:29,880:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:29,880:INFO:[LightGBM] [Info] Total Bins 1104
2025-05-07 16:14:29,881:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:14:29,881:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:30,038:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001427 seconds.
2025-05-07 16:14:30,038:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:30,038:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:30,040:INFO:[LightGBM] [Info] Total Bins 1102
2025-05-07 16:14:30,040:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:14:30,041:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:30,204:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001556 seconds.
2025-05-07 16:14:30,205:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:30,205:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:30,205:INFO:[LightGBM] [Info] Total Bins 1100
2025-05-07 16:14:30,206:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 58
2025-05-07 16:14:30,206:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:30,377:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001290 seconds.
2025-05-07 16:14:30,377:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:30,378:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:30,378:INFO:[LightGBM] [Info] Total Bins 1098
2025-05-07 16:14:30,378:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 57
2025-05-07 16:14:30,380:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:30,530:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001108 seconds.
2025-05-07 16:14:30,530:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:30,530:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:30,530:INFO:[LightGBM] [Info] Total Bins 1096
2025-05-07 16:14:30,531:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 56
2025-05-07 16:14:30,531:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:30,681:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000920 seconds.
2025-05-07 16:14:30,681:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:30,681:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:30,682:INFO:[LightGBM] [Info] Total Bins 1096
2025-05-07 16:14:30,682:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 56
2025-05-07 16:14:30,682:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:30,827:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001162 seconds.
2025-05-07 16:14:30,828:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:30,828:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:30,828:INFO:[LightGBM] [Info] Total Bins 1094
2025-05-07 16:14:30,829:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 55
2025-05-07 16:14:30,829:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:31,001:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001158 seconds.
2025-05-07 16:14:31,001:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:31,001:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:31,002:INFO:[LightGBM] [Info] Total Bins 1092
2025-05-07 16:14:31,003:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:14:31,003:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:31,188:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001519 seconds.
2025-05-07 16:14:31,190:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:31,190:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:31,190:INFO:[LightGBM] [Info] Total Bins 1092
2025-05-07 16:14:31,191:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:14:31,192:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:31,347:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,002137 seconds.
2025-05-07 16:14:31,347:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:31,347:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:31,347:INFO:[LightGBM] [Info] Total Bins 1090
2025-05-07 16:14:31,348:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 53
2025-05-07 16:14:31,348:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:31,498:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,002946 seconds.
2025-05-07 16:14:31,498:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:14:31,498:INFO:[LightGBM] [Info] Total Bins 1088
2025-05-07 16:14:31,499:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 52
2025-05-07 16:14:31,499:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:31,669:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,003145 seconds.
2025-05-07 16:14:31,669:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:14:31,669:INFO:[LightGBM] [Info] Total Bins 1086
2025-05-07 16:14:31,670:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 51
2025-05-07 16:14:31,670:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:31,839:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,004091 seconds.
2025-05-07 16:14:31,839:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:14:31,839:INFO:[LightGBM] [Info] Total Bins 1084
2025-05-07 16:14:31,840:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 50
2025-05-07 16:14:31,841:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:32,011:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001027 seconds.
2025-05-07 16:14:32,011:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:32,011:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:32,012:INFO:[LightGBM] [Info] Total Bins 1082
2025-05-07 16:14:32,012:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 49
2025-05-07 16:14:32,012:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:32,154:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001160 seconds.
2025-05-07 16:14:32,155:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:32,155:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:32,155:INFO:[LightGBM] [Info] Total Bins 1080
2025-05-07 16:14:32,157:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 48
2025-05-07 16:14:32,157:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:32,315:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001614 seconds.
2025-05-07 16:14:32,316:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:32,316:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:32,316:INFO:[LightGBM] [Info] Total Bins 1078
2025-05-07 16:14:32,316:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 47
2025-05-07 16:14:32,317:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:32,462:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001036 seconds.
2025-05-07 16:14:32,462:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:32,462:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:32,462:INFO:[LightGBM] [Info] Total Bins 1076
2025-05-07 16:14:32,463:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 46
2025-05-07 16:14:32,464:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:32,610:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001410 seconds.
2025-05-07 16:14:32,610:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:32,611:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:32,611:INFO:[LightGBM] [Info] Total Bins 1074
2025-05-07 16:14:32,611:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 45
2025-05-07 16:14:32,612:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:32,749:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001168 seconds.
2025-05-07 16:14:32,749:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:32,749:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:32,750:INFO:[LightGBM] [Info] Total Bins 1072
2025-05-07 16:14:32,750:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 44
2025-05-07 16:14:32,750:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:32,890:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001160 seconds.
2025-05-07 16:14:32,891:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:32,891:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:32,891:INFO:[LightGBM] [Info] Total Bins 1070
2025-05-07 16:14:32,891:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 43
2025-05-07 16:14:32,892:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:33,064:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,003806 seconds.
2025-05-07 16:14:33,064:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:14:33,064:INFO:[LightGBM] [Info] Total Bins 1068
2025-05-07 16:14:33,064:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 42
2025-05-07 16:14:33,065:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:33,227:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001235 seconds.
2025-05-07 16:14:33,227:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:33,227:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:33,228:INFO:[LightGBM] [Info] Total Bins 1066
2025-05-07 16:14:33,228:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 41
2025-05-07 16:14:33,228:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:33,359:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001183 seconds.
2025-05-07 16:14:33,360:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:33,360:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:33,360:INFO:[LightGBM] [Info] Total Bins 1064
2025-05-07 16:14:33,360:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 40
2025-05-07 16:14:33,361:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:33,495:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000936 seconds.
2025-05-07 16:14:33,496:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:33,496:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:33,496:INFO:[LightGBM] [Info] Total Bins 1062
2025-05-07 16:14:33,497:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 39
2025-05-07 16:14:33,497:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:33,638:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001350 seconds.
2025-05-07 16:14:33,639:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:33,639:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:33,639:INFO:[LightGBM] [Info] Total Bins 1060
2025-05-07 16:14:33,639:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 38
2025-05-07 16:14:33,639:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:33,788:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001008 seconds.
2025-05-07 16:14:33,788:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:33,789:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:33,789:INFO:[LightGBM] [Info] Total Bins 1058
2025-05-07 16:14:33,789:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 37
2025-05-07 16:14:33,789:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:33,918:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000642 seconds.
2025-05-07 16:14:33,919:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:33,919:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:33,919:INFO:[LightGBM] [Info] Total Bins 1056
2025-05-07 16:14:33,919:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 36
2025-05-07 16:14:33,920:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:34,069:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000821 seconds.
2025-05-07 16:14:34,070:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:34,070:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:34,070:INFO:[LightGBM] [Info] Total Bins 1054
2025-05-07 16:14:34,071:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 35
2025-05-07 16:14:34,071:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:34,210:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000878 seconds.
2025-05-07 16:14:34,210:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:34,210:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:34,211:INFO:[LightGBM] [Info] Total Bins 1052
2025-05-07 16:14:34,211:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 34
2025-05-07 16:14:34,211:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:34,374:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001048 seconds.
2025-05-07 16:14:34,375:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:34,375:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:34,375:INFO:[LightGBM] [Info] Total Bins 1050
2025-05-07 16:14:34,375:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 33
2025-05-07 16:14:34,376:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:34,518:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000820 seconds.
2025-05-07 16:14:34,518:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:34,519:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:34,519:INFO:[LightGBM] [Info] Total Bins 1048
2025-05-07 16:14:34,519:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 32
2025-05-07 16:14:34,519:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:34,648:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000777 seconds.
2025-05-07 16:14:34,648:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:34,649:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:34,649:INFO:[LightGBM] [Info] Total Bins 1046
2025-05-07 16:14:34,649:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 31
2025-05-07 16:14:34,649:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:34,778:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001237 seconds.
2025-05-07 16:14:34,778:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:34,778:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:34,779:INFO:[LightGBM] [Info] Total Bins 1044
2025-05-07 16:14:34,779:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 30
2025-05-07 16:14:34,779:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:34,915:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001174 seconds.
2025-05-07 16:14:34,916:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:34,916:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:34,916:INFO:[LightGBM] [Info] Total Bins 1042
2025-05-07 16:14:34,916:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 29
2025-05-07 16:14:34,917:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:35,044:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001227 seconds.
2025-05-07 16:14:35,045:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:35,045:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:35,045:INFO:[LightGBM] [Info] Total Bins 1040
2025-05-07 16:14:35,045:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 28
2025-05-07 16:14:35,046:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:35,209:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001479 seconds.
2025-05-07 16:14:35,209:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:35,209:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:35,210:INFO:[LightGBM] [Info] Total Bins 1038
2025-05-07 16:14:35,210:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 27
2025-05-07 16:14:35,210:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:35,345:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001237 seconds.
2025-05-07 16:14:35,346:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:35,346:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:35,346:INFO:[LightGBM] [Info] Total Bins 1036
2025-05-07 16:14:35,346:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 26
2025-05-07 16:14:35,347:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:35,477:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001797 seconds.
2025-05-07 16:14:35,477:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:35,477:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:35,478:INFO:[LightGBM] [Info] Total Bins 1034
2025-05-07 16:14:35,478:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 25
2025-05-07 16:14:35,478:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:35,602:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000981 seconds.
2025-05-07 16:14:35,603:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:35,603:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:35,603:INFO:[LightGBM] [Info] Total Bins 1032
2025-05-07 16:14:35,604:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 24
2025-05-07 16:14:35,605:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:35,729:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000793 seconds.
2025-05-07 16:14:35,729:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:35,729:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:35,730:INFO:[LightGBM] [Info] Total Bins 1030
2025-05-07 16:14:35,730:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 23
2025-05-07 16:14:35,730:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:35,849:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000813 seconds.
2025-05-07 16:14:35,850:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:35,850:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:35,850:INFO:[LightGBM] [Info] Total Bins 1028
2025-05-07 16:14:35,850:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 22
2025-05-07 16:14:35,851:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:35,977:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000993 seconds.
2025-05-07 16:14:35,977:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:35,977:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:35,978:INFO:[LightGBM] [Info] Total Bins 1026
2025-05-07 16:14:35,978:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 21
2025-05-07 16:14:35,978:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:36,103:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000900 seconds.
2025-05-07 16:14:36,104:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:36,104:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:36,105:INFO:[LightGBM] [Info] Total Bins 1024
2025-05-07 16:14:36,105:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 20
2025-05-07 16:14:36,105:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:36,219:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000750 seconds.
2025-05-07 16:14:36,219:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:36,221:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:36,221:INFO:[LightGBM] [Info] Total Bins 1022
2025-05-07 16:14:36,222:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 19
2025-05-07 16:14:36,222:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:36,344:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000994 seconds.
2025-05-07 16:14:36,345:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:36,345:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:36,345:INFO:[LightGBM] [Info] Total Bins 1020
2025-05-07 16:14:36,345:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 18
2025-05-07 16:14:36,346:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:36,486:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001095 seconds.
2025-05-07 16:14:36,486:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:36,486:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:36,487:INFO:[LightGBM] [Info] Total Bins 1018
2025-05-07 16:14:36,487:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 17
2025-05-07 16:14:36,487:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:36,612:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001023 seconds.
2025-05-07 16:14:36,612:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:36,612:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:36,612:INFO:[LightGBM] [Info] Total Bins 1016
2025-05-07 16:14:36,614:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 16
2025-05-07 16:14:36,614:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:36,729:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001178 seconds.
2025-05-07 16:14:36,729:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:36,729:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:36,731:INFO:[LightGBM] [Info] Total Bins 1014
2025-05-07 16:14:36,731:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 15
2025-05-07 16:14:36,731:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:36,843:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000643 seconds.
2025-05-07 16:14:36,843:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:36,844:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:36,844:INFO:[LightGBM] [Info] Total Bins 1012
2025-05-07 16:14:36,844:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 14
2025-05-07 16:14:36,844:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:36,960:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000763 seconds.
2025-05-07 16:14:36,961:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:36,961:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:36,961:INFO:[LightGBM] [Info] Total Bins 1010
2025-05-07 16:14:36,961:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 13
2025-05-07 16:14:36,961:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:37,081:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000497 seconds.
2025-05-07 16:14:37,081:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:37,082:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:37,082:INFO:[LightGBM] [Info] Total Bins 1008
2025-05-07 16:14:37,082:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 12
2025-05-07 16:14:37,082:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:37,195:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000740 seconds.
2025-05-07 16:14:37,195:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:37,195:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:37,195:INFO:[LightGBM] [Info] Total Bins 1006
2025-05-07 16:14:37,196:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 11
2025-05-07 16:14:37,196:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:37,300:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000745 seconds.
2025-05-07 16:14:37,300:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:37,300:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:37,301:INFO:[LightGBM] [Info] Total Bins 1004
2025-05-07 16:14:37,301:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 10
2025-05-07 16:14:37,301:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:37,415:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000576 seconds.
2025-05-07 16:14:37,416:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:37,416:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:37,416:INFO:[LightGBM] [Info] Total Bins 1002
2025-05-07 16:14:37,416:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 9
2025-05-07 16:14:37,417:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:37,526:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000178 seconds.
2025-05-07 16:14:37,526:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:37,526:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:37,527:INFO:[LightGBM] [Info] Total Bins 1000
2025-05-07 16:14:37,527:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 8
2025-05-07 16:14:37,528:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:37,627:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000203 seconds.
2025-05-07 16:14:37,627:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:37,627:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:37,627:INFO:[LightGBM] [Info] Total Bins 994
2025-05-07 16:14:37,628:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 7
2025-05-07 16:14:37,628:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:37,723:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000148 seconds.
2025-05-07 16:14:37,724:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:37,724:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:37,724:INFO:[LightGBM] [Info] Total Bins 977
2025-05-07 16:14:37,725:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 6
2025-05-07 16:14:37,725:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:37,822:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000100 seconds.
2025-05-07 16:14:37,822:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:37,824:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:37,824:INFO:[LightGBM] [Info] Total Bins 962
2025-05-07 16:14:37,824:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 5
2025-05-07 16:14:37,824:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:37,916:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000088 seconds.
2025-05-07 16:14:37,916:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:37,917:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:37,917:INFO:[LightGBM] [Info] Total Bins 938
2025-05-07 16:14:37,917:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 4
2025-05-07 16:14:37,917:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:38,007:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000262 seconds.
2025-05-07 16:14:38,007:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:38,007:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:38,008:INFO:[LightGBM] [Info] Total Bins 684
2025-05-07 16:14:38,008:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 3
2025-05-07 16:14:38,008:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:38,090:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000068 seconds.
2025-05-07 16:14:38,090:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:38,090:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:38,090:INFO:[LightGBM] [Info] Total Bins 508
2025-05-07 16:14:38,090:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 2
2025-05-07 16:14:38,091:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:38,171:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000079 seconds.
2025-05-07 16:14:38,171:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:38,171:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:38,171:INFO:[LightGBM] [Info] Total Bins 253
2025-05-07 16:14:38,172:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 1
2025-05-07 16:14:38,172:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:14:38,306:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001078 seconds.
2025-05-07 16:14:38,306:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:38,307:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:38,307:INFO:[LightGBM] [Info] Total Bins 1120
2025-05-07 16:14:38,307:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 68
2025-05-07 16:14:38,308:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:38,474:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001141 seconds.
2025-05-07 16:14:38,474:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:38,475:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:38,475:INFO:[LightGBM] [Info] Total Bins 1118
2025-05-07 16:14:38,475:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:14:38,476:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:38,654:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001403 seconds.
2025-05-07 16:14:38,654:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:38,654:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:38,655:INFO:[LightGBM] [Info] Total Bins 1116
2025-05-07 16:14:38,655:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:14:38,655:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:38,821:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001280 seconds.
2025-05-07 16:14:38,821:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:38,822:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:38,822:INFO:[LightGBM] [Info] Total Bins 1114
2025-05-07 16:14:38,822:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:14:38,823:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:38,983:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000936 seconds.
2025-05-07 16:14:38,983:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:38,983:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:38,983:INFO:[LightGBM] [Info] Total Bins 1114
2025-05-07 16:14:38,983:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:14:38,984:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:39,166:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001414 seconds.
2025-05-07 16:14:39,167:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:39,167:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:39,167:INFO:[LightGBM] [Info] Total Bins 1114
2025-05-07 16:14:39,168:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:14:39,169:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:39,352:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001220 seconds.
2025-05-07 16:14:39,352:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:39,352:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:39,353:INFO:[LightGBM] [Info] Total Bins 1114
2025-05-07 16:14:39,353:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:14:39,354:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:39,519:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001033 seconds.
2025-05-07 16:14:39,521:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:39,521:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:39,521:INFO:[LightGBM] [Info] Total Bins 1112
2025-05-07 16:14:39,522:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:14:39,522:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:39,684:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001102 seconds.
2025-05-07 16:14:39,685:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:39,685:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:39,685:INFO:[LightGBM] [Info] Total Bins 1112
2025-05-07 16:14:39,686:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:14:39,686:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:39,846:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,002272 seconds.
2025-05-07 16:14:39,847:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:39,847:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:39,847:INFO:[LightGBM] [Info] Total Bins 1110
2025-05-07 16:14:39,848:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:14:39,848:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:40,007:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001939 seconds.
2025-05-07 16:14:40,008:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:40,008:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:40,008:INFO:[LightGBM] [Info] Total Bins 1110
2025-05-07 16:14:40,009:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:14:40,009:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:40,181:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000986 seconds.
2025-05-07 16:14:40,182:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:40,182:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:40,182:INFO:[LightGBM] [Info] Total Bins 1108
2025-05-07 16:14:40,182:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:14:40,183:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:40,349:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001146 seconds.
2025-05-07 16:14:40,349:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:40,349:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:40,349:INFO:[LightGBM] [Info] Total Bins 1108
2025-05-07 16:14:40,349:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:14:40,351:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:40,506:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001156 seconds.
2025-05-07 16:14:40,506:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:40,506:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:40,507:INFO:[LightGBM] [Info] Total Bins 1106
2025-05-07 16:14:40,507:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 61
2025-05-07 16:14:40,509:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:40,684:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001080 seconds.
2025-05-07 16:14:40,684:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:40,684:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:40,685:INFO:[LightGBM] [Info] Total Bins 1104
2025-05-07 16:14:40,685:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:14:40,685:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:40,837:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001701 seconds.
2025-05-07 16:14:40,838:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:40,838:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:40,838:INFO:[LightGBM] [Info] Total Bins 1102
2025-05-07 16:14:40,839:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:14:40,839:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:40,988:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001072 seconds.
2025-05-07 16:14:40,988:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:40,988:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:40,989:INFO:[LightGBM] [Info] Total Bins 1102
2025-05-07 16:14:40,989:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:14:40,989:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:41,146:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001101 seconds.
2025-05-07 16:14:41,146:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:41,146:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:41,146:INFO:[LightGBM] [Info] Total Bins 1102
2025-05-07 16:14:41,147:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:14:41,147:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:41,301:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001257 seconds.
2025-05-07 16:14:41,301:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:41,301:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:41,301:INFO:[LightGBM] [Info] Total Bins 1100
2025-05-07 16:14:41,302:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 58
2025-05-07 16:14:41,303:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:41,449:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001227 seconds.
2025-05-07 16:14:41,449:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:41,449:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:41,451:INFO:[LightGBM] [Info] Total Bins 1098
2025-05-07 16:14:41,451:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 57
2025-05-07 16:14:41,451:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:41,601:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001335 seconds.
2025-05-07 16:14:41,601:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:41,601:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:41,601:INFO:[LightGBM] [Info] Total Bins 1096
2025-05-07 16:14:41,602:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 56
2025-05-07 16:14:41,603:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:41,747:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001406 seconds.
2025-05-07 16:14:41,747:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:41,747:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:41,748:INFO:[LightGBM] [Info] Total Bins 1094
2025-05-07 16:14:41,748:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 55
2025-05-07 16:14:41,748:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:41,899:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001226 seconds.
2025-05-07 16:14:41,899:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:41,901:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:41,901:INFO:[LightGBM] [Info] Total Bins 1092
2025-05-07 16:14:41,901:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:14:41,902:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:42,057:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001238 seconds.
2025-05-07 16:14:42,057:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:42,057:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:42,058:INFO:[LightGBM] [Info] Total Bins 1090
2025-05-07 16:14:42,058:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 53
2025-05-07 16:14:42,058:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:42,197:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000843 seconds.
2025-05-07 16:14:42,197:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:42,198:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:42,198:INFO:[LightGBM] [Info] Total Bins 1088
2025-05-07 16:14:42,198:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 52
2025-05-07 16:14:42,199:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:42,357:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001226 seconds.
2025-05-07 16:14:42,357:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:42,357:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:42,358:INFO:[LightGBM] [Info] Total Bins 1086
2025-05-07 16:14:42,358:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 51
2025-05-07 16:14:42,359:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:42,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001082 seconds.
2025-05-07 16:14:42,506:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:42,506:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:42,506:INFO:[LightGBM] [Info] Total Bins 1084
2025-05-07 16:14:42,506:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 50
2025-05-07 16:14:42,507:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:42,651:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000795 seconds.
2025-05-07 16:14:42,652:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:42,652:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:42,652:INFO:[LightGBM] [Info] Total Bins 1082
2025-05-07 16:14:42,652:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 49
2025-05-07 16:14:42,653:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:42,823:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,002196 seconds.
2025-05-07 16:14:42,823:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:42,823:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:42,824:INFO:[LightGBM] [Info] Total Bins 1080
2025-05-07 16:14:42,824:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 48
2025-05-07 16:14:42,825:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:42,966:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001165 seconds.
2025-05-07 16:14:42,966:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:42,966:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:42,967:INFO:[LightGBM] [Info] Total Bins 1078
2025-05-07 16:14:42,967:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 47
2025-05-07 16:14:42,968:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:43,124:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001287 seconds.
2025-05-07 16:14:43,125:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:43,125:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:43,125:INFO:[LightGBM] [Info] Total Bins 1076
2025-05-07 16:14:43,126:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 46
2025-05-07 16:14:43,126:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:43,291:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000928 seconds.
2025-05-07 16:14:43,291:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:43,292:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:43,292:INFO:[LightGBM] [Info] Total Bins 1074
2025-05-07 16:14:43,292:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 45
2025-05-07 16:14:43,293:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:43,431:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001103 seconds.
2025-05-07 16:14:43,432:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:43,432:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:43,432:INFO:[LightGBM] [Info] Total Bins 1072
2025-05-07 16:14:43,432:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 44
2025-05-07 16:14:43,433:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:43,574:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001427 seconds.
2025-05-07 16:14:43,574:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:43,576:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:43,576:INFO:[LightGBM] [Info] Total Bins 1070
2025-05-07 16:14:43,576:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 43
2025-05-07 16:14:43,576:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:43,708:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001022 seconds.
2025-05-07 16:14:43,708:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:43,708:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:43,709:INFO:[LightGBM] [Info] Total Bins 1068
2025-05-07 16:14:43,709:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 42
2025-05-07 16:14:43,709:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:43,847:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001271 seconds.
2025-05-07 16:14:43,848:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:43,848:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:43,848:INFO:[LightGBM] [Info] Total Bins 1066
2025-05-07 16:14:43,848:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 41
2025-05-07 16:14:43,849:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:44,007:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001304 seconds.
2025-05-07 16:14:44,007:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:44,007:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:44,008:INFO:[LightGBM] [Info] Total Bins 1064
2025-05-07 16:14:44,008:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 40
2025-05-07 16:14:44,008:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:44,148:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000981 seconds.
2025-05-07 16:14:44,148:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:44,148:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:44,148:INFO:[LightGBM] [Info] Total Bins 1062
2025-05-07 16:14:44,149:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 39
2025-05-07 16:14:44,149:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:44,294:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,006041 seconds.
2025-05-07 16:14:44,294:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:14:44,295:INFO:[LightGBM] [Info] Total Bins 1060
2025-05-07 16:14:44,295:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 38
2025-05-07 16:14:44,295:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:44,455:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001144 seconds.
2025-05-07 16:14:44,455:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:44,455:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:44,455:INFO:[LightGBM] [Info] Total Bins 1058
2025-05-07 16:14:44,456:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 37
2025-05-07 16:14:44,457:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:44,599:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001015 seconds.
2025-05-07 16:14:44,599:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:44,600:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:44,600:INFO:[LightGBM] [Info] Total Bins 1056
2025-05-07 16:14:44,600:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 36
2025-05-07 16:14:44,601:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:44,734:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001046 seconds.
2025-05-07 16:14:44,735:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:44,735:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:44,736:INFO:[LightGBM] [Info] Total Bins 1054
2025-05-07 16:14:44,736:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 35
2025-05-07 16:14:44,736:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:44,893:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000916 seconds.
2025-05-07 16:14:44,894:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:44,894:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:44,895:INFO:[LightGBM] [Info] Total Bins 1052
2025-05-07 16:14:44,895:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 34
2025-05-07 16:14:44,895:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:45,035:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001039 seconds.
2025-05-07 16:14:45,036:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:45,036:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:45,036:INFO:[LightGBM] [Info] Total Bins 1050
2025-05-07 16:14:45,037:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 33
2025-05-07 16:14:45,037:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:45,175:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001299 seconds.
2025-05-07 16:14:45,175:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:45,176:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:45,176:INFO:[LightGBM] [Info] Total Bins 1048
2025-05-07 16:14:45,176:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 32
2025-05-07 16:14:45,176:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:45,308:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001140 seconds.
2025-05-07 16:14:45,309:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:45,309:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:45,309:INFO:[LightGBM] [Info] Total Bins 1046
2025-05-07 16:14:45,309:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 31
2025-05-07 16:14:45,310:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:45,434:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000913 seconds.
2025-05-07 16:14:45,434:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:45,435:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:45,435:INFO:[LightGBM] [Info] Total Bins 1044
2025-05-07 16:14:45,435:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 30
2025-05-07 16:14:45,436:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:45,577:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001299 seconds.
2025-05-07 16:14:45,578:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:45,578:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:45,578:INFO:[LightGBM] [Info] Total Bins 1042
2025-05-07 16:14:45,579:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 29
2025-05-07 16:14:45,579:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:45,707:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001262 seconds.
2025-05-07 16:14:45,707:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:45,707:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:45,708:INFO:[LightGBM] [Info] Total Bins 1040
2025-05-07 16:14:45,708:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 28
2025-05-07 16:14:45,708:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:45,834:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001037 seconds.
2025-05-07 16:14:45,834:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:45,834:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:45,835:INFO:[LightGBM] [Info] Total Bins 1038
2025-05-07 16:14:45,835:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 27
2025-05-07 16:14:45,836:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:45,962:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000912 seconds.
2025-05-07 16:14:45,963:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:45,963:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:45,963:INFO:[LightGBM] [Info] Total Bins 1036
2025-05-07 16:14:45,963:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 26
2025-05-07 16:14:45,964:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:46,099:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000811 seconds.
2025-05-07 16:14:46,099:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:46,099:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:46,099:INFO:[LightGBM] [Info] Total Bins 1034
2025-05-07 16:14:46,100:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 25
2025-05-07 16:14:46,100:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:46,235:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001420 seconds.
2025-05-07 16:14:46,235:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:46,235:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:46,236:INFO:[LightGBM] [Info] Total Bins 1032
2025-05-07 16:14:46,236:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 24
2025-05-07 16:14:46,236:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:46,374:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001284 seconds.
2025-05-07 16:14:46,375:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:46,375:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:46,375:INFO:[LightGBM] [Info] Total Bins 1030
2025-05-07 16:14:46,375:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 23
2025-05-07 16:14:46,376:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:46,501:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001709 seconds.
2025-05-07 16:14:46,501:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:46,501:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:46,502:INFO:[LightGBM] [Info] Total Bins 1028
2025-05-07 16:14:46,502:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 22
2025-05-07 16:14:46,502:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:46,627:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001710 seconds.
2025-05-07 16:14:46,627:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:46,627:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:46,627:INFO:[LightGBM] [Info] Total Bins 1026
2025-05-07 16:14:46,628:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 21
2025-05-07 16:14:46,628:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:46,748:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001004 seconds.
2025-05-07 16:14:46,748:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:46,748:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:46,749:INFO:[LightGBM] [Info] Total Bins 1024
2025-05-07 16:14:46,749:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 20
2025-05-07 16:14:46,749:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:46,877:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000953 seconds.
2025-05-07 16:14:46,877:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:46,877:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:46,878:INFO:[LightGBM] [Info] Total Bins 1022
2025-05-07 16:14:46,878:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 19
2025-05-07 16:14:46,878:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:47,005:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001103 seconds.
2025-05-07 16:14:47,006:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:47,006:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:47,006:INFO:[LightGBM] [Info] Total Bins 1020
2025-05-07 16:14:47,007:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 18
2025-05-07 16:14:47,007:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:47,137:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000970 seconds.
2025-05-07 16:14:47,137:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:47,137:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:47,138:INFO:[LightGBM] [Info] Total Bins 1018
2025-05-07 16:14:47,138:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 17
2025-05-07 16:14:47,138:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:47,278:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,002570 seconds.
2025-05-07 16:14:47,278:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:14:47,279:INFO:[LightGBM] [Info] Total Bins 1016
2025-05-07 16:14:47,279:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 16
2025-05-07 16:14:47,279:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:47,429:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000884 seconds.
2025-05-07 16:14:47,430:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:47,430:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:47,430:INFO:[LightGBM] [Info] Total Bins 1014
2025-05-07 16:14:47,430:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 15
2025-05-07 16:14:47,430:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:47,543:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001754 seconds.
2025-05-07 16:14:47,543:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:47,544:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:47,544:INFO:[LightGBM] [Info] Total Bins 1012
2025-05-07 16:14:47,544:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 14
2025-05-07 16:14:47,545:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:47,659:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001305 seconds.
2025-05-07 16:14:47,659:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:47,660:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:47,660:INFO:[LightGBM] [Info] Total Bins 1010
2025-05-07 16:14:47,660:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 13
2025-05-07 16:14:47,660:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:47,769:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000761 seconds.
2025-05-07 16:14:47,769:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:47,770:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:47,770:INFO:[LightGBM] [Info] Total Bins 1008
2025-05-07 16:14:47,770:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 12
2025-05-07 16:14:47,770:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:47,888:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000779 seconds.
2025-05-07 16:14:47,888:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:47,888:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:47,888:INFO:[LightGBM] [Info] Total Bins 1006
2025-05-07 16:14:47,889:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 11
2025-05-07 16:14:47,890:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:48,000:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000705 seconds.
2025-05-07 16:14:48,002:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:48,002:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:48,002:INFO:[LightGBM] [Info] Total Bins 1004
2025-05-07 16:14:48,003:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 10
2025-05-07 16:14:48,003:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:48,116:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000188 seconds.
2025-05-07 16:14:48,116:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:48,116:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:48,117:INFO:[LightGBM] [Info] Total Bins 1002
2025-05-07 16:14:48,117:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 9
2025-05-07 16:14:48,117:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:48,227:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000701 seconds.
2025-05-07 16:14:48,227:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:14:48,228:INFO:[LightGBM] [Info] Total Bins 1000
2025-05-07 16:14:48,228:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 8
2025-05-07 16:14:48,228:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:48,325:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000202 seconds.
2025-05-07 16:14:48,325:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:48,325:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:48,325:INFO:[LightGBM] [Info] Total Bins 994
2025-05-07 16:14:48,326:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 7
2025-05-07 16:14:48,326:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:48,442:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000179 seconds.
2025-05-07 16:14:48,442:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:48,442:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:48,444:INFO:[LightGBM] [Info] Total Bins 977
2025-05-07 16:14:48,444:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 6
2025-05-07 16:14:48,444:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:48,542:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000399 seconds.
2025-05-07 16:14:48,543:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:14:48,543:INFO:[LightGBM] [Info] Total Bins 962
2025-05-07 16:14:48,543:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 5
2025-05-07 16:14:48,543:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:48,632:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000091 seconds.
2025-05-07 16:14:48,632:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:48,632:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:48,632:INFO:[LightGBM] [Info] Total Bins 938
2025-05-07 16:14:48,632:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 4
2025-05-07 16:14:48,632:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:48,723:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000115 seconds.
2025-05-07 16:14:48,723:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:48,724:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:48,724:INFO:[LightGBM] [Info] Total Bins 684
2025-05-07 16:14:48,724:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 3
2025-05-07 16:14:48,724:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:48,810:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000091 seconds.
2025-05-07 16:14:48,810:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:48,810:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:48,810:INFO:[LightGBM] [Info] Total Bins 509
2025-05-07 16:14:48,810:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 2
2025-05-07 16:14:48,812:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:48,891:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000063 seconds.
2025-05-07 16:14:48,892:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:48,892:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:48,892:INFO:[LightGBM] [Info] Total Bins 254
2025-05-07 16:14:48,893:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 1
2025-05-07 16:14:48,893:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:14:49,057:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001380 seconds.
2025-05-07 16:14:49,058:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:49,058:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:49,058:INFO:[LightGBM] [Info] Total Bins 1122
2025-05-07 16:14:49,059:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 70
2025-05-07 16:14:49,059:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:49,216:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001115 seconds.
2025-05-07 16:14:49,216:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:49,217:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:49,217:INFO:[LightGBM] [Info] Total Bins 1120
2025-05-07 16:14:49,217:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 69
2025-05-07 16:14:49,218:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:49,378:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001415 seconds.
2025-05-07 16:14:49,379:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:49,379:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:49,379:INFO:[LightGBM] [Info] Total Bins 1120
2025-05-07 16:14:49,380:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 69
2025-05-07 16:14:49,380:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:49,544:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001907 seconds.
2025-05-07 16:14:49,544:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:49,544:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:49,544:INFO:[LightGBM] [Info] Total Bins 1118
2025-05-07 16:14:49,545:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 68
2025-05-07 16:14:49,545:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:49,700:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001013 seconds.
2025-05-07 16:14:49,700:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:49,700:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:49,700:INFO:[LightGBM] [Info] Total Bins 1118
2025-05-07 16:14:49,700:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 68
2025-05-07 16:14:49,702:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:49,853:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001465 seconds.
2025-05-07 16:14:49,853:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:49,853:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:49,853:INFO:[LightGBM] [Info] Total Bins 1116
2025-05-07 16:14:49,853:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:14:49,854:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:50,037:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,004537 seconds.
2025-05-07 16:14:50,037:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:14:50,037:INFO:[LightGBM] [Info] Total Bins 1114
2025-05-07 16:14:50,038:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:14:50,038:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:50,253:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001601 seconds.
2025-05-07 16:14:50,253:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:50,254:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:50,254:INFO:[LightGBM] [Info] Total Bins 1112
2025-05-07 16:14:50,254:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:14:50,254:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:50,438:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001099 seconds.
2025-05-07 16:14:50,439:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:50,439:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:50,439:INFO:[LightGBM] [Info] Total Bins 1110
2025-05-07 16:14:50,439:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:14:50,440:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:50,613:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001086 seconds.
2025-05-07 16:14:50,613:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:50,614:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:50,614:INFO:[LightGBM] [Info] Total Bins 1108
2025-05-07 16:14:50,614:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:14:50,615:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:50,792:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001556 seconds.
2025-05-07 16:14:50,793:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:50,793:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:50,793:INFO:[LightGBM] [Info] Total Bins 1106
2025-05-07 16:14:50,793:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:14:50,794:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:50,968:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001260 seconds.
2025-05-07 16:14:50,968:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:50,969:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:50,969:INFO:[LightGBM] [Info] Total Bins 1104
2025-05-07 16:14:50,970:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 61
2025-05-07 16:14:50,970:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:51,169:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001512 seconds.
2025-05-07 16:14:51,170:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:51,170:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:51,170:INFO:[LightGBM] [Info] Total Bins 1102
2025-05-07 16:14:51,170:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:14:51,172:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:51,353:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001354 seconds.
2025-05-07 16:14:51,354:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:51,354:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:51,354:INFO:[LightGBM] [Info] Total Bins 1102
2025-05-07 16:14:51,355:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:14:51,355:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:51,531:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001495 seconds.
2025-05-07 16:14:51,531:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:51,532:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:51,532:INFO:[LightGBM] [Info] Total Bins 1102
2025-05-07 16:14:51,532:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:14:51,533:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:51,688:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001174 seconds.
2025-05-07 16:14:51,688:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:51,688:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:51,689:INFO:[LightGBM] [Info] Total Bins 1102
2025-05-07 16:14:51,689:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:14:51,690:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:51,837:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,005136 seconds.
2025-05-07 16:14:51,837:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:14:51,837:INFO:[LightGBM] [Info] Total Bins 1100
2025-05-07 16:14:51,837:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:14:51,838:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:52,021:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001454 seconds.
2025-05-07 16:14:52,021:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:52,022:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:52,022:INFO:[LightGBM] [Info] Total Bins 1100
2025-05-07 16:14:52,022:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:14:52,023:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:52,200:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001069 seconds.
2025-05-07 16:14:52,201:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:52,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:52,201:INFO:[LightGBM] [Info] Total Bins 1098
2025-05-07 16:14:52,201:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 58
2025-05-07 16:14:52,202:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:52,403:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001204 seconds.
2025-05-07 16:14:52,404:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:52,404:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:52,405:INFO:[LightGBM] [Info] Total Bins 1096
2025-05-07 16:14:52,405:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 57
2025-05-07 16:14:52,405:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:52,566:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001303 seconds.
2025-05-07 16:14:52,566:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:52,566:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:52,566:INFO:[LightGBM] [Info] Total Bins 1094
2025-05-07 16:14:52,567:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 56
2025-05-07 16:14:52,567:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:52,717:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001271 seconds.
2025-05-07 16:14:52,717:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:52,717:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:52,718:INFO:[LightGBM] [Info] Total Bins 1092
2025-05-07 16:14:52,718:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 55
2025-05-07 16:14:52,719:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:52,882:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001435 seconds.
2025-05-07 16:14:52,882:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:52,882:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:52,882:INFO:[LightGBM] [Info] Total Bins 1090
2025-05-07 16:14:52,882:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:14:52,884:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:53,051:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001375 seconds.
2025-05-07 16:14:53,051:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:53,051:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:53,052:INFO:[LightGBM] [Info] Total Bins 1088
2025-05-07 16:14:53,052:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 53
2025-05-07 16:14:53,052:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:53,236:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001208 seconds.
2025-05-07 16:14:53,237:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:53,237:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:53,237:INFO:[LightGBM] [Info] Total Bins 1086
2025-05-07 16:14:53,237:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 52
2025-05-07 16:14:53,238:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:53,400:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001545 seconds.
2025-05-07 16:14:53,401:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:53,401:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:53,401:INFO:[LightGBM] [Info] Total Bins 1084
2025-05-07 16:14:53,401:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 51
2025-05-07 16:14:53,402:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:53,571:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001212 seconds.
2025-05-07 16:14:53,571:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:53,571:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:53,572:INFO:[LightGBM] [Info] Total Bins 1082
2025-05-07 16:14:53,572:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 50
2025-05-07 16:14:53,573:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:53,724:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001469 seconds.
2025-05-07 16:14:53,724:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:53,725:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:53,725:INFO:[LightGBM] [Info] Total Bins 1080
2025-05-07 16:14:53,725:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 49
2025-05-07 16:14:53,726:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:53,889:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001345 seconds.
2025-05-07 16:14:53,889:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:53,889:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:53,890:INFO:[LightGBM] [Info] Total Bins 1078
2025-05-07 16:14:53,890:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 48
2025-05-07 16:14:53,890:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:54,050:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001435 seconds.
2025-05-07 16:14:54,050:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:54,050:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:54,050:INFO:[LightGBM] [Info] Total Bins 1076
2025-05-07 16:14:54,050:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 47
2025-05-07 16:14:54,052:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:54,212:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000985 seconds.
2025-05-07 16:14:54,212:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:54,212:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:54,212:INFO:[LightGBM] [Info] Total Bins 1074
2025-05-07 16:14:54,212:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 46
2025-05-07 16:14:54,214:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:54,375:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001354 seconds.
2025-05-07 16:14:54,375:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:54,375:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:54,376:INFO:[LightGBM] [Info] Total Bins 1072
2025-05-07 16:14:54,376:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 45
2025-05-07 16:14:54,376:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:54,534:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000980 seconds.
2025-05-07 16:14:54,534:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:54,535:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:54,535:INFO:[LightGBM] [Info] Total Bins 1070
2025-05-07 16:14:54,536:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 44
2025-05-07 16:14:54,537:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:54,693:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001742 seconds.
2025-05-07 16:14:54,693:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:54,693:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:54,694:INFO:[LightGBM] [Info] Total Bins 1068
2025-05-07 16:14:54,694:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 43
2025-05-07 16:14:54,694:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:54,850:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001115 seconds.
2025-05-07 16:14:54,851:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:54,851:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:54,851:INFO:[LightGBM] [Info] Total Bins 1066
2025-05-07 16:14:54,851:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 42
2025-05-07 16:14:54,852:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:55,004:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001083 seconds.
2025-05-07 16:14:55,005:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:55,005:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:55,006:INFO:[LightGBM] [Info] Total Bins 1064
2025-05-07 16:14:55,006:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 41
2025-05-07 16:14:55,006:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:55,162:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001140 seconds.
2025-05-07 16:14:55,162:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:55,162:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:55,162:INFO:[LightGBM] [Info] Total Bins 1062
2025-05-07 16:14:55,164:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 40
2025-05-07 16:14:55,164:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:55,346:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001027 seconds.
2025-05-07 16:14:55,347:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:55,347:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:55,347:INFO:[LightGBM] [Info] Total Bins 1060
2025-05-07 16:14:55,347:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 39
2025-05-07 16:14:55,348:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:55,500:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000673 seconds.
2025-05-07 16:14:55,501:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:55,501:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:55,501:INFO:[LightGBM] [Info] Total Bins 1058
2025-05-07 16:14:55,502:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 38
2025-05-07 16:14:55,502:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:55,665:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001167 seconds.
2025-05-07 16:14:55,665:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:55,665:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:55,666:INFO:[LightGBM] [Info] Total Bins 1056
2025-05-07 16:14:55,666:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 37
2025-05-07 16:14:55,666:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:55,821:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000944 seconds.
2025-05-07 16:14:55,821:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:55,821:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:55,821:INFO:[LightGBM] [Info] Total Bins 1054
2025-05-07 16:14:55,821:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 36
2025-05-07 16:14:55,822:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:55,981:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,004249 seconds.
2025-05-07 16:14:55,981:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:14:55,981:INFO:[LightGBM] [Info] Total Bins 1052
2025-05-07 16:14:55,981:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 35
2025-05-07 16:14:55,982:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:56,162:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000856 seconds.
2025-05-07 16:14:56,162:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:56,162:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:56,162:INFO:[LightGBM] [Info] Total Bins 1050
2025-05-07 16:14:56,164:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 34
2025-05-07 16:14:56,164:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:56,301:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001053 seconds.
2025-05-07 16:14:56,301:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:56,301:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:56,302:INFO:[LightGBM] [Info] Total Bins 1048
2025-05-07 16:14:56,302:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 33
2025-05-07 16:14:56,303:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:56,452:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001092 seconds.
2025-05-07 16:14:56,454:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:56,454:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:56,454:INFO:[LightGBM] [Info] Total Bins 1046
2025-05-07 16:14:56,455:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 32
2025-05-07 16:14:56,455:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:56,591:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,002076 seconds.
2025-05-07 16:14:56,591:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:56,591:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:56,591:INFO:[LightGBM] [Info] Total Bins 1044
2025-05-07 16:14:56,591:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 31
2025-05-07 16:14:56,592:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:56,724:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001146 seconds.
2025-05-07 16:14:56,725:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:56,725:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:56,725:INFO:[LightGBM] [Info] Total Bins 1042
2025-05-07 16:14:56,725:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 30
2025-05-07 16:14:56,726:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:56,856:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001740 seconds.
2025-05-07 16:14:56,857:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:56,857:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:56,857:INFO:[LightGBM] [Info] Total Bins 1040
2025-05-07 16:14:56,858:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 29
2025-05-07 16:14:56,858:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:56,981:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001151 seconds.
2025-05-07 16:14:56,981:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:56,981:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:56,981:INFO:[LightGBM] [Info] Total Bins 1038
2025-05-07 16:14:56,981:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 28
2025-05-07 16:14:56,982:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:57,112:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000951 seconds.
2025-05-07 16:14:57,112:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:57,112:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:57,112:INFO:[LightGBM] [Info] Total Bins 1036
2025-05-07 16:14:57,112:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 27
2025-05-07 16:14:57,114:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:57,237:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001136 seconds.
2025-05-07 16:14:57,237:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:57,238:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:57,238:INFO:[LightGBM] [Info] Total Bins 1034
2025-05-07 16:14:57,238:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 26
2025-05-07 16:14:57,238:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:57,417:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000942 seconds.
2025-05-07 16:14:57,418:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:57,418:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:57,418:INFO:[LightGBM] [Info] Total Bins 1032
2025-05-07 16:14:57,419:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 25
2025-05-07 16:14:57,419:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:57,538:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001030 seconds.
2025-05-07 16:14:57,538:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:57,538:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:57,539:INFO:[LightGBM] [Info] Total Bins 1030
2025-05-07 16:14:57,540:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 24
2025-05-07 16:14:57,540:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:57,661:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000796 seconds.
2025-05-07 16:14:57,661:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:57,661:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:57,661:INFO:[LightGBM] [Info] Total Bins 1028
2025-05-07 16:14:57,661:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 23
2025-05-07 16:14:57,662:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:57,777:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000864 seconds.
2025-05-07 16:14:57,777:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:57,777:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:57,777:INFO:[LightGBM] [Info] Total Bins 1026
2025-05-07 16:14:57,778:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 22
2025-05-07 16:14:57,778:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:57,894:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000980 seconds.
2025-05-07 16:14:57,895:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:57,895:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:57,895:INFO:[LightGBM] [Info] Total Bins 1024
2025-05-07 16:14:57,895:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 21
2025-05-07 16:14:57,896:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:58,016:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000877 seconds.
2025-05-07 16:14:58,016:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:58,016:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:58,017:INFO:[LightGBM] [Info] Total Bins 1022
2025-05-07 16:14:58,017:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 20
2025-05-07 16:14:58,017:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:58,133:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000901 seconds.
2025-05-07 16:14:58,134:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:58,134:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:58,134:INFO:[LightGBM] [Info] Total Bins 1020
2025-05-07 16:14:58,135:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 19
2025-05-07 16:14:58,135:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:58,250:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000732 seconds.
2025-05-07 16:14:58,250:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:58,250:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:58,251:INFO:[LightGBM] [Info] Total Bins 1018
2025-05-07 16:14:58,251:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 18
2025-05-07 16:14:58,251:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:58,372:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001087 seconds.
2025-05-07 16:14:58,372:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:58,372:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:58,374:INFO:[LightGBM] [Info] Total Bins 1016
2025-05-07 16:14:58,374:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 17
2025-05-07 16:14:58,374:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:58,499:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000718 seconds.
2025-05-07 16:14:58,499:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:58,499:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:58,499:INFO:[LightGBM] [Info] Total Bins 1014
2025-05-07 16:14:58,500:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 16
2025-05-07 16:14:58,500:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:58,688:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001261 seconds.
2025-05-07 16:14:58,689:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:58,689:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:58,689:INFO:[LightGBM] [Info] Total Bins 1012
2025-05-07 16:14:58,689:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 15
2025-05-07 16:14:58,690:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:58,807:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000887 seconds.
2025-05-07 16:14:58,807:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:58,808:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:58,808:INFO:[LightGBM] [Info] Total Bins 1010
2025-05-07 16:14:58,808:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 14
2025-05-07 16:14:58,808:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:58,927:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000686 seconds.
2025-05-07 16:14:58,927:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:58,927:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:58,928:INFO:[LightGBM] [Info] Total Bins 1008
2025-05-07 16:14:58,928:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 13
2025-05-07 16:14:58,928:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:59,061:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000989 seconds.
2025-05-07 16:14:59,061:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:59,061:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:59,061:INFO:[LightGBM] [Info] Total Bins 1006
2025-05-07 16:14:59,061:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 12
2025-05-07 16:14:59,062:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:59,201:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000700 seconds.
2025-05-07 16:14:59,201:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:59,202:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:59,202:INFO:[LightGBM] [Info] Total Bins 1004
2025-05-07 16:14:59,202:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 11
2025-05-07 16:14:59,202:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:59,333:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000588 seconds.
2025-05-07 16:14:59,333:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:59,333:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:59,333:INFO:[LightGBM] [Info] Total Bins 1002
2025-05-07 16:14:59,333:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 10
2025-05-07 16:14:59,333:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:59,475:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000684 seconds.
2025-05-07 16:14:59,476:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:59,476:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:59,476:INFO:[LightGBM] [Info] Total Bins 1000
2025-05-07 16:14:59,477:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 9
2025-05-07 16:14:59,477:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:59,586:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000830 seconds.
2025-05-07 16:14:59,586:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:59,586:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:59,587:INFO:[LightGBM] [Info] Total Bins 994
2025-05-07 16:14:59,587:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 8
2025-05-07 16:14:59,587:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:59,696:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000146 seconds.
2025-05-07 16:14:59,697:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:59,697:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:59,697:INFO:[LightGBM] [Info] Total Bins 992
2025-05-07 16:14:59,697:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 7
2025-05-07 16:14:59,698:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:59,799:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000141 seconds.
2025-05-07 16:14:59,800:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:14:59,800:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:14:59,800:INFO:[LightGBM] [Info] Total Bins 975
2025-05-07 16:14:59,800:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 6
2025-05-07 16:14:59,801:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:59,902:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000469 seconds.
2025-05-07 16:14:59,903:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:14:59,903:INFO:[LightGBM] [Info] Total Bins 961
2025-05-07 16:14:59,904:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 5
2025-05-07 16:14:59,904:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:14:59,997:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000313 seconds.
2025-05-07 16:14:59,998:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:14:59,998:INFO:[LightGBM] [Info] Total Bins 938
2025-05-07 16:14:59,998:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 4
2025-05-07 16:14:59,999:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:15:00,106:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000155 seconds.
2025-05-07 16:15:00,106:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:00,106:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:00,107:INFO:[LightGBM] [Info] Total Bins 684
2025-05-07 16:15:00,107:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 3
2025-05-07 16:15:00,107:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:15:00,190:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000238 seconds.
2025-05-07 16:15:00,190:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:15:00,190:INFO:[LightGBM] [Info] Total Bins 508
2025-05-07 16:15:00,191:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 2
2025-05-07 16:15:00,191:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:15:00,268:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000059 seconds.
2025-05-07 16:15:00,269:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:00,269:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:00,269:INFO:[LightGBM] [Info] Total Bins 253
2025-05-07 16:15:00,270:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 1
2025-05-07 16:15:00,270:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:15:00,423:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,003332 seconds.
2025-05-07 16:15:00,424:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:15:00,424:INFO:[LightGBM] [Info] Total Bins 1117
2025-05-07 16:15:00,424:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 68
2025-05-07 16:15:00,424:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:00,614:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001226 seconds.
2025-05-07 16:15:00,614:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:00,614:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:00,615:INFO:[LightGBM] [Info] Total Bins 1115
2025-05-07 16:15:00,615:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:15:00,615:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:00,787:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001201 seconds.
2025-05-07 16:15:00,787:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:00,787:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:00,788:INFO:[LightGBM] [Info] Total Bins 1115
2025-05-07 16:15:00,788:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:15:00,789:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:00,973:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001175 seconds.
2025-05-07 16:15:00,974:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:00,974:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:00,974:INFO:[LightGBM] [Info] Total Bins 1115
2025-05-07 16:15:00,975:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:15:00,976:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:01,130:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001174 seconds.
2025-05-07 16:15:01,130:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:01,130:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:01,131:INFO:[LightGBM] [Info] Total Bins 1113
2025-05-07 16:15:01,131:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:15:01,132:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:01,292:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001455 seconds.
2025-05-07 16:15:01,292:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:01,293:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:01,293:INFO:[LightGBM] [Info] Total Bins 1113
2025-05-07 16:15:01,294:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:15:01,294:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:01,454:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001464 seconds.
2025-05-07 16:15:01,454:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:01,455:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:01,455:INFO:[LightGBM] [Info] Total Bins 1111
2025-05-07 16:15:01,456:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:15:01,456:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:01,629:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001214 seconds.
2025-05-07 16:15:01,630:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:01,630:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:01,630:INFO:[LightGBM] [Info] Total Bins 1109
2025-05-07 16:15:01,631:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:15:01,631:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:01,783:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001021 seconds.
2025-05-07 16:15:01,784:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:01,784:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:01,784:INFO:[LightGBM] [Info] Total Bins 1109
2025-05-07 16:15:01,784:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:15:01,785:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:01,936:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,003702 seconds.
2025-05-07 16:15:01,937:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:15:01,937:INFO:[LightGBM] [Info] Total Bins 1107
2025-05-07 16:15:01,938:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:15:01,938:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:02,149:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001310 seconds.
2025-05-07 16:15:02,149:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:02,149:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:02,150:INFO:[LightGBM] [Info] Total Bins 1107
2025-05-07 16:15:02,150:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:15:02,150:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:02,305:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001162 seconds.
2025-05-07 16:15:02,305:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:02,306:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:02,306:INFO:[LightGBM] [Info] Total Bins 1107
2025-05-07 16:15:02,306:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:15:02,307:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:02,472:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001268 seconds.
2025-05-07 16:15:02,472:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:02,474:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:02,474:INFO:[LightGBM] [Info] Total Bins 1107
2025-05-07 16:15:02,474:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:15:02,475:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:02,637:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000954 seconds.
2025-05-07 16:15:02,637:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:02,638:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:02,638:INFO:[LightGBM] [Info] Total Bins 1107
2025-05-07 16:15:02,638:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:15:02,639:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:02,801:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001154 seconds.
2025-05-07 16:15:02,801:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:02,801:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:02,802:INFO:[LightGBM] [Info] Total Bins 1105
2025-05-07 16:15:02,802:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:15:02,803:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:02,971:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001273 seconds.
2025-05-07 16:15:02,972:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:02,972:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:02,972:INFO:[LightGBM] [Info] Total Bins 1103
2025-05-07 16:15:02,973:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 61
2025-05-07 16:15:02,974:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:03,132:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001105 seconds.
2025-05-07 16:15:03,132:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:03,132:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:03,132:INFO:[LightGBM] [Info] Total Bins 1101
2025-05-07 16:15:03,134:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:15:03,134:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:03,322:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001387 seconds.
2025-05-07 16:15:03,323:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:03,323:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:03,323:INFO:[LightGBM] [Info] Total Bins 1099
2025-05-07 16:15:03,324:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:15:03,324:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:03,477:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001177 seconds.
2025-05-07 16:15:03,478:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:03,478:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:03,478:INFO:[LightGBM] [Info] Total Bins 1097
2025-05-07 16:15:03,478:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 58
2025-05-07 16:15:03,479:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:03,637:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001480 seconds.
2025-05-07 16:15:03,637:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:03,637:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:03,637:INFO:[LightGBM] [Info] Total Bins 1095
2025-05-07 16:15:03,638:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 57
2025-05-07 16:15:03,638:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:03,786:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001342 seconds.
2025-05-07 16:15:03,786:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:03,787:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:03,787:INFO:[LightGBM] [Info] Total Bins 1093
2025-05-07 16:15:03,788:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 56
2025-05-07 16:15:03,788:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:03,930:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001112 seconds.
2025-05-07 16:15:03,931:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:03,931:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:03,931:INFO:[LightGBM] [Info] Total Bins 1091
2025-05-07 16:15:03,932:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 55
2025-05-07 16:15:03,932:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:04,082:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001092 seconds.
2025-05-07 16:15:04,082:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:04,083:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:04,083:INFO:[LightGBM] [Info] Total Bins 1089
2025-05-07 16:15:04,084:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:15:04,084:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:04,229:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001419 seconds.
2025-05-07 16:15:04,229:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:04,230:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:04,230:INFO:[LightGBM] [Info] Total Bins 1087
2025-05-07 16:15:04,230:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 53
2025-05-07 16:15:04,231:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:04,394:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000926 seconds.
2025-05-07 16:15:04,395:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:04,395:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:04,395:INFO:[LightGBM] [Info] Total Bins 1085
2025-05-07 16:15:04,395:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 52
2025-05-07 16:15:04,396:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:04,545:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001531 seconds.
2025-05-07 16:15:04,545:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:04,545:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:04,545:INFO:[LightGBM] [Info] Total Bins 1083
2025-05-07 16:15:04,546:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 51
2025-05-07 16:15:04,546:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:04,698:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000916 seconds.
2025-05-07 16:15:04,698:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:04,699:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:04,699:INFO:[LightGBM] [Info] Total Bins 1081
2025-05-07 16:15:04,699:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 50
2025-05-07 16:15:04,700:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:04,846:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000909 seconds.
2025-05-07 16:15:04,846:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:04,846:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:04,846:INFO:[LightGBM] [Info] Total Bins 1079
2025-05-07 16:15:04,847:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 49
2025-05-07 16:15:04,847:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:04,990:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001247 seconds.
2025-05-07 16:15:04,990:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:04,990:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:04,990:INFO:[LightGBM] [Info] Total Bins 1077
2025-05-07 16:15:04,991:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 48
2025-05-07 16:15:04,991:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:05,140:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001149 seconds.
2025-05-07 16:15:05,141:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:05,141:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:05,141:INFO:[LightGBM] [Info] Total Bins 1075
2025-05-07 16:15:05,141:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 47
2025-05-07 16:15:05,142:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:05,287:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000878 seconds.
2025-05-07 16:15:05,287:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:05,287:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:05,288:INFO:[LightGBM] [Info] Total Bins 1073
2025-05-07 16:15:05,288:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 46
2025-05-07 16:15:05,289:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:05,451:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001086 seconds.
2025-05-07 16:15:05,451:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:05,451:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:05,452:INFO:[LightGBM] [Info] Total Bins 1071
2025-05-07 16:15:05,452:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 45
2025-05-07 16:15:05,452:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:05,601:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000653 seconds.
2025-05-07 16:15:05,602:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:05,602:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:05,602:INFO:[LightGBM] [Info] Total Bins 1069
2025-05-07 16:15:05,602:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 44
2025-05-07 16:15:05,603:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:05,760:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001002 seconds.
2025-05-07 16:15:05,761:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:05,761:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:05,761:INFO:[LightGBM] [Info] Total Bins 1067
2025-05-07 16:15:05,762:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 43
2025-05-07 16:15:05,762:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:05,900:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000958 seconds.
2025-05-07 16:15:05,901:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:05,901:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:05,901:INFO:[LightGBM] [Info] Total Bins 1065
2025-05-07 16:15:05,901:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 42
2025-05-07 16:15:05,902:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:06,041:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000740 seconds.
2025-05-07 16:15:06,041:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:06,042:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:06,042:INFO:[LightGBM] [Info] Total Bins 1063
2025-05-07 16:15:06,042:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 41
2025-05-07 16:15:06,042:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:06,180:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001107 seconds.
2025-05-07 16:15:06,180:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:06,180:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:06,180:INFO:[LightGBM] [Info] Total Bins 1061
2025-05-07 16:15:06,181:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 40
2025-05-07 16:15:06,181:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:06,317:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001114 seconds.
2025-05-07 16:15:06,318:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:06,318:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:06,318:INFO:[LightGBM] [Info] Total Bins 1059
2025-05-07 16:15:06,319:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 39
2025-05-07 16:15:06,319:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:06,462:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000832 seconds.
2025-05-07 16:15:06,462:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:06,462:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:06,462:INFO:[LightGBM] [Info] Total Bins 1057
2025-05-07 16:15:06,463:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 38
2025-05-07 16:15:06,464:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:06,604:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001214 seconds.
2025-05-07 16:15:06,605:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:06,605:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:06,605:INFO:[LightGBM] [Info] Total Bins 1055
2025-05-07 16:15:06,605:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 37
2025-05-07 16:15:06,606:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:06,747:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000903 seconds.
2025-05-07 16:15:06,747:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:06,747:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:06,748:INFO:[LightGBM] [Info] Total Bins 1053
2025-05-07 16:15:06,748:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 36
2025-05-07 16:15:06,748:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:06,882:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000799 seconds.
2025-05-07 16:15:06,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:06,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:06,884:INFO:[LightGBM] [Info] Total Bins 1051
2025-05-07 16:15:06,884:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 35
2025-05-07 16:15:06,884:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:07,028:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001235 seconds.
2025-05-07 16:15:07,029:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:07,029:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:07,029:INFO:[LightGBM] [Info] Total Bins 1049
2025-05-07 16:15:07,029:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 34
2025-05-07 16:15:07,030:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:07,179:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000964 seconds.
2025-05-07 16:15:07,180:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:07,180:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:07,181:INFO:[LightGBM] [Info] Total Bins 1047
2025-05-07 16:15:07,181:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 33
2025-05-07 16:15:07,181:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:07,346:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001154 seconds.
2025-05-07 16:15:07,346:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:07,347:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:07,347:INFO:[LightGBM] [Info] Total Bins 1045
2025-05-07 16:15:07,347:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 32
2025-05-07 16:15:07,347:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:07,477:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001998 seconds.
2025-05-07 16:15:07,477:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:07,477:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:07,478:INFO:[LightGBM] [Info] Total Bins 1043
2025-05-07 16:15:07,478:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 31
2025-05-07 16:15:07,478:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:07,615:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001253 seconds.
2025-05-07 16:15:07,615:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:07,615:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:07,615:INFO:[LightGBM] [Info] Total Bins 1041
2025-05-07 16:15:07,615:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 30
2025-05-07 16:15:07,616:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:07,750:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001129 seconds.
2025-05-07 16:15:07,750:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:07,750:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:07,751:INFO:[LightGBM] [Info] Total Bins 1039
2025-05-07 16:15:07,751:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 29
2025-05-07 16:15:07,752:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:07,904:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001113 seconds.
2025-05-07 16:15:07,904:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:07,905:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:07,905:INFO:[LightGBM] [Info] Total Bins 1037
2025-05-07 16:15:07,905:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 28
2025-05-07 16:15:07,905:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:08,033:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000879 seconds.
2025-05-07 16:15:08,034:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:08,034:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:08,034:INFO:[LightGBM] [Info] Total Bins 1035
2025-05-07 16:15:08,034:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 27
2025-05-07 16:15:08,035:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:08,160:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001048 seconds.
2025-05-07 16:15:08,160:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:08,160:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:08,161:INFO:[LightGBM] [Info] Total Bins 1033
2025-05-07 16:15:08,161:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 26
2025-05-07 16:15:08,161:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:08,289:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001001 seconds.
2025-05-07 16:15:08,290:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:08,290:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:08,290:INFO:[LightGBM] [Info] Total Bins 1031
2025-05-07 16:15:08,290:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 25
2025-05-07 16:15:08,291:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:08,416:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001189 seconds.
2025-05-07 16:15:08,416:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:08,417:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:08,417:INFO:[LightGBM] [Info] Total Bins 1029
2025-05-07 16:15:08,417:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 24
2025-05-07 16:15:08,418:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:08,544:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001055 seconds.
2025-05-07 16:15:08,544:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:08,544:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:08,544:INFO:[LightGBM] [Info] Total Bins 1027
2025-05-07 16:15:08,545:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 23
2025-05-07 16:15:08,545:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:08,660:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000987 seconds.
2025-05-07 16:15:08,661:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:08,661:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:08,661:INFO:[LightGBM] [Info] Total Bins 1025
2025-05-07 16:15:08,661:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 22
2025-05-07 16:15:08,662:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:08,779:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000987 seconds.
2025-05-07 16:15:08,780:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:08,780:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:08,780:INFO:[LightGBM] [Info] Total Bins 1023
2025-05-07 16:15:08,780:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 21
2025-05-07 16:15:08,781:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:08,894:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001449 seconds.
2025-05-07 16:15:08,895:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:08,895:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:08,895:INFO:[LightGBM] [Info] Total Bins 1021
2025-05-07 16:15:08,895:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 20
2025-05-07 16:15:08,896:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:09,010:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000643 seconds.
2025-05-07 16:15:09,011:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:09,011:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:09,011:INFO:[LightGBM] [Info] Total Bins 1019
2025-05-07 16:15:09,011:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 19
2025-05-07 16:15:09,012:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:09,118:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001176 seconds.
2025-05-07 16:15:09,119:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:09,119:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:09,119:INFO:[LightGBM] [Info] Total Bins 1017
2025-05-07 16:15:09,119:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 18
2025-05-07 16:15:09,119:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:09,234:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001044 seconds.
2025-05-07 16:15:09,235:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:09,235:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:09,235:INFO:[LightGBM] [Info] Total Bins 1015
2025-05-07 16:15:09,235:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 17
2025-05-07 16:15:09,236:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:09,368:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001011 seconds.
2025-05-07 16:15:09,369:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:09,369:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:09,369:INFO:[LightGBM] [Info] Total Bins 1013
2025-05-07 16:15:09,370:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 16
2025-05-07 16:15:09,370:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:09,484:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000641 seconds.
2025-05-07 16:15:09,485:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:09,485:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:09,485:INFO:[LightGBM] [Info] Total Bins 1011
2025-05-07 16:15:09,486:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 15
2025-05-07 16:15:09,486:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:09,593:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000659 seconds.
2025-05-07 16:15:09,593:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:09,594:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:09,594:INFO:[LightGBM] [Info] Total Bins 1009
2025-05-07 16:15:09,594:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 14
2025-05-07 16:15:09,594:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:09,705:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001265 seconds.
2025-05-07 16:15:09,705:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:09,705:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:09,705:INFO:[LightGBM] [Info] Total Bins 1007
2025-05-07 16:15:09,706:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 13
2025-05-07 16:15:09,706:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:09,814:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001006 seconds.
2025-05-07 16:15:09,814:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:09,814:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:09,815:INFO:[LightGBM] [Info] Total Bins 1005
2025-05-07 16:15:09,815:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 12
2025-05-07 16:15:09,815:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:09,950:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000677 seconds.
2025-05-07 16:15:09,950:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:09,950:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:09,950:INFO:[LightGBM] [Info] Total Bins 1003
2025-05-07 16:15:09,951:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 11
2025-05-07 16:15:09,951:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:10,061:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000622 seconds.
2025-05-07 16:15:10,062:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:10,062:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:10,062:INFO:[LightGBM] [Info] Total Bins 1001
2025-05-07 16:15:10,062:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 10
2025-05-07 16:15:10,062:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:10,166:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000184 seconds.
2025-05-07 16:15:10,166:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:10,166:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:10,167:INFO:[LightGBM] [Info] Total Bins 999
2025-05-07 16:15:10,167:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 9
2025-05-07 16:15:10,167:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:10,275:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000649 seconds.
2025-05-07 16:15:10,276:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:15:10,276:INFO:[LightGBM] [Info] Total Bins 997
2025-05-07 16:15:10,276:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 8
2025-05-07 16:15:10,277:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:10,384:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000181 seconds.
2025-05-07 16:15:10,385:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:10,385:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:10,385:INFO:[LightGBM] [Info] Total Bins 991
2025-05-07 16:15:10,386:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 7
2025-05-07 16:15:10,386:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:10,496:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000139 seconds.
2025-05-07 16:15:10,497:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:10,497:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:10,497:INFO:[LightGBM] [Info] Total Bins 974
2025-05-07 16:15:10,497:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 6
2025-05-07 16:15:10,497:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:10,599:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000384 seconds.
2025-05-07 16:15:10,599:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:15:10,600:INFO:[LightGBM] [Info] Total Bins 959
2025-05-07 16:15:10,600:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 5
2025-05-07 16:15:10,600:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:10,689:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000107 seconds.
2025-05-07 16:15:10,689:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:10,689:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:10,690:INFO:[LightGBM] [Info] Total Bins 935
2025-05-07 16:15:10,690:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 4
2025-05-07 16:15:10,690:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:10,790:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000088 seconds.
2025-05-07 16:15:10,790:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:10,790:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:10,790:INFO:[LightGBM] [Info] Total Bins 681
2025-05-07 16:15:10,791:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 3
2025-05-07 16:15:10,791:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:10,874:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000091 seconds.
2025-05-07 16:15:10,875:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:10,875:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:10,875:INFO:[LightGBM] [Info] Total Bins 508
2025-05-07 16:15:10,875:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 2
2025-05-07 16:15:10,876:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:10,951:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000083 seconds.
2025-05-07 16:15:10,952:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:10,952:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:10,952:INFO:[LightGBM] [Info] Total Bins 253
2025-05-07 16:15:10,952:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 1
2025-05-07 16:15:10,952:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:15:11,085:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001650 seconds.
2025-05-07 16:15:11,086:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:11,086:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:11,086:INFO:[LightGBM] [Info] Total Bins 1119
2025-05-07 16:15:11,086:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 68
2025-05-07 16:15:11,087:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:11,255:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001300 seconds.
2025-05-07 16:15:11,255:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:11,256:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:11,256:INFO:[LightGBM] [Info] Total Bins 1117
2025-05-07 16:15:11,256:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:15:11,257:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:11,417:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001308 seconds.
2025-05-07 16:15:11,418:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:11,418:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:11,419:INFO:[LightGBM] [Info] Total Bins 1115
2025-05-07 16:15:11,419:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:15:11,419:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:11,575:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001435 seconds.
2025-05-07 16:15:11,575:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:11,575:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:11,576:INFO:[LightGBM] [Info] Total Bins 1113
2025-05-07 16:15:11,576:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:15:11,576:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:11,725:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,002316 seconds.
2025-05-07 16:15:11,725:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:11,725:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:11,726:INFO:[LightGBM] [Info] Total Bins 1111
2025-05-07 16:15:11,726:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:15:11,726:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:11,882:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001029 seconds.
2025-05-07 16:15:11,882:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:11,882:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:11,882:INFO:[LightGBM] [Info] Total Bins 1109
2025-05-07 16:15:11,884:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:15:11,884:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:12,063:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001046 seconds.
2025-05-07 16:15:12,064:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:12,064:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:12,064:INFO:[LightGBM] [Info] Total Bins 1107
2025-05-07 16:15:12,064:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:15:12,064:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:12,213:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001222 seconds.
2025-05-07 16:15:12,214:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:12,214:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:12,214:INFO:[LightGBM] [Info] Total Bins 1107
2025-05-07 16:15:12,214:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:15:12,215:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:12,381:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001221 seconds.
2025-05-07 16:15:12,381:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:12,381:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:12,382:INFO:[LightGBM] [Info] Total Bins 1107
2025-05-07 16:15:12,382:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:15:12,382:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:12,545:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001334 seconds.
2025-05-07 16:15:12,546:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:12,546:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:12,546:INFO:[LightGBM] [Info] Total Bins 1105
2025-05-07 16:15:12,546:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 61
2025-05-07 16:15:12,547:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:12,692:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001385 seconds.
2025-05-07 16:15:12,692:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:12,693:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:12,693:INFO:[LightGBM] [Info] Total Bins 1103
2025-05-07 16:15:12,693:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:15:12,694:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:12,842:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001670 seconds.
2025-05-07 16:15:12,842:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:12,842:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:12,843:INFO:[LightGBM] [Info] Total Bins 1101
2025-05-07 16:15:12,843:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:15:12,843:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:12,986:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000956 seconds.
2025-05-07 16:15:12,987:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:12,987:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:12,987:INFO:[LightGBM] [Info] Total Bins 1101
2025-05-07 16:15:12,988:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:15:12,988:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:13,147:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001330 seconds.
2025-05-07 16:15:13,147:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:13,147:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:13,148:INFO:[LightGBM] [Info] Total Bins 1101
2025-05-07 16:15:13,148:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:15:13,148:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:13,299:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001297 seconds.
2025-05-07 16:15:13,300:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:13,300:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:13,300:INFO:[LightGBM] [Info] Total Bins 1101
2025-05-07 16:15:13,301:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:15:13,301:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:13,447:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001172 seconds.
2025-05-07 16:15:13,447:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:13,447:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:13,448:INFO:[LightGBM] [Info] Total Bins 1099
2025-05-07 16:15:13,448:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 58
2025-05-07 16:15:13,448:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:13,608:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001353 seconds.
2025-05-07 16:15:13,609:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:13,609:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:13,609:INFO:[LightGBM] [Info] Total Bins 1097
2025-05-07 16:15:13,609:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 57
2025-05-07 16:15:13,610:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:13,751:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001275 seconds.
2025-05-07 16:15:13,752:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:13,752:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:13,753:INFO:[LightGBM] [Info] Total Bins 1095
2025-05-07 16:15:13,753:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 56
2025-05-07 16:15:13,753:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:13,906:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001401 seconds.
2025-05-07 16:15:13,907:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:13,907:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:13,907:INFO:[LightGBM] [Info] Total Bins 1093
2025-05-07 16:15:13,908:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 55
2025-05-07 16:15:13,909:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:14,081:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001324 seconds.
2025-05-07 16:15:14,081:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:14,081:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:14,081:INFO:[LightGBM] [Info] Total Bins 1091
2025-05-07 16:15:14,082:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:15:14,082:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:14,228:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001302 seconds.
2025-05-07 16:15:14,228:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:14,228:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:14,228:INFO:[LightGBM] [Info] Total Bins 1091
2025-05-07 16:15:14,228:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:15:14,228:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:14,392:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001409 seconds.
2025-05-07 16:15:14,394:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:14,394:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:14,394:INFO:[LightGBM] [Info] Total Bins 1091
2025-05-07 16:15:14,395:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:15:14,395:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:14,553:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000933 seconds.
2025-05-07 16:15:14,554:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:14,554:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:14,554:INFO:[LightGBM] [Info] Total Bins 1091
2025-05-07 16:15:14,554:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:15:14,555:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:14,707:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001670 seconds.
2025-05-07 16:15:14,707:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:14,707:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:14,707:INFO:[LightGBM] [Info] Total Bins 1089
2025-05-07 16:15:14,708:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 53
2025-05-07 16:15:14,708:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:14,903:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001240 seconds.
2025-05-07 16:15:14,904:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:14,904:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:14,904:INFO:[LightGBM] [Info] Total Bins 1087
2025-05-07 16:15:14,904:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 52
2025-05-07 16:15:14,905:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:15,055:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000763 seconds.
2025-05-07 16:15:15,056:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:15,056:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:15,057:INFO:[LightGBM] [Info] Total Bins 1085
2025-05-07 16:15:15,057:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 51
2025-05-07 16:15:15,057:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:15,213:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001233 seconds.
2025-05-07 16:15:15,213:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:15,214:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:15,214:INFO:[LightGBM] [Info] Total Bins 1083
2025-05-07 16:15:15,214:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 50
2025-05-07 16:15:15,214:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:15,386:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000966 seconds.
2025-05-07 16:15:15,386:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:15,386:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:15,386:INFO:[LightGBM] [Info] Total Bins 1081
2025-05-07 16:15:15,387:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 49
2025-05-07 16:15:15,387:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:15,544:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000705 seconds.
2025-05-07 16:15:15,544:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:15,545:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:15,545:INFO:[LightGBM] [Info] Total Bins 1079
2025-05-07 16:15:15,545:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 48
2025-05-07 16:15:15,546:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:15,688:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001202 seconds.
2025-05-07 16:15:15,688:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:15,688:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:15,689:INFO:[LightGBM] [Info] Total Bins 1077
2025-05-07 16:15:15,690:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 47
2025-05-07 16:15:15,690:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:15,839:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001129 seconds.
2025-05-07 16:15:15,839:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:15,839:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:15,840:INFO:[LightGBM] [Info] Total Bins 1075
2025-05-07 16:15:15,840:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 46
2025-05-07 16:15:15,840:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:15,982:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000936 seconds.
2025-05-07 16:15:15,983:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:15,983:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:15,983:INFO:[LightGBM] [Info] Total Bins 1073
2025-05-07 16:15:15,984:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 45
2025-05-07 16:15:15,984:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:16,145:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001219 seconds.
2025-05-07 16:15:16,146:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:16,146:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:16,146:INFO:[LightGBM] [Info] Total Bins 1071
2025-05-07 16:15:16,146:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 44
2025-05-07 16:15:16,147:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:16,299:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001171 seconds.
2025-05-07 16:15:16,299:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:16,299:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:16,300:INFO:[LightGBM] [Info] Total Bins 1069
2025-05-07 16:15:16,300:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 43
2025-05-07 16:15:16,300:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:16,442:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001253 seconds.
2025-05-07 16:15:16,443:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:16,443:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:16,443:INFO:[LightGBM] [Info] Total Bins 1067
2025-05-07 16:15:16,443:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 42
2025-05-07 16:15:16,444:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:16,578:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000719 seconds.
2025-05-07 16:15:16,579:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:16,579:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:16,579:INFO:[LightGBM] [Info] Total Bins 1065
2025-05-07 16:15:16,579:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 41
2025-05-07 16:15:16,580:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:16,711:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000757 seconds.
2025-05-07 16:15:16,711:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:16,712:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:16,712:INFO:[LightGBM] [Info] Total Bins 1063
2025-05-07 16:15:16,712:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 40
2025-05-07 16:15:16,713:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:16,848:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001241 seconds.
2025-05-07 16:15:16,848:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:16,848:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:16,848:INFO:[LightGBM] [Info] Total Bins 1061
2025-05-07 16:15:16,849:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 39
2025-05-07 16:15:16,849:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:16,988:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,003662 seconds.
2025-05-07 16:15:16,989:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:15:16,989:INFO:[LightGBM] [Info] Total Bins 1059
2025-05-07 16:15:16,989:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 38
2025-05-07 16:15:16,990:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:17,151:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,004049 seconds.
2025-05-07 16:15:17,151:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:15:17,151:INFO:[LightGBM] [Info] Total Bins 1057
2025-05-07 16:15:17,152:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 37
2025-05-07 16:15:17,152:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:17,301:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000789 seconds.
2025-05-07 16:15:17,302:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:17,302:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:17,302:INFO:[LightGBM] [Info] Total Bins 1055
2025-05-07 16:15:17,302:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 36
2025-05-07 16:15:17,304:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:17,438:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001185 seconds.
2025-05-07 16:15:17,438:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:17,439:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:17,439:INFO:[LightGBM] [Info] Total Bins 1053
2025-05-07 16:15:17,439:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 35
2025-05-07 16:15:17,440:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:17,572:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001205 seconds.
2025-05-07 16:15:17,572:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:17,572:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:17,573:INFO:[LightGBM] [Info] Total Bins 1051
2025-05-07 16:15:17,573:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 34
2025-05-07 16:15:17,573:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:17,706:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001084 seconds.
2025-05-07 16:15:17,707:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:17,707:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:17,707:INFO:[LightGBM] [Info] Total Bins 1049
2025-05-07 16:15:17,707:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 33
2025-05-07 16:15:17,708:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:17,843:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000936 seconds.
2025-05-07 16:15:17,844:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:17,844:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:17,844:INFO:[LightGBM] [Info] Total Bins 1047
2025-05-07 16:15:17,844:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 32
2025-05-07 16:15:17,845:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:17,980:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000846 seconds.
2025-05-07 16:15:17,980:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:17,981:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:17,981:INFO:[LightGBM] [Info] Total Bins 1045
2025-05-07 16:15:17,981:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 31
2025-05-07 16:15:17,982:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:18,120:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,003347 seconds.
2025-05-07 16:15:18,120:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:15:18,121:INFO:[LightGBM] [Info] Total Bins 1043
2025-05-07 16:15:18,122:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 30
2025-05-07 16:15:18,122:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:18,299:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000885 seconds.
2025-05-07 16:15:18,299:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:18,300:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:18,300:INFO:[LightGBM] [Info] Total Bins 1041
2025-05-07 16:15:18,300:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 29
2025-05-07 16:15:18,300:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:18,436:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001070 seconds.
2025-05-07 16:15:18,436:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:18,436:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:18,437:INFO:[LightGBM] [Info] Total Bins 1039
2025-05-07 16:15:18,437:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 28
2025-05-07 16:15:18,438:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:18,577:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001099 seconds.
2025-05-07 16:15:18,578:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:18,578:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:18,578:INFO:[LightGBM] [Info] Total Bins 1037
2025-05-07 16:15:18,578:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 27
2025-05-07 16:15:18,579:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:18,709:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001387 seconds.
2025-05-07 16:15:18,710:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:18,710:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:18,710:INFO:[LightGBM] [Info] Total Bins 1035
2025-05-07 16:15:18,711:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 26
2025-05-07 16:15:18,711:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:18,867:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000645 seconds.
2025-05-07 16:15:18,868:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:18,868:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:18,868:INFO:[LightGBM] [Info] Total Bins 1033
2025-05-07 16:15:18,869:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 25
2025-05-07 16:15:18,869:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:18,991:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001224 seconds.
2025-05-07 16:15:18,992:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:18,992:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:18,992:INFO:[LightGBM] [Info] Total Bins 1031
2025-05-07 16:15:18,992:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 24
2025-05-07 16:15:18,992:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:19,118:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001030 seconds.
2025-05-07 16:15:19,119:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:19,119:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:19,119:INFO:[LightGBM] [Info] Total Bins 1029
2025-05-07 16:15:19,120:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 23
2025-05-07 16:15:19,120:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:19,304:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001050 seconds.
2025-05-07 16:15:19,304:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:19,304:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:19,304:INFO:[LightGBM] [Info] Total Bins 1027
2025-05-07 16:15:19,304:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 22
2025-05-07 16:15:19,305:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:19,432:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000970 seconds.
2025-05-07 16:15:19,434:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:19,434:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:19,434:INFO:[LightGBM] [Info] Total Bins 1025
2025-05-07 16:15:19,435:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 21
2025-05-07 16:15:19,435:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:19,569:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000928 seconds.
2025-05-07 16:15:19,570:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:19,570:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:19,570:INFO:[LightGBM] [Info] Total Bins 1023
2025-05-07 16:15:19,570:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 20
2025-05-07 16:15:19,571:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:19,693:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001029 seconds.
2025-05-07 16:15:19,694:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:19,694:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:19,694:INFO:[LightGBM] [Info] Total Bins 1021
2025-05-07 16:15:19,694:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 19
2025-05-07 16:15:19,695:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:19,808:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001675 seconds.
2025-05-07 16:15:19,809:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:19,809:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:19,809:INFO:[LightGBM] [Info] Total Bins 1019
2025-05-07 16:15:19,809:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 18
2025-05-07 16:15:19,810:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:19,921:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001290 seconds.
2025-05-07 16:15:19,922:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:19,922:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:19,922:INFO:[LightGBM] [Info] Total Bins 1017
2025-05-07 16:15:19,922:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 17
2025-05-07 16:15:19,922:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:20,048:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001090 seconds.
2025-05-07 16:15:20,048:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:20,048:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:20,048:INFO:[LightGBM] [Info] Total Bins 1015
2025-05-07 16:15:20,049:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 16
2025-05-07 16:15:20,049:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:20,159:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000928 seconds.
2025-05-07 16:15:20,160:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:20,160:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:20,160:INFO:[LightGBM] [Info] Total Bins 1013
2025-05-07 16:15:20,160:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 15
2025-05-07 16:15:20,160:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:20,268:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000664 seconds.
2025-05-07 16:15:20,268:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:20,269:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:20,269:INFO:[LightGBM] [Info] Total Bins 1011
2025-05-07 16:15:20,269:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 14
2025-05-07 16:15:20,270:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:20,395:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000939 seconds.
2025-05-07 16:15:20,396:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:20,396:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:20,396:INFO:[LightGBM] [Info] Total Bins 1009
2025-05-07 16:15:20,396:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 13
2025-05-07 16:15:20,396:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:20,541:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000892 seconds.
2025-05-07 16:15:20,542:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:20,542:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:20,542:INFO:[LightGBM] [Info] Total Bins 1007
2025-05-07 16:15:20,542:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 12
2025-05-07 16:15:20,543:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:20,684:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000787 seconds.
2025-05-07 16:15:20,684:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:20,684:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:20,684:INFO:[LightGBM] [Info] Total Bins 1005
2025-05-07 16:15:20,684:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 11
2025-05-07 16:15:20,685:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:20,825:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000768 seconds.
2025-05-07 16:15:20,825:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:20,826:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:20,826:INFO:[LightGBM] [Info] Total Bins 1003
2025-05-07 16:15:20,826:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 10
2025-05-07 16:15:20,826:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:20,962:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000764 seconds.
2025-05-07 16:15:20,962:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:20,962:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:20,962:INFO:[LightGBM] [Info] Total Bins 997
2025-05-07 16:15:20,964:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 9
2025-05-07 16:15:20,964:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:21,074:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000755 seconds.
2025-05-07 16:15:21,074:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:15:21,074:INFO:[LightGBM] [Info] Total Bins 995
2025-05-07 16:15:21,074:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 8
2025-05-07 16:15:21,075:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:21,172:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000197 seconds.
2025-05-07 16:15:21,173:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:21,173:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:21,173:INFO:[LightGBM] [Info] Total Bins 993
2025-05-07 16:15:21,173:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 7
2025-05-07 16:15:21,174:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:21,278:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000468 seconds.
2025-05-07 16:15:21,278:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:15:21,278:INFO:[LightGBM] [Info] Total Bins 976
2025-05-07 16:15:21,278:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 6
2025-05-07 16:15:21,279:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:21,371:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000445 seconds.
2025-05-07 16:15:21,372:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:15:21,372:INFO:[LightGBM] [Info] Total Bins 962
2025-05-07 16:15:21,372:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 5
2025-05-07 16:15:21,372:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:21,454:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000385 seconds.
2025-05-07 16:15:21,455:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:15:21,455:INFO:[LightGBM] [Info] Total Bins 938
2025-05-07 16:15:21,455:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 4
2025-05-07 16:15:21,456:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:21,560:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000092 seconds.
2025-05-07 16:15:21,560:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:21,560:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:21,561:INFO:[LightGBM] [Info] Total Bins 684
2025-05-07 16:15:21,561:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 3
2025-05-07 16:15:21,561:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:21,713:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000088 seconds.
2025-05-07 16:15:21,713:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:21,713:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:21,713:INFO:[LightGBM] [Info] Total Bins 508
2025-05-07 16:15:21,715:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 2
2025-05-07 16:15:21,715:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:21,798:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000065 seconds.
2025-05-07 16:15:21,798:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:21,798:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:21,799:INFO:[LightGBM] [Info] Total Bins 253
2025-05-07 16:15:21,799:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 1
2025-05-07 16:15:21,799:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:15:21,950:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001033 seconds.
2025-05-07 16:15:21,951:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:21,951:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:21,951:INFO:[LightGBM] [Info] Total Bins 1121
2025-05-07 16:15:21,952:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 69
2025-05-07 16:15:21,952:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:22,117:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000921 seconds.
2025-05-07 16:15:22,117:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:22,117:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:22,118:INFO:[LightGBM] [Info] Total Bins 1119
2025-05-07 16:15:22,118:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 68
2025-05-07 16:15:22,119:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:22,287:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001239 seconds.
2025-05-07 16:15:22,288:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:22,288:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:22,288:INFO:[LightGBM] [Info] Total Bins 1117
2025-05-07 16:15:22,288:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:15:22,289:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:22,467:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001208 seconds.
2025-05-07 16:15:22,467:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:22,467:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:22,468:INFO:[LightGBM] [Info] Total Bins 1117
2025-05-07 16:15:22,468:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:15:22,469:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:22,641:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001678 seconds.
2025-05-07 16:15:22,641:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:22,642:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:22,642:INFO:[LightGBM] [Info] Total Bins 1115
2025-05-07 16:15:22,642:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:15:22,643:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:22,800:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000954 seconds.
2025-05-07 16:15:22,800:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:22,800:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:22,800:INFO:[LightGBM] [Info] Total Bins 1115
2025-05-07 16:15:22,801:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:15:22,801:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:22,962:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001429 seconds.
2025-05-07 16:15:22,963:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:22,963:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:22,963:INFO:[LightGBM] [Info] Total Bins 1115
2025-05-07 16:15:22,964:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:15:22,964:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:23,145:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001024 seconds.
2025-05-07 16:15:23,146:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:23,146:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:23,146:INFO:[LightGBM] [Info] Total Bins 1113
2025-05-07 16:15:23,147:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:15:23,147:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:23,337:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001313 seconds.
2025-05-07 16:15:23,338:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:23,338:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:23,338:INFO:[LightGBM] [Info] Total Bins 1111
2025-05-07 16:15:23,340:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:15:23,341:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:23,499:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001608 seconds.
2025-05-07 16:15:23,500:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:23,500:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:23,500:INFO:[LightGBM] [Info] Total Bins 1111
2025-05-07 16:15:23,500:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:15:23,501:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:23,671:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001569 seconds.
2025-05-07 16:15:23,671:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:23,671:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:23,672:INFO:[LightGBM] [Info] Total Bins 1111
2025-05-07 16:15:23,672:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:15:23,672:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:23,835:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001310 seconds.
2025-05-07 16:15:23,835:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:23,835:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:23,836:INFO:[LightGBM] [Info] Total Bins 1109
2025-05-07 16:15:23,836:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:15:23,836:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:23,988:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001207 seconds.
2025-05-07 16:15:23,988:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:23,988:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:23,989:INFO:[LightGBM] [Info] Total Bins 1107
2025-05-07 16:15:23,989:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:15:23,990:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:24,149:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001210 seconds.
2025-05-07 16:15:24,150:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:24,150:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:24,150:INFO:[LightGBM] [Info] Total Bins 1105
2025-05-07 16:15:24,151:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 61
2025-05-07 16:15:24,151:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:24,315:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001009 seconds.
2025-05-07 16:15:24,315:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:24,315:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:24,316:INFO:[LightGBM] [Info] Total Bins 1105
2025-05-07 16:15:24,316:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 61
2025-05-07 16:15:24,316:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:24,473:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001688 seconds.
2025-05-07 16:15:24,474:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:24,474:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:24,475:INFO:[LightGBM] [Info] Total Bins 1103
2025-05-07 16:15:24,475:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:15:24,475:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:24,667:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001202 seconds.
2025-05-07 16:15:24,667:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:24,667:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:24,668:INFO:[LightGBM] [Info] Total Bins 1103
2025-05-07 16:15:24,669:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:15:24,669:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:24,828:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001265 seconds.
2025-05-07 16:15:24,829:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:24,829:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:24,829:INFO:[LightGBM] [Info] Total Bins 1101
2025-05-07 16:15:24,830:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:15:24,830:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:24,985:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001053 seconds.
2025-05-07 16:15:24,986:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:24,986:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:24,987:INFO:[LightGBM] [Info] Total Bins 1099
2025-05-07 16:15:24,987:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 58
2025-05-07 16:15:24,987:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:25,148:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001027 seconds.
2025-05-07 16:15:25,148:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:25,148:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:25,149:INFO:[LightGBM] [Info] Total Bins 1097
2025-05-07 16:15:25,149:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 57
2025-05-07 16:15:25,150:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:25,306:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001421 seconds.
2025-05-07 16:15:25,307:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:25,307:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:25,307:INFO:[LightGBM] [Info] Total Bins 1095
2025-05-07 16:15:25,308:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 56
2025-05-07 16:15:25,308:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:25,454:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001174 seconds.
2025-05-07 16:15:25,455:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:25,455:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:25,455:INFO:[LightGBM] [Info] Total Bins 1093
2025-05-07 16:15:25,456:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 55
2025-05-07 16:15:25,456:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:25,611:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001414 seconds.
2025-05-07 16:15:25,612:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:25,612:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:25,612:INFO:[LightGBM] [Info] Total Bins 1091
2025-05-07 16:15:25,612:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:15:25,613:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:25,770:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000920 seconds.
2025-05-07 16:15:25,770:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:25,770:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:25,771:INFO:[LightGBM] [Info] Total Bins 1089
2025-05-07 16:15:25,772:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 53
2025-05-07 16:15:25,772:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:25,931:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001176 seconds.
2025-05-07 16:15:25,931:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:25,931:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:25,932:INFO:[LightGBM] [Info] Total Bins 1087
2025-05-07 16:15:25,932:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 52
2025-05-07 16:15:25,932:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:26,092:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001424 seconds.
2025-05-07 16:15:26,092:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:26,092:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:26,093:INFO:[LightGBM] [Info] Total Bins 1085
2025-05-07 16:15:26,093:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 51
2025-05-07 16:15:26,094:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:26,259:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000895 seconds.
2025-05-07 16:15:26,259:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:26,259:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:26,260:INFO:[LightGBM] [Info] Total Bins 1083
2025-05-07 16:15:26,260:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 50
2025-05-07 16:15:26,260:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:26,413:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001481 seconds.
2025-05-07 16:15:26,414:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:26,414:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:26,414:INFO:[LightGBM] [Info] Total Bins 1081
2025-05-07 16:15:26,414:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 49
2025-05-07 16:15:26,414:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:26,577:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001394 seconds.
2025-05-07 16:15:26,577:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:26,577:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:26,578:INFO:[LightGBM] [Info] Total Bins 1079
2025-05-07 16:15:26,578:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 48
2025-05-07 16:15:26,578:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:26,722:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001204 seconds.
2025-05-07 16:15:26,722:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:26,723:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:26,723:INFO:[LightGBM] [Info] Total Bins 1077
2025-05-07 16:15:26,723:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 47
2025-05-07 16:15:26,723:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:26,872:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001081 seconds.
2025-05-07 16:15:26,872:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:26,872:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:26,874:INFO:[LightGBM] [Info] Total Bins 1075
2025-05-07 16:15:26,874:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 46
2025-05-07 16:15:26,874:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:27,061:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001335 seconds.
2025-05-07 16:15:27,061:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:27,061:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:27,062:INFO:[LightGBM] [Info] Total Bins 1073
2025-05-07 16:15:27,062:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 45
2025-05-07 16:15:27,063:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:27,214:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001947 seconds.
2025-05-07 16:15:27,214:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:27,214:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:27,214:INFO:[LightGBM] [Info] Total Bins 1071
2025-05-07 16:15:27,215:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 44
2025-05-07 16:15:27,215:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:27,382:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001373 seconds.
2025-05-07 16:15:27,382:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:27,382:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:27,382:INFO:[LightGBM] [Info] Total Bins 1069
2025-05-07 16:15:27,383:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 43
2025-05-07 16:15:27,384:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:27,529:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001009 seconds.
2025-05-07 16:15:27,529:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:27,529:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:27,530:INFO:[LightGBM] [Info] Total Bins 1067
2025-05-07 16:15:27,530:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 42
2025-05-07 16:15:27,530:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:27,693:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001217 seconds.
2025-05-07 16:15:27,694:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:27,694:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:27,694:INFO:[LightGBM] [Info] Total Bins 1065
2025-05-07 16:15:27,694:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 41
2025-05-07 16:15:27,695:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:27,835:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001124 seconds.
2025-05-07 16:15:27,835:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:27,835:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:27,837:INFO:[LightGBM] [Info] Total Bins 1063
2025-05-07 16:15:27,837:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 40
2025-05-07 16:15:27,838:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:27,980:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001053 seconds.
2025-05-07 16:15:27,980:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:27,981:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:27,981:INFO:[LightGBM] [Info] Total Bins 1061
2025-05-07 16:15:27,981:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 39
2025-05-07 16:15:27,982:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:28,120:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001530 seconds.
2025-05-07 16:15:28,121:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:28,121:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:28,121:INFO:[LightGBM] [Info] Total Bins 1059
2025-05-07 16:15:28,122:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 38
2025-05-07 16:15:28,122:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:28,274:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,004960 seconds.
2025-05-07 16:15:28,276:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:15:28,276:INFO:[LightGBM] [Info] Total Bins 1057
2025-05-07 16:15:28,276:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 37
2025-05-07 16:15:28,277:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:28,443:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,002968 seconds.
2025-05-07 16:15:28,443:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:15:28,443:INFO:[LightGBM] [Info] Total Bins 1055
2025-05-07 16:15:28,444:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 36
2025-05-07 16:15:28,444:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:28,611:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000847 seconds.
2025-05-07 16:15:28,611:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:28,612:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:28,612:INFO:[LightGBM] [Info] Total Bins 1053
2025-05-07 16:15:28,612:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 35
2025-05-07 16:15:28,612:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:28,764:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000898 seconds.
2025-05-07 16:15:28,765:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:28,765:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:28,765:INFO:[LightGBM] [Info] Total Bins 1051
2025-05-07 16:15:28,765:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 34
2025-05-07 16:15:28,766:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:28,917:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000841 seconds.
2025-05-07 16:15:28,917:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:28,917:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:28,918:INFO:[LightGBM] [Info] Total Bins 1049
2025-05-07 16:15:28,918:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 33
2025-05-07 16:15:28,918:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:29,078:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,004153 seconds.
2025-05-07 16:15:29,078:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:15:29,079:INFO:[LightGBM] [Info] Total Bins 1047
2025-05-07 16:15:29,079:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 32
2025-05-07 16:15:29,079:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:29,232:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001107 seconds.
2025-05-07 16:15:29,233:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:29,233:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:29,233:INFO:[LightGBM] [Info] Total Bins 1045
2025-05-07 16:15:29,234:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 31
2025-05-07 16:15:29,234:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:29,362:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000688 seconds.
2025-05-07 16:15:29,363:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:29,363:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:29,363:INFO:[LightGBM] [Info] Total Bins 1043
2025-05-07 16:15:29,363:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 30
2025-05-07 16:15:29,363:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:29,490:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001618 seconds.
2025-05-07 16:15:29,490:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:29,491:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:29,491:INFO:[LightGBM] [Info] Total Bins 1041
2025-05-07 16:15:29,491:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 29
2025-05-07 16:15:29,492:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:29,622:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001756 seconds.
2025-05-07 16:15:29,622:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:29,622:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:29,622:INFO:[LightGBM] [Info] Total Bins 1039
2025-05-07 16:15:29,623:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 28
2025-05-07 16:15:29,624:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:29,763:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001268 seconds.
2025-05-07 16:15:29,763:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:29,764:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:29,764:INFO:[LightGBM] [Info] Total Bins 1037
2025-05-07 16:15:29,764:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 27
2025-05-07 16:15:29,764:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:29,890:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001738 seconds.
2025-05-07 16:15:29,890:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:29,890:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:29,891:INFO:[LightGBM] [Info] Total Bins 1035
2025-05-07 16:15:29,891:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 26
2025-05-07 16:15:29,892:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:30,022:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001062 seconds.
2025-05-07 16:15:30,022:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:30,022:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:30,023:INFO:[LightGBM] [Info] Total Bins 1033
2025-05-07 16:15:30,023:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 25
2025-05-07 16:15:30,024:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:30,142:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001181 seconds.
2025-05-07 16:15:30,142:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:30,143:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:30,143:INFO:[LightGBM] [Info] Total Bins 1031
2025-05-07 16:15:30,143:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 24
2025-05-07 16:15:30,143:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:30,259:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000810 seconds.
2025-05-07 16:15:30,260:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:30,260:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:30,260:INFO:[LightGBM] [Info] Total Bins 1029
2025-05-07 16:15:30,260:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 23
2025-05-07 16:15:30,261:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:30,384:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000988 seconds.
2025-05-07 16:15:30,384:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:30,384:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:30,384:INFO:[LightGBM] [Info] Total Bins 1027
2025-05-07 16:15:30,384:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 22
2025-05-07 16:15:30,386:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:30,507:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001388 seconds.
2025-05-07 16:15:30,507:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:30,507:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:30,508:INFO:[LightGBM] [Info] Total Bins 1025
2025-05-07 16:15:30,508:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 21
2025-05-07 16:15:30,508:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:30,632:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000873 seconds.
2025-05-07 16:15:30,632:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:30,633:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:30,633:INFO:[LightGBM] [Info] Total Bins 1023
2025-05-07 16:15:30,633:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 20
2025-05-07 16:15:30,633:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:30,770:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000928 seconds.
2025-05-07 16:15:30,770:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:30,770:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:30,770:INFO:[LightGBM] [Info] Total Bins 1021
2025-05-07 16:15:30,771:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 19
2025-05-07 16:15:30,772:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:30,883:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000702 seconds.
2025-05-07 16:15:30,884:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:30,884:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:30,884:INFO:[LightGBM] [Info] Total Bins 1019
2025-05-07 16:15:30,884:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 18
2025-05-07 16:15:30,884:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:31,005:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001225 seconds.
2025-05-07 16:15:31,006:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:31,006:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:31,006:INFO:[LightGBM] [Info] Total Bins 1017
2025-05-07 16:15:31,007:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 17
2025-05-07 16:15:31,007:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:31,125:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001204 seconds.
2025-05-07 16:15:31,126:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:31,126:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:31,126:INFO:[LightGBM] [Info] Total Bins 1015
2025-05-07 16:15:31,126:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 16
2025-05-07 16:15:31,127:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:31,262:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000772 seconds.
2025-05-07 16:15:31,262:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:31,263:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:31,263:INFO:[LightGBM] [Info] Total Bins 1013
2025-05-07 16:15:31,263:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 15
2025-05-07 16:15:31,264:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:31,391:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000965 seconds.
2025-05-07 16:15:31,392:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:31,392:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:31,392:INFO:[LightGBM] [Info] Total Bins 1011
2025-05-07 16:15:31,392:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 14
2025-05-07 16:15:31,393:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:31,510:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,001873 seconds.
2025-05-07 16:15:31,511:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:15:31,511:INFO:[LightGBM] [Info] Total Bins 1009
2025-05-07 16:15:31,511:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 13
2025-05-07 16:15:31,512:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:31,667:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000955 seconds.
2025-05-07 16:15:31,668:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:31,668:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:31,668:INFO:[LightGBM] [Info] Total Bins 1007
2025-05-07 16:15:31,669:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 12
2025-05-07 16:15:31,669:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:31,782:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000651 seconds.
2025-05-07 16:15:31,782:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:31,782:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:31,783:INFO:[LightGBM] [Info] Total Bins 1005
2025-05-07 16:15:31,783:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 11
2025-05-07 16:15:31,783:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:31,893:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000759 seconds.
2025-05-07 16:15:31,893:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:31,893:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:31,893:INFO:[LightGBM] [Info] Total Bins 1003
2025-05-07 16:15:31,894:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 10
2025-05-07 16:15:31,894:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:32,013:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000479 seconds.
2025-05-07 16:15:32,013:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:32,013:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:32,013:INFO:[LightGBM] [Info] Total Bins 1001
2025-05-07 16:15:32,014:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 9
2025-05-07 16:15:32,014:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:32,117:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000145 seconds.
2025-05-07 16:15:32,117:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:32,117:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:32,118:INFO:[LightGBM] [Info] Total Bins 999
2025-05-07 16:15:32,118:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 8
2025-05-07 16:15:32,118:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:32,226:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000205 seconds.
2025-05-07 16:15:32,226:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:32,226:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:32,227:INFO:[LightGBM] [Info] Total Bins 993
2025-05-07 16:15:32,227:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 7
2025-05-07 16:15:32,227:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:32,329:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000163 seconds.
2025-05-07 16:15:32,329:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:32,329:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:32,329:INFO:[LightGBM] [Info] Total Bins 976
2025-05-07 16:15:32,330:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 6
2025-05-07 16:15:32,330:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:32,431:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000135 seconds.
2025-05-07 16:15:32,432:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:32,432:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:32,432:INFO:[LightGBM] [Info] Total Bins 962
2025-05-07 16:15:32,432:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 5
2025-05-07 16:15:32,432:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:32,550:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000342 seconds.
2025-05-07 16:15:32,550:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:15:32,551:INFO:[LightGBM] [Info] Total Bins 940
2025-05-07 16:15:32,551:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 4
2025-05-07 16:15:32,551:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:32,651:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000116 seconds.
2025-05-07 16:15:32,651:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:32,652:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:32,652:INFO:[LightGBM] [Info] Total Bins 686
2025-05-07 16:15:32,652:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 3
2025-05-07 16:15:32,652:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:32,736:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000077 seconds.
2025-05-07 16:15:32,737:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:32,737:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:32,737:INFO:[LightGBM] [Info] Total Bins 508
2025-05-07 16:15:32,738:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 2
2025-05-07 16:15:32,738:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:32,839:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000066 seconds.
2025-05-07 16:15:32,840:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:32,840:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:32,840:INFO:[LightGBM] [Info] Total Bins 253
2025-05-07 16:15:32,840:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 1
2025-05-07 16:15:32,841:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:15:32,982:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001156 seconds.
2025-05-07 16:15:32,982:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:32,982:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:32,983:INFO:[LightGBM] [Info] Total Bins 1123
2025-05-07 16:15:32,983:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 69
2025-05-07 16:15:32,984:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:33,134:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,003341 seconds.
2025-05-07 16:15:33,136:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:15:33,137:INFO:[LightGBM] [Info] Total Bins 1121
2025-05-07 16:15:33,137:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 68
2025-05-07 16:15:33,138:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:33,307:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001350 seconds.
2025-05-07 16:15:33,308:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:33,308:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:33,308:INFO:[LightGBM] [Info] Total Bins 1121
2025-05-07 16:15:33,309:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 68
2025-05-07 16:15:33,309:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:33,466:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001371 seconds.
2025-05-07 16:15:33,467:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:33,467:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:33,467:INFO:[LightGBM] [Info] Total Bins 1121
2025-05-07 16:15:33,468:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 68
2025-05-07 16:15:33,468:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:33,644:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001312 seconds.
2025-05-07 16:15:33,644:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:33,644:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:33,645:INFO:[LightGBM] [Info] Total Bins 1119
2025-05-07 16:15:33,645:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:15:33,645:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:33,806:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001228 seconds.
2025-05-07 16:15:33,807:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:33,807:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:33,807:INFO:[LightGBM] [Info] Total Bins 1119
2025-05-07 16:15:33,807:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:15:33,808:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:33,954:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000972 seconds.
2025-05-07 16:15:33,954:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:33,955:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:33,955:INFO:[LightGBM] [Info] Total Bins 1119
2025-05-07 16:15:33,955:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:15:33,956:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:34,117:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001137 seconds.
2025-05-07 16:15:34,117:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:34,117:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:34,118:INFO:[LightGBM] [Info] Total Bins 1117
2025-05-07 16:15:34,118:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:15:34,120:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:34,272:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001097 seconds.
2025-05-07 16:15:34,272:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:34,272:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:34,272:INFO:[LightGBM] [Info] Total Bins 1117
2025-05-07 16:15:34,272:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:15:34,273:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:34,427:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000961 seconds.
2025-05-07 16:15:34,427:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:34,427:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:34,428:INFO:[LightGBM] [Info] Total Bins 1115
2025-05-07 16:15:34,428:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:15:34,428:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:34,586:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001342 seconds.
2025-05-07 16:15:34,586:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:34,586:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:34,587:INFO:[LightGBM] [Info] Total Bins 1113
2025-05-07 16:15:34,587:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:15:34,588:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:34,756:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001491 seconds.
2025-05-07 16:15:34,756:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:34,757:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:34,757:INFO:[LightGBM] [Info] Total Bins 1111
2025-05-07 16:15:34,757:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:15:34,758:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:34,931:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001623 seconds.
2025-05-07 16:15:34,932:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:34,932:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:34,932:INFO:[LightGBM] [Info] Total Bins 1111
2025-05-07 16:15:34,933:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:15:34,933:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:35,112:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001169 seconds.
2025-05-07 16:15:35,112:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:35,112:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:35,112:INFO:[LightGBM] [Info] Total Bins 1109
2025-05-07 16:15:35,112:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:15:35,113:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:35,293:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001836 seconds.
2025-05-07 16:15:35,294:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:35,294:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:35,294:INFO:[LightGBM] [Info] Total Bins 1107
2025-05-07 16:15:35,294:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 61
2025-05-07 16:15:35,296:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:35,452:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001076 seconds.
2025-05-07 16:15:35,452:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:35,453:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:35,453:INFO:[LightGBM] [Info] Total Bins 1107
2025-05-07 16:15:35,453:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 61
2025-05-07 16:15:35,454:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:35,615:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001389 seconds.
2025-05-07 16:15:35,615:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:35,615:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:35,616:INFO:[LightGBM] [Info] Total Bins 1105
2025-05-07 16:15:35,616:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:15:35,616:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:35,805:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001185 seconds.
2025-05-07 16:15:35,805:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:35,805:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:35,806:INFO:[LightGBM] [Info] Total Bins 1103
2025-05-07 16:15:35,806:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:15:35,807:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:35,980:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001294 seconds.
2025-05-07 16:15:35,980:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:35,981:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:35,981:INFO:[LightGBM] [Info] Total Bins 1101
2025-05-07 16:15:35,981:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 58
2025-05-07 16:15:35,982:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:36,142:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001287 seconds.
2025-05-07 16:15:36,142:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:36,144:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:36,144:INFO:[LightGBM] [Info] Total Bins 1099
2025-05-07 16:15:36,144:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 57
2025-05-07 16:15:36,145:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:36,296:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001074 seconds.
2025-05-07 16:15:36,296:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:36,297:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:36,297:INFO:[LightGBM] [Info] Total Bins 1097
2025-05-07 16:15:36,297:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 56
2025-05-07 16:15:36,298:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:36,482:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001291 seconds.
2025-05-07 16:15:36,483:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:36,483:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:36,484:INFO:[LightGBM] [Info] Total Bins 1095
2025-05-07 16:15:36,484:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 55
2025-05-07 16:15:36,485:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:36,683:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001092 seconds.
2025-05-07 16:15:36,683:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:36,684:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:36,684:INFO:[LightGBM] [Info] Total Bins 1093
2025-05-07 16:15:36,684:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:15:36,685:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:36,842:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001313 seconds.
2025-05-07 16:15:36,843:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:36,844:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:36,844:INFO:[LightGBM] [Info] Total Bins 1091
2025-05-07 16:15:36,844:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 53
2025-05-07 16:15:36,845:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:36,993:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001184 seconds.
2025-05-07 16:15:36,993:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:36,994:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:36,994:INFO:[LightGBM] [Info] Total Bins 1089
2025-05-07 16:15:36,994:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 52
2025-05-07 16:15:36,995:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:37,183:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001265 seconds.
2025-05-07 16:15:37,184:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:37,184:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:37,184:INFO:[LightGBM] [Info] Total Bins 1087
2025-05-07 16:15:37,185:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 51
2025-05-07 16:15:37,185:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:37,355:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001643 seconds.
2025-05-07 16:15:37,355:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:37,355:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:37,356:INFO:[LightGBM] [Info] Total Bins 1085
2025-05-07 16:15:37,356:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 50
2025-05-07 16:15:37,356:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:37,525:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001244 seconds.
2025-05-07 16:15:37,526:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:37,526:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:37,526:INFO:[LightGBM] [Info] Total Bins 1083
2025-05-07 16:15:37,526:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 49
2025-05-07 16:15:37,527:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:37,698:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001450 seconds.
2025-05-07 16:15:37,699:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:37,699:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:37,699:INFO:[LightGBM] [Info] Total Bins 1081
2025-05-07 16:15:37,700:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 48
2025-05-07 16:15:37,700:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:37,866:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001318 seconds.
2025-05-07 16:15:37,867:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:37,867:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:37,867:INFO:[LightGBM] [Info] Total Bins 1079
2025-05-07 16:15:37,868:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 47
2025-05-07 16:15:37,868:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:38,042:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001306 seconds.
2025-05-07 16:15:38,042:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:38,042:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:38,044:INFO:[LightGBM] [Info] Total Bins 1077
2025-05-07 16:15:38,045:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 46
2025-05-07 16:15:38,045:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:38,234:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001289 seconds.
2025-05-07 16:15:38,235:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:38,235:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:38,235:INFO:[LightGBM] [Info] Total Bins 1075
2025-05-07 16:15:38,235:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 45
2025-05-07 16:15:38,236:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:38,420:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001152 seconds.
2025-05-07 16:15:38,420:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:38,420:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:38,421:INFO:[LightGBM] [Info] Total Bins 1073
2025-05-07 16:15:38,421:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 44
2025-05-07 16:15:38,422:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:38,552:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000724 seconds.
2025-05-07 16:15:38,553:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:38,553:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:38,554:INFO:[LightGBM] [Info] Total Bins 1071
2025-05-07 16:15:38,554:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 43
2025-05-07 16:15:38,554:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:38,699:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000875 seconds.
2025-05-07 16:15:38,699:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:38,699:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:38,700:INFO:[LightGBM] [Info] Total Bins 1069
2025-05-07 16:15:38,700:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 42
2025-05-07 16:15:38,700:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:38,845:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001146 seconds.
2025-05-07 16:15:38,845:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:38,845:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:38,845:INFO:[LightGBM] [Info] Total Bins 1067
2025-05-07 16:15:38,846:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 41
2025-05-07 16:15:38,846:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:38,990:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000935 seconds.
2025-05-07 16:15:38,990:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:38,990:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:38,991:INFO:[LightGBM] [Info] Total Bins 1065
2025-05-07 16:15:38,991:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 40
2025-05-07 16:15:38,991:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:39,150:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000684 seconds.
2025-05-07 16:15:39,150:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:39,150:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:39,151:INFO:[LightGBM] [Info] Total Bins 1063
2025-05-07 16:15:39,151:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 39
2025-05-07 16:15:39,151:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:39,314:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001201 seconds.
2025-05-07 16:15:39,315:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:39,315:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:39,315:INFO:[LightGBM] [Info] Total Bins 1061
2025-05-07 16:15:39,315:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 38
2025-05-07 16:15:39,315:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:39,463:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001041 seconds.
2025-05-07 16:15:39,463:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:39,464:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:39,464:INFO:[LightGBM] [Info] Total Bins 1059
2025-05-07 16:15:39,464:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 37
2025-05-07 16:15:39,464:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:39,612:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001151 seconds.
2025-05-07 16:15:39,612:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:39,612:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:39,612:INFO:[LightGBM] [Info] Total Bins 1057
2025-05-07 16:15:39,612:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 36
2025-05-07 16:15:39,613:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:39,765:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,003239 seconds.
2025-05-07 16:15:39,765:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:15:39,765:INFO:[LightGBM] [Info] Total Bins 1055
2025-05-07 16:15:39,766:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 35
2025-05-07 16:15:39,766:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:39,984:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001025 seconds.
2025-05-07 16:15:39,985:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:39,985:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:39,985:INFO:[LightGBM] [Info] Total Bins 1053
2025-05-07 16:15:39,985:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 34
2025-05-07 16:15:39,985:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:40,128:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001057 seconds.
2025-05-07 16:15:40,128:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:40,128:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:40,129:INFO:[LightGBM] [Info] Total Bins 1051
2025-05-07 16:15:40,129:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 33
2025-05-07 16:15:40,129:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:40,268:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001031 seconds.
2025-05-07 16:15:40,269:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:40,269:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:40,269:INFO:[LightGBM] [Info] Total Bins 1049
2025-05-07 16:15:40,270:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 32
2025-05-07 16:15:40,270:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:40,401:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001155 seconds.
2025-05-07 16:15:40,402:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:40,402:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:40,402:INFO:[LightGBM] [Info] Total Bins 1047
2025-05-07 16:15:40,403:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 31
2025-05-07 16:15:40,404:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:40,557:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001334 seconds.
2025-05-07 16:15:40,558:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:40,558:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:40,558:INFO:[LightGBM] [Info] Total Bins 1045
2025-05-07 16:15:40,558:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 30
2025-05-07 16:15:40,559:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:40,701:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001319 seconds.
2025-05-07 16:15:40,701:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:40,701:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:40,702:INFO:[LightGBM] [Info] Total Bins 1043
2025-05-07 16:15:40,702:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 29
2025-05-07 16:15:40,703:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:40,844:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000970 seconds.
2025-05-07 16:15:40,844:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:40,844:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:40,844:INFO:[LightGBM] [Info] Total Bins 1041
2025-05-07 16:15:40,845:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 28
2025-05-07 16:15:40,845:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:40,980:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001260 seconds.
2025-05-07 16:15:40,981:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:40,981:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:40,981:INFO:[LightGBM] [Info] Total Bins 1039
2025-05-07 16:15:40,981:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 27
2025-05-07 16:15:40,982:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:41,125:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001367 seconds.
2025-05-07 16:15:41,127:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:41,127:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:41,127:INFO:[LightGBM] [Info] Total Bins 1037
2025-05-07 16:15:41,127:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 26
2025-05-07 16:15:41,128:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:41,268:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001137 seconds.
2025-05-07 16:15:41,268:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:41,269:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:41,269:INFO:[LightGBM] [Info] Total Bins 1035
2025-05-07 16:15:41,270:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 25
2025-05-07 16:15:41,271:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:41,394:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000875 seconds.
2025-05-07 16:15:41,395:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:41,395:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:41,395:INFO:[LightGBM] [Info] Total Bins 1033
2025-05-07 16:15:41,395:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 24
2025-05-07 16:15:41,395:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:41,522:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001020 seconds.
2025-05-07 16:15:41,522:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:41,522:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:41,522:INFO:[LightGBM] [Info] Total Bins 1031
2025-05-07 16:15:41,522:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 23
2025-05-07 16:15:41,523:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:41,640:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000639 seconds.
2025-05-07 16:15:41,641:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:41,641:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:41,641:INFO:[LightGBM] [Info] Total Bins 1029
2025-05-07 16:15:41,641:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 22
2025-05-07 16:15:41,642:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:41,767:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000766 seconds.
2025-05-07 16:15:41,767:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:41,768:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:41,768:INFO:[LightGBM] [Info] Total Bins 1027
2025-05-07 16:15:41,768:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 21
2025-05-07 16:15:41,769:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:41,882:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000609 seconds.
2025-05-07 16:15:41,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:41,883:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:41,883:INFO:[LightGBM] [Info] Total Bins 1025
2025-05-07 16:15:41,883:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 20
2025-05-07 16:15:41,884:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:42,002:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,002537 seconds.
2025-05-07 16:15:42,002:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:15:42,002:INFO:[LightGBM] [Info] Total Bins 1023
2025-05-07 16:15:42,003:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 19
2025-05-07 16:15:42,003:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:42,147:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000726 seconds.
2025-05-07 16:15:42,148:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:15:42,148:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:15:42,148:INFO:[LightGBM] [Info] Total Bins 1021
2025-05-07 16:15:42,148:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 18
2025-05-07 16:15:42,149:INFO:[LightGBM] [Info] Start training from score 436886,572593
2025-05-07 16:15:49,555:INFO:Initializing plot_model()
2025-05-07 16:15:49,556:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), plot=learning, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-07 16:15:49,556:INFO:Checking exceptions
2025-05-07 16:15:49,563:INFO:Preloading libraries
2025-05-07 16:15:49,566:INFO:Copying training dataset
2025-05-07 16:15:49,566:INFO:Plot type: learning
2025-05-07 16:15:49,798:INFO:Fitting Model
2025-05-07 16:16:05,237:INFO:Visual Rendered Successfully
2025-05-07 16:16:05,398:INFO:plot_model() successfully completed......................................
2025-05-07 16:16:05,406:INFO:Initializing evaluate_model()
2025-05-07 16:16:05,406:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-07 16:16:05,420:INFO:Initializing plot_model()
2025-05-07 16:16:05,421:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-07 16:16:05,421:INFO:Checking exceptions
2025-05-07 16:16:05,431:INFO:Preloading libraries
2025-05-07 16:16:05,435:INFO:Copying training dataset
2025-05-07 16:16:05,435:INFO:Plot type: pipeline
2025-05-07 16:16:05,556:INFO:Visual Rendered Successfully
2025-05-07 16:16:05,663:INFO:plot_model() successfully completed......................................
2025-05-07 16:16:05,671:INFO:Initializing plot_model()
2025-05-07 16:16:05,671:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), plot=rfe, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-07 16:16:05,671:INFO:Checking exceptions
2025-05-07 16:16:05,679:INFO:Preloading libraries
2025-05-07 16:16:05,683:INFO:Copying training dataset
2025-05-07 16:16:05,683:INFO:Plot type: rfe
2025-05-07 16:16:05,955:INFO:Fitting Model
2025-05-07 16:16:06,047:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001276 seconds.
2025-05-07 16:16:06,048:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:06,048:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:06,048:INFO:[LightGBM] [Info] Total Bins 1120
2025-05-07 16:16:06,048:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 68
2025-05-07 16:16:06,048:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:06,200:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000794 seconds.
2025-05-07 16:16:06,200:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:06,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:06,201:INFO:[LightGBM] [Info] Total Bins 1118
2025-05-07 16:16:06,201:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:16:06,202:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:06,377:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001061 seconds.
2025-05-07 16:16:06,377:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:06,377:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:06,377:INFO:[LightGBM] [Info] Total Bins 1116
2025-05-07 16:16:06,377:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:16:06,379:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:06,533:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001329 seconds.
2025-05-07 16:16:06,534:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:06,534:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:06,534:INFO:[LightGBM] [Info] Total Bins 1116
2025-05-07 16:16:06,535:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:16:06,535:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:06,686:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001177 seconds.
2025-05-07 16:16:06,686:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:06,686:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:06,687:INFO:[LightGBM] [Info] Total Bins 1114
2025-05-07 16:16:06,688:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:16:06,688:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:06,845:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000920 seconds.
2025-05-07 16:16:06,845:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:06,845:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:06,846:INFO:[LightGBM] [Info] Total Bins 1114
2025-05-07 16:16:06,846:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:16:06,846:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:07,016:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001614 seconds.
2025-05-07 16:16:07,016:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:07,016:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:07,017:INFO:[LightGBM] [Info] Total Bins 1112
2025-05-07 16:16:07,017:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:16:07,018:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:07,179:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001384 seconds.
2025-05-07 16:16:07,180:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:07,180:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:07,180:INFO:[LightGBM] [Info] Total Bins 1112
2025-05-07 16:16:07,180:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:16:07,180:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:07,369:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001268 seconds.
2025-05-07 16:16:07,369:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:07,369:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:07,370:INFO:[LightGBM] [Info] Total Bins 1112
2025-05-07 16:16:07,371:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:16:07,371:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:07,547:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000836 seconds.
2025-05-07 16:16:07,547:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:07,547:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:07,547:INFO:[LightGBM] [Info] Total Bins 1110
2025-05-07 16:16:07,547:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:16:07,549:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:07,719:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001355 seconds.
2025-05-07 16:16:07,720:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:07,720:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:07,721:INFO:[LightGBM] [Info] Total Bins 1110
2025-05-07 16:16:07,721:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:16:07,722:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:07,886:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,004151 seconds.
2025-05-07 16:16:07,886:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:16:07,887:INFO:[LightGBM] [Info] Total Bins 1108
2025-05-07 16:16:07,887:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:16:07,887:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:08,081:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001382 seconds.
2025-05-07 16:16:08,081:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:08,083:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:08,083:INFO:[LightGBM] [Info] Total Bins 1108
2025-05-07 16:16:08,083:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:16:08,084:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:08,247:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000863 seconds.
2025-05-07 16:16:08,247:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:08,249:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:08,249:INFO:[LightGBM] [Info] Total Bins 1106
2025-05-07 16:16:08,249:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 61
2025-05-07 16:16:08,250:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:08,427:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,002153 seconds.
2025-05-07 16:16:08,427:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:08,427:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:08,427:INFO:[LightGBM] [Info] Total Bins 1104
2025-05-07 16:16:08,429:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:16:08,429:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:08,585:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001147 seconds.
2025-05-07 16:16:08,585:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:08,586:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:08,586:INFO:[LightGBM] [Info] Total Bins 1102
2025-05-07 16:16:08,587:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:16:08,587:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:08,734:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001152 seconds.
2025-05-07 16:16:08,735:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:08,735:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:08,735:INFO:[LightGBM] [Info] Total Bins 1100
2025-05-07 16:16:08,735:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 58
2025-05-07 16:16:08,736:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:08,888:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001218 seconds.
2025-05-07 16:16:08,888:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:08,888:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:08,888:INFO:[LightGBM] [Info] Total Bins 1098
2025-05-07 16:16:08,888:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 57
2025-05-07 16:16:08,889:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:09,046:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001113 seconds.
2025-05-07 16:16:09,047:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:09,047:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:09,047:INFO:[LightGBM] [Info] Total Bins 1096
2025-05-07 16:16:09,048:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 56
2025-05-07 16:16:09,048:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:09,197:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001156 seconds.
2025-05-07 16:16:09,197:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:09,197:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:09,198:INFO:[LightGBM] [Info] Total Bins 1096
2025-05-07 16:16:09,198:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 56
2025-05-07 16:16:09,198:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:09,351:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001268 seconds.
2025-05-07 16:16:09,351:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:09,352:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:09,352:INFO:[LightGBM] [Info] Total Bins 1094
2025-05-07 16:16:09,352:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 55
2025-05-07 16:16:09,353:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:09,497:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001003 seconds.
2025-05-07 16:16:09,497:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:09,498:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:09,498:INFO:[LightGBM] [Info] Total Bins 1092
2025-05-07 16:16:09,498:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:16:09,498:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:09,664:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001550 seconds.
2025-05-07 16:16:09,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:09,665:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:09,665:INFO:[LightGBM] [Info] Total Bins 1092
2025-05-07 16:16:09,665:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:16:09,666:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:09,817:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001112 seconds.
2025-05-07 16:16:09,817:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:09,817:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:09,818:INFO:[LightGBM] [Info] Total Bins 1090
2025-05-07 16:16:09,818:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 53
2025-05-07 16:16:09,818:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:09,973:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001407 seconds.
2025-05-07 16:16:09,973:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:09,974:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:09,974:INFO:[LightGBM] [Info] Total Bins 1088
2025-05-07 16:16:09,974:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 52
2025-05-07 16:16:09,975:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:10,126:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,002436 seconds.
2025-05-07 16:16:10,127:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:10,127:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:10,127:INFO:[LightGBM] [Info] Total Bins 1086
2025-05-07 16:16:10,128:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 51
2025-05-07 16:16:10,128:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:10,271:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001905 seconds.
2025-05-07 16:16:10,273:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:10,273:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:10,273:INFO:[LightGBM] [Info] Total Bins 1084
2025-05-07 16:16:10,273:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 50
2025-05-07 16:16:10,274:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:10,431:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001493 seconds.
2025-05-07 16:16:10,432:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:10,432:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:10,432:INFO:[LightGBM] [Info] Total Bins 1082
2025-05-07 16:16:10,432:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 49
2025-05-07 16:16:10,433:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:10,600:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001339 seconds.
2025-05-07 16:16:10,601:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:10,601:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:10,601:INFO:[LightGBM] [Info] Total Bins 1080
2025-05-07 16:16:10,601:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 48
2025-05-07 16:16:10,603:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:10,751:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,003460 seconds.
2025-05-07 16:16:10,751:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:16:10,753:INFO:[LightGBM] [Info] Total Bins 1078
2025-05-07 16:16:10,753:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 47
2025-05-07 16:16:10,754:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:10,927:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000808 seconds.
2025-05-07 16:16:10,927:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:10,927:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:10,928:INFO:[LightGBM] [Info] Total Bins 1076
2025-05-07 16:16:10,928:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 46
2025-05-07 16:16:10,928:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:11,068:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001062 seconds.
2025-05-07 16:16:11,068:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:11,069:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:11,069:INFO:[LightGBM] [Info] Total Bins 1074
2025-05-07 16:16:11,070:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 45
2025-05-07 16:16:11,071:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:11,207:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001385 seconds.
2025-05-07 16:16:11,207:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:11,207:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:11,207:INFO:[LightGBM] [Info] Total Bins 1072
2025-05-07 16:16:11,208:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 44
2025-05-07 16:16:11,208:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:11,375:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001115 seconds.
2025-05-07 16:16:11,375:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:11,375:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:11,376:INFO:[LightGBM] [Info] Total Bins 1070
2025-05-07 16:16:11,376:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 43
2025-05-07 16:16:11,376:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:11,520:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001441 seconds.
2025-05-07 16:16:11,520:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:11,521:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:11,521:INFO:[LightGBM] [Info] Total Bins 1068
2025-05-07 16:16:11,521:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 42
2025-05-07 16:16:11,521:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:11,691:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001299 seconds.
2025-05-07 16:16:11,691:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:11,691:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:11,693:INFO:[LightGBM] [Info] Total Bins 1066
2025-05-07 16:16:11,693:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 41
2025-05-07 16:16:11,693:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:11,840:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001289 seconds.
2025-05-07 16:16:11,841:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:11,841:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:11,841:INFO:[LightGBM] [Info] Total Bins 1064
2025-05-07 16:16:11,841:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 40
2025-05-07 16:16:11,841:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:11,991:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001067 seconds.
2025-05-07 16:16:11,991:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:11,992:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:11,992:INFO:[LightGBM] [Info] Total Bins 1062
2025-05-07 16:16:11,992:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 39
2025-05-07 16:16:11,993:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:12,131:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001293 seconds.
2025-05-07 16:16:12,132:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:12,132:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:12,132:INFO:[LightGBM] [Info] Total Bins 1060
2025-05-07 16:16:12,132:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 38
2025-05-07 16:16:12,132:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:12,266:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000763 seconds.
2025-05-07 16:16:12,266:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:12,267:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:12,267:INFO:[LightGBM] [Info] Total Bins 1058
2025-05-07 16:16:12,267:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 37
2025-05-07 16:16:12,268:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:12,413:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000862 seconds.
2025-05-07 16:16:12,413:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:12,413:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:12,414:INFO:[LightGBM] [Info] Total Bins 1056
2025-05-07 16:16:12,414:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 36
2025-05-07 16:16:12,414:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:12,563:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000903 seconds.
2025-05-07 16:16:12,563:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:12,563:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:12,563:INFO:[LightGBM] [Info] Total Bins 1054
2025-05-07 16:16:12,563:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 35
2025-05-07 16:16:12,564:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:12,694:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000842 seconds.
2025-05-07 16:16:12,695:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:12,695:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:12,695:INFO:[LightGBM] [Info] Total Bins 1052
2025-05-07 16:16:12,695:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 34
2025-05-07 16:16:12,696:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:12,831:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000841 seconds.
2025-05-07 16:16:12,831:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:12,831:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:12,831:INFO:[LightGBM] [Info] Total Bins 1050
2025-05-07 16:16:12,831:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 33
2025-05-07 16:16:12,831:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:12,968:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001014 seconds.
2025-05-07 16:16:12,968:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:12,968:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:12,969:INFO:[LightGBM] [Info] Total Bins 1048
2025-05-07 16:16:12,969:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 32
2025-05-07 16:16:12,969:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:13,109:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000913 seconds.
2025-05-07 16:16:13,110:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:13,110:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:13,110:INFO:[LightGBM] [Info] Total Bins 1046
2025-05-07 16:16:13,110:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 31
2025-05-07 16:16:13,111:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:13,243:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001259 seconds.
2025-05-07 16:16:13,243:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:13,244:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:13,244:INFO:[LightGBM] [Info] Total Bins 1044
2025-05-07 16:16:13,244:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 30
2025-05-07 16:16:13,244:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:13,378:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001798 seconds.
2025-05-07 16:16:13,378:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:13,378:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:13,379:INFO:[LightGBM] [Info] Total Bins 1042
2025-05-07 16:16:13,379:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 29
2025-05-07 16:16:13,379:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:13,506:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001264 seconds.
2025-05-07 16:16:13,506:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:13,507:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:13,507:INFO:[LightGBM] [Info] Total Bins 1040
2025-05-07 16:16:13,507:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 28
2025-05-07 16:16:13,507:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:13,642:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000966 seconds.
2025-05-07 16:16:13,643:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:13,643:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:13,643:INFO:[LightGBM] [Info] Total Bins 1038
2025-05-07 16:16:13,643:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 27
2025-05-07 16:16:13,643:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:13,772:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001211 seconds.
2025-05-07 16:16:13,773:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:13,773:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:13,773:INFO:[LightGBM] [Info] Total Bins 1036
2025-05-07 16:16:13,773:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 26
2025-05-07 16:16:13,774:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:13,905:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001367 seconds.
2025-05-07 16:16:13,905:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:13,906:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:13,906:INFO:[LightGBM] [Info] Total Bins 1034
2025-05-07 16:16:13,906:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 25
2025-05-07 16:16:13,907:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:14,051:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001012 seconds.
2025-05-07 16:16:14,051:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:14,051:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:14,053:INFO:[LightGBM] [Info] Total Bins 1032
2025-05-07 16:16:14,053:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 24
2025-05-07 16:16:14,053:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:14,188:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001232 seconds.
2025-05-07 16:16:14,188:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:14,188:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:14,188:INFO:[LightGBM] [Info] Total Bins 1030
2025-05-07 16:16:14,188:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 23
2025-05-07 16:16:14,190:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:14,316:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001121 seconds.
2025-05-07 16:16:14,317:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:14,317:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:14,317:INFO:[LightGBM] [Info] Total Bins 1028
2025-05-07 16:16:14,318:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 22
2025-05-07 16:16:14,318:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:14,455:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000723 seconds.
2025-05-07 16:16:14,455:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:14,455:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:14,456:INFO:[LightGBM] [Info] Total Bins 1026
2025-05-07 16:16:14,456:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 21
2025-05-07 16:16:14,456:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:14,578:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001057 seconds.
2025-05-07 16:16:14,578:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:14,578:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:14,578:INFO:[LightGBM] [Info] Total Bins 1024
2025-05-07 16:16:14,578:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 20
2025-05-07 16:16:14,580:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:14,710:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000887 seconds.
2025-05-07 16:16:14,711:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:14,711:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:14,711:INFO:[LightGBM] [Info] Total Bins 1022
2025-05-07 16:16:14,711:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 19
2025-05-07 16:16:14,712:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:14,832:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000946 seconds.
2025-05-07 16:16:14,832:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:14,833:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:14,833:INFO:[LightGBM] [Info] Total Bins 1020
2025-05-07 16:16:14,833:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 18
2025-05-07 16:16:14,833:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:14,956:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001255 seconds.
2025-05-07 16:16:14,956:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:14,956:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:14,957:INFO:[LightGBM] [Info] Total Bins 1018
2025-05-07 16:16:14,957:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 17
2025-05-07 16:16:14,957:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:15,084:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000857 seconds.
2025-05-07 16:16:15,085:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:15,085:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:15,085:INFO:[LightGBM] [Info] Total Bins 1016
2025-05-07 16:16:15,085:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 16
2025-05-07 16:16:15,087:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:15,217:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001024 seconds.
2025-05-07 16:16:15,218:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:15,218:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:15,218:INFO:[LightGBM] [Info] Total Bins 1014
2025-05-07 16:16:15,218:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 15
2025-05-07 16:16:15,218:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:15,364:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001236 seconds.
2025-05-07 16:16:15,365:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:15,365:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:15,365:INFO:[LightGBM] [Info] Total Bins 1012
2025-05-07 16:16:15,365:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 14
2025-05-07 16:16:15,366:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:15,484:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000642 seconds.
2025-05-07 16:16:15,484:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:15,484:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:15,485:INFO:[LightGBM] [Info] Total Bins 1010
2025-05-07 16:16:15,485:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 13
2025-05-07 16:16:15,485:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:15,599:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000600 seconds.
2025-05-07 16:16:15,599:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:15,599:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:15,600:INFO:[LightGBM] [Info] Total Bins 1008
2025-05-07 16:16:15,600:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 12
2025-05-07 16:16:15,601:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:15,725:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000726 seconds.
2025-05-07 16:16:15,725:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:15,725:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:15,725:INFO:[LightGBM] [Info] Total Bins 1006
2025-05-07 16:16:15,726:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 11
2025-05-07 16:16:15,726:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:15,828:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000891 seconds.
2025-05-07 16:16:15,828:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:16:15,830:INFO:[LightGBM] [Info] Total Bins 1004
2025-05-07 16:16:15,830:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 10
2025-05-07 16:16:15,830:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:16,000:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000605 seconds.
2025-05-07 16:16:16,000:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:16,001:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:16,001:INFO:[LightGBM] [Info] Total Bins 1002
2025-05-07 16:16:16,001:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 9
2025-05-07 16:16:16,002:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:16,107:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000277 seconds.
2025-05-07 16:16:16,107:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:16,108:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:16,108:INFO:[LightGBM] [Info] Total Bins 1000
2025-05-07 16:16:16,108:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 8
2025-05-07 16:16:16,108:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:16,218:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000744 seconds.
2025-05-07 16:16:16,218:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:16,220:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:16,220:INFO:[LightGBM] [Info] Total Bins 994
2025-05-07 16:16:16,220:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 7
2025-05-07 16:16:16,220:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:16,322:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000138 seconds.
2025-05-07 16:16:16,323:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:16,323:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:16,324:INFO:[LightGBM] [Info] Total Bins 977
2025-05-07 16:16:16,324:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 6
2025-05-07 16:16:16,324:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:16,415:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000384 seconds.
2025-05-07 16:16:16,415:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:16:16,415:INFO:[LightGBM] [Info] Total Bins 962
2025-05-07 16:16:16,416:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 5
2025-05-07 16:16:16,416:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:16,510:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000088 seconds.
2025-05-07 16:16:16,511:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:16,511:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:16,511:INFO:[LightGBM] [Info] Total Bins 938
2025-05-07 16:16:16,511:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 4
2025-05-07 16:16:16,511:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:16,595:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000089 seconds.
2025-05-07 16:16:16,596:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:16,596:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:16,596:INFO:[LightGBM] [Info] Total Bins 684
2025-05-07 16:16:16,596:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 3
2025-05-07 16:16:16,596:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:16,697:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000089 seconds.
2025-05-07 16:16:16,697:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:16,697:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:16,698:INFO:[LightGBM] [Info] Total Bins 508
2025-05-07 16:16:16,698:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 2
2025-05-07 16:16:16,698:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:16,789:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000128 seconds.
2025-05-07 16:16:16,789:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:16,789:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:16,790:INFO:[LightGBM] [Info] Total Bins 253
2025-05-07 16:16:16,790:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 1
2025-05-07 16:16:16,790:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:16:16,930:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001407 seconds.
2025-05-07 16:16:16,930:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:16,930:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:16,931:INFO:[LightGBM] [Info] Total Bins 1120
2025-05-07 16:16:16,931:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 68
2025-05-07 16:16:16,932:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:17,102:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,004370 seconds.
2025-05-07 16:16:17,102:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:16:17,102:INFO:[LightGBM] [Info] Total Bins 1118
2025-05-07 16:16:17,103:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:16:17,103:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:17,293:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001361 seconds.
2025-05-07 16:16:17,294:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:17,294:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:17,294:INFO:[LightGBM] [Info] Total Bins 1116
2025-05-07 16:16:17,295:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:16:17,295:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:17,460:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,002766 seconds.
2025-05-07 16:16:17,460:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:17,460:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:17,461:INFO:[LightGBM] [Info] Total Bins 1114
2025-05-07 16:16:17,461:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:16:17,461:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:17,631:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001147 seconds.
2025-05-07 16:16:17,633:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:17,633:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:17,633:INFO:[LightGBM] [Info] Total Bins 1114
2025-05-07 16:16:17,634:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:16:17,635:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:17,799:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001058 seconds.
2025-05-07 16:16:17,800:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:17,800:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:17,800:INFO:[LightGBM] [Info] Total Bins 1114
2025-05-07 16:16:17,800:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:16:17,802:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:17,973:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001570 seconds.
2025-05-07 16:16:17,974:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:17,974:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:17,974:INFO:[LightGBM] [Info] Total Bins 1114
2025-05-07 16:16:17,975:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:16:17,975:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:18,149:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000934 seconds.
2025-05-07 16:16:18,149:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:18,149:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:18,149:INFO:[LightGBM] [Info] Total Bins 1112
2025-05-07 16:16:18,150:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:16:18,150:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:18,311:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000983 seconds.
2025-05-07 16:16:18,313:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:18,313:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:18,313:INFO:[LightGBM] [Info] Total Bins 1112
2025-05-07 16:16:18,313:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:16:18,314:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:18,474:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001462 seconds.
2025-05-07 16:16:18,474:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:18,474:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:18,475:INFO:[LightGBM] [Info] Total Bins 1110
2025-05-07 16:16:18,475:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:16:18,476:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:18,647:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001229 seconds.
2025-05-07 16:16:18,647:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:18,647:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:18,648:INFO:[LightGBM] [Info] Total Bins 1110
2025-05-07 16:16:18,648:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:16:18,648:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:18,827:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001381 seconds.
2025-05-07 16:16:18,827:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:18,827:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:18,828:INFO:[LightGBM] [Info] Total Bins 1108
2025-05-07 16:16:18,828:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:16:18,828:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:18,981:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001281 seconds.
2025-05-07 16:16:18,981:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:18,981:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:18,981:INFO:[LightGBM] [Info] Total Bins 1108
2025-05-07 16:16:18,983:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:16:18,983:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:19,151:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001370 seconds.
2025-05-07 16:16:19,153:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:19,153:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:19,153:INFO:[LightGBM] [Info] Total Bins 1106
2025-05-07 16:16:19,154:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 61
2025-05-07 16:16:19,154:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:19,314:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001150 seconds.
2025-05-07 16:16:19,314:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:19,314:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:19,314:INFO:[LightGBM] [Info] Total Bins 1104
2025-05-07 16:16:19,315:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:16:19,315:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:19,480:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001337 seconds.
2025-05-07 16:16:19,481:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:19,481:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:19,481:INFO:[LightGBM] [Info] Total Bins 1102
2025-05-07 16:16:19,481:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:16:19,481:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:19,638:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000911 seconds.
2025-05-07 16:16:19,638:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:19,638:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:19,639:INFO:[LightGBM] [Info] Total Bins 1102
2025-05-07 16:16:19,639:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:16:19,640:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:19,799:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001370 seconds.
2025-05-07 16:16:19,799:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:19,799:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:19,799:INFO:[LightGBM] [Info] Total Bins 1102
2025-05-07 16:16:19,799:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:16:19,800:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:19,961:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001589 seconds.
2025-05-07 16:16:19,961:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:19,961:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:19,963:INFO:[LightGBM] [Info] Total Bins 1100
2025-05-07 16:16:19,963:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 58
2025-05-07 16:16:19,964:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:20,137:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000939 seconds.
2025-05-07 16:16:20,138:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:20,138:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:20,139:INFO:[LightGBM] [Info] Total Bins 1098
2025-05-07 16:16:20,139:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 57
2025-05-07 16:16:20,140:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:20,296:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001092 seconds.
2025-05-07 16:16:20,296:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:20,296:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:20,297:INFO:[LightGBM] [Info] Total Bins 1096
2025-05-07 16:16:20,297:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 56
2025-05-07 16:16:20,297:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:20,475:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001101 seconds.
2025-05-07 16:16:20,476:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:20,476:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:20,476:INFO:[LightGBM] [Info] Total Bins 1094
2025-05-07 16:16:20,476:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 55
2025-05-07 16:16:20,477:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:20,637:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000868 seconds.
2025-05-07 16:16:20,638:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:20,638:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:20,638:INFO:[LightGBM] [Info] Total Bins 1092
2025-05-07 16:16:20,638:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:16:20,639:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:20,817:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000934 seconds.
2025-05-07 16:16:20,818:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:20,818:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:20,819:INFO:[LightGBM] [Info] Total Bins 1090
2025-05-07 16:16:20,819:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 53
2025-05-07 16:16:20,820:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:20,996:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001297 seconds.
2025-05-07 16:16:20,997:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:20,997:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:20,997:INFO:[LightGBM] [Info] Total Bins 1088
2025-05-07 16:16:20,997:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 52
2025-05-07 16:16:20,998:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:21,161:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001128 seconds.
2025-05-07 16:16:21,161:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:21,161:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:21,163:INFO:[LightGBM] [Info] Total Bins 1086
2025-05-07 16:16:21,163:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 51
2025-05-07 16:16:21,163:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:21,310:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001113 seconds.
2025-05-07 16:16:21,311:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:21,311:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:21,311:INFO:[LightGBM] [Info] Total Bins 1084
2025-05-07 16:16:21,311:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 50
2025-05-07 16:16:21,313:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:21,455:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001665 seconds.
2025-05-07 16:16:21,456:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:21,456:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:21,456:INFO:[LightGBM] [Info] Total Bins 1082
2025-05-07 16:16:21,457:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 49
2025-05-07 16:16:21,457:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:21,596:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001368 seconds.
2025-05-07 16:16:21,596:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:21,596:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:21,597:INFO:[LightGBM] [Info] Total Bins 1080
2025-05-07 16:16:21,597:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 48
2025-05-07 16:16:21,597:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:21,773:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000995 seconds.
2025-05-07 16:16:21,774:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:21,774:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:21,774:INFO:[LightGBM] [Info] Total Bins 1078
2025-05-07 16:16:21,774:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 47
2025-05-07 16:16:21,775:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:21,943:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001338 seconds.
2025-05-07 16:16:21,943:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:21,943:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:21,943:INFO:[LightGBM] [Info] Total Bins 1076
2025-05-07 16:16:21,944:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 46
2025-05-07 16:16:21,944:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:22,116:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001294 seconds.
2025-05-07 16:16:22,116:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:22,117:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:22,117:INFO:[LightGBM] [Info] Total Bins 1074
2025-05-07 16:16:22,117:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 45
2025-05-07 16:16:22,118:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:22,274:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001167 seconds.
2025-05-07 16:16:22,274:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:22,274:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:22,275:INFO:[LightGBM] [Info] Total Bins 1072
2025-05-07 16:16:22,275:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 44
2025-05-07 16:16:22,276:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:22,411:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000981 seconds.
2025-05-07 16:16:22,411:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:22,411:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:22,411:INFO:[LightGBM] [Info] Total Bins 1070
2025-05-07 16:16:22,413:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 43
2025-05-07 16:16:22,413:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:22,580:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001296 seconds.
2025-05-07 16:16:22,580:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:22,580:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:22,580:INFO:[LightGBM] [Info] Total Bins 1068
2025-05-07 16:16:22,581:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 42
2025-05-07 16:16:22,581:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:22,777:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000945 seconds.
2025-05-07 16:16:22,777:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:22,777:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:22,777:INFO:[LightGBM] [Info] Total Bins 1066
2025-05-07 16:16:22,778:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 41
2025-05-07 16:16:22,778:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:22,921:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,002034 seconds.
2025-05-07 16:16:22,921:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:22,921:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:22,921:INFO:[LightGBM] [Info] Total Bins 1064
2025-05-07 16:16:22,923:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 40
2025-05-07 16:16:22,923:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:23,091:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001300 seconds.
2025-05-07 16:16:23,091:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:23,091:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:23,091:INFO:[LightGBM] [Info] Total Bins 1062
2025-05-07 16:16:23,093:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 39
2025-05-07 16:16:23,093:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:23,246:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001211 seconds.
2025-05-07 16:16:23,247:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:23,247:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:23,247:INFO:[LightGBM] [Info] Total Bins 1060
2025-05-07 16:16:23,248:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 38
2025-05-07 16:16:23,248:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:23,427:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001017 seconds.
2025-05-07 16:16:23,428:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:23,428:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:23,428:INFO:[LightGBM] [Info] Total Bins 1058
2025-05-07 16:16:23,428:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 37
2025-05-07 16:16:23,429:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:23,570:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001122 seconds.
2025-05-07 16:16:23,570:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:23,570:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:23,570:INFO:[LightGBM] [Info] Total Bins 1056
2025-05-07 16:16:23,571:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 36
2025-05-07 16:16:23,571:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:23,728:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000680 seconds.
2025-05-07 16:16:23,728:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:23,728:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:23,729:INFO:[LightGBM] [Info] Total Bins 1054
2025-05-07 16:16:23,729:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 35
2025-05-07 16:16:23,729:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:23,868:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001102 seconds.
2025-05-07 16:16:23,869:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:23,869:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:23,869:INFO:[LightGBM] [Info] Total Bins 1052
2025-05-07 16:16:23,869:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 34
2025-05-07 16:16:23,871:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:24,023:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001277 seconds.
2025-05-07 16:16:24,023:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:24,023:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:24,024:INFO:[LightGBM] [Info] Total Bins 1050
2025-05-07 16:16:24,024:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 33
2025-05-07 16:16:24,024:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:24,170:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001329 seconds.
2025-05-07 16:16:24,170:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:24,170:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:24,171:INFO:[LightGBM] [Info] Total Bins 1048
2025-05-07 16:16:24,171:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 32
2025-05-07 16:16:24,171:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:24,309:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001084 seconds.
2025-05-07 16:16:24,309:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:24,311:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:24,311:INFO:[LightGBM] [Info] Total Bins 1046
2025-05-07 16:16:24,311:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 31
2025-05-07 16:16:24,311:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:24,446:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001051 seconds.
2025-05-07 16:16:24,446:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:24,446:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:24,447:INFO:[LightGBM] [Info] Total Bins 1044
2025-05-07 16:16:24,447:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 30
2025-05-07 16:16:24,447:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:24,579:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001210 seconds.
2025-05-07 16:16:24,579:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:24,579:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:24,579:INFO:[LightGBM] [Info] Total Bins 1042
2025-05-07 16:16:24,579:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 29
2025-05-07 16:16:24,579:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:24,726:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001078 seconds.
2025-05-07 16:16:24,726:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:24,726:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:24,727:INFO:[LightGBM] [Info] Total Bins 1040
2025-05-07 16:16:24,727:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 28
2025-05-07 16:16:24,727:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:24,863:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001048 seconds.
2025-05-07 16:16:24,863:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:24,863:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:24,864:INFO:[LightGBM] [Info] Total Bins 1038
2025-05-07 16:16:24,864:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 27
2025-05-07 16:16:24,864:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:24,997:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001182 seconds.
2025-05-07 16:16:24,997:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:24,998:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:24,998:INFO:[LightGBM] [Info] Total Bins 1036
2025-05-07 16:16:24,998:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 26
2025-05-07 16:16:24,999:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:25,163:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001587 seconds.
2025-05-07 16:16:25,163:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:25,163:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:25,164:INFO:[LightGBM] [Info] Total Bins 1034
2025-05-07 16:16:25,164:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 25
2025-05-07 16:16:25,164:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:25,293:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001234 seconds.
2025-05-07 16:16:25,294:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:25,294:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:25,294:INFO:[LightGBM] [Info] Total Bins 1032
2025-05-07 16:16:25,294:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 24
2025-05-07 16:16:25,295:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:25,424:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001113 seconds.
2025-05-07 16:16:25,425:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:25,425:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:25,425:INFO:[LightGBM] [Info] Total Bins 1030
2025-05-07 16:16:25,425:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 23
2025-05-07 16:16:25,426:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:25,545:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001003 seconds.
2025-05-07 16:16:25,545:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:25,545:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:25,546:INFO:[LightGBM] [Info] Total Bins 1028
2025-05-07 16:16:25,546:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 22
2025-05-07 16:16:25,546:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:25,694:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001268 seconds.
2025-05-07 16:16:25,694:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:25,694:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:25,694:INFO:[LightGBM] [Info] Total Bins 1026
2025-05-07 16:16:25,695:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 21
2025-05-07 16:16:25,695:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:25,852:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,002853 seconds.
2025-05-07 16:16:25,852:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:16:25,852:INFO:[LightGBM] [Info] Total Bins 1024
2025-05-07 16:16:25,853:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 20
2025-05-07 16:16:25,853:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:26,023:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001631 seconds.
2025-05-07 16:16:26,023:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:26,023:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:26,023:INFO:[LightGBM] [Info] Total Bins 1022
2025-05-07 16:16:26,023:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 19
2025-05-07 16:16:26,024:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:26,148:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001119 seconds.
2025-05-07 16:16:26,148:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:26,148:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:26,148:INFO:[LightGBM] [Info] Total Bins 1020
2025-05-07 16:16:26,149:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 18
2025-05-07 16:16:26,149:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:26,277:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000794 seconds.
2025-05-07 16:16:26,277:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:26,278:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:26,278:INFO:[LightGBM] [Info] Total Bins 1018
2025-05-07 16:16:26,278:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 17
2025-05-07 16:16:26,278:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:26,396:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001110 seconds.
2025-05-07 16:16:26,397:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:26,397:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:26,397:INFO:[LightGBM] [Info] Total Bins 1016
2025-05-07 16:16:26,397:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 16
2025-05-07 16:16:26,398:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:26,521:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001221 seconds.
2025-05-07 16:16:26,521:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:26,522:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:26,522:INFO:[LightGBM] [Info] Total Bins 1014
2025-05-07 16:16:26,522:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 15
2025-05-07 16:16:26,522:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:26,636:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001057 seconds.
2025-05-07 16:16:26,636:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:26,637:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:26,637:INFO:[LightGBM] [Info] Total Bins 1012
2025-05-07 16:16:26,637:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 14
2025-05-07 16:16:26,637:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:26,756:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000748 seconds.
2025-05-07 16:16:26,756:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:26,757:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:26,757:INFO:[LightGBM] [Info] Total Bins 1010
2025-05-07 16:16:26,757:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 13
2025-05-07 16:16:26,757:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:26,879:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001181 seconds.
2025-05-07 16:16:26,881:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:26,881:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:26,881:INFO:[LightGBM] [Info] Total Bins 1008
2025-05-07 16:16:26,882:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 12
2025-05-07 16:16:26,882:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:27,039:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000578 seconds.
2025-05-07 16:16:27,039:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:27,041:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:27,041:INFO:[LightGBM] [Info] Total Bins 1006
2025-05-07 16:16:27,041:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 11
2025-05-07 16:16:27,042:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:27,179:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000701 seconds.
2025-05-07 16:16:27,181:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:27,181:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:27,181:INFO:[LightGBM] [Info] Total Bins 1004
2025-05-07 16:16:27,181:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 10
2025-05-07 16:16:27,181:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:27,311:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000658 seconds.
2025-05-07 16:16:27,311:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:16:27,312:INFO:[LightGBM] [Info] Total Bins 1002
2025-05-07 16:16:27,312:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 9
2025-05-07 16:16:27,313:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:27,443:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000145 seconds.
2025-05-07 16:16:27,444:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:27,444:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:27,444:INFO:[LightGBM] [Info] Total Bins 1000
2025-05-07 16:16:27,444:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 8
2025-05-07 16:16:27,445:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:27,553:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000195 seconds.
2025-05-07 16:16:27,554:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:27,554:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:27,554:INFO:[LightGBM] [Info] Total Bins 994
2025-05-07 16:16:27,554:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 7
2025-05-07 16:16:27,556:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:27,663:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000142 seconds.
2025-05-07 16:16:27,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:27,664:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:27,664:INFO:[LightGBM] [Info] Total Bins 977
2025-05-07 16:16:27,664:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 6
2025-05-07 16:16:27,665:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:27,763:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000398 seconds.
2025-05-07 16:16:27,763:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:16:27,763:INFO:[LightGBM] [Info] Total Bins 962
2025-05-07 16:16:27,763:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 5
2025-05-07 16:16:27,764:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:27,857:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000085 seconds.
2025-05-07 16:16:27,857:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:27,857:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:27,857:INFO:[LightGBM] [Info] Total Bins 938
2025-05-07 16:16:27,858:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 4
2025-05-07 16:16:27,858:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:27,943:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000095 seconds.
2025-05-07 16:16:27,944:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:27,944:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:27,944:INFO:[LightGBM] [Info] Total Bins 684
2025-05-07 16:16:27,944:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 3
2025-05-07 16:16:27,944:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:28,031:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000072 seconds.
2025-05-07 16:16:28,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:28,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:28,031:INFO:[LightGBM] [Info] Total Bins 509
2025-05-07 16:16:28,031:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 2
2025-05-07 16:16:28,031:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:28,109:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000058 seconds.
2025-05-07 16:16:28,109:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:28,109:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:28,109:INFO:[LightGBM] [Info] Total Bins 254
2025-05-07 16:16:28,109:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 1
2025-05-07 16:16:28,109:INFO:[LightGBM] [Info] Start training from score 436853,857676
2025-05-07 16:16:28,247:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000805 seconds.
2025-05-07 16:16:28,248:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:28,248:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:28,248:INFO:[LightGBM] [Info] Total Bins 1122
2025-05-07 16:16:28,248:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 70
2025-05-07 16:16:28,249:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:28,401:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000873 seconds.
2025-05-07 16:16:28,402:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:28,402:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:28,403:INFO:[LightGBM] [Info] Total Bins 1120
2025-05-07 16:16:28,403:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 69
2025-05-07 16:16:28,403:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:28,559:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001294 seconds.
2025-05-07 16:16:28,559:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:28,561:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:28,561:INFO:[LightGBM] [Info] Total Bins 1120
2025-05-07 16:16:28,561:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 69
2025-05-07 16:16:28,562:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:28,714:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001065 seconds.
2025-05-07 16:16:28,716:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:28,716:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:28,716:INFO:[LightGBM] [Info] Total Bins 1118
2025-05-07 16:16:28,717:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 68
2025-05-07 16:16:28,717:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:28,870:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001254 seconds.
2025-05-07 16:16:28,870:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:28,870:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:28,871:INFO:[LightGBM] [Info] Total Bins 1118
2025-05-07 16:16:28,871:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 68
2025-05-07 16:16:28,871:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:29,039:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001532 seconds.
2025-05-07 16:16:29,039:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:29,040:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:29,040:INFO:[LightGBM] [Info] Total Bins 1116
2025-05-07 16:16:29,040:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:16:29,040:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:29,204:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001339 seconds.
2025-05-07 16:16:29,204:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:29,204:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:29,205:INFO:[LightGBM] [Info] Total Bins 1114
2025-05-07 16:16:29,205:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:16:29,205:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:29,367:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001283 seconds.
2025-05-07 16:16:29,367:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:29,368:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:29,368:INFO:[LightGBM] [Info] Total Bins 1112
2025-05-07 16:16:29,368:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:16:29,369:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:29,516:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001582 seconds.
2025-05-07 16:16:29,517:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:29,517:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:29,518:INFO:[LightGBM] [Info] Total Bins 1110
2025-05-07 16:16:29,518:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:16:29,519:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:29,699:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001338 seconds.
2025-05-07 16:16:29,701:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:29,701:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:29,701:INFO:[LightGBM] [Info] Total Bins 1108
2025-05-07 16:16:29,701:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:16:29,702:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:29,862:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001094 seconds.
2025-05-07 16:16:29,862:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:29,862:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:29,862:INFO:[LightGBM] [Info] Total Bins 1106
2025-05-07 16:16:29,862:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:16:29,863:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:30,024:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001385 seconds.
2025-05-07 16:16:30,025:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:30,025:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:30,025:INFO:[LightGBM] [Info] Total Bins 1104
2025-05-07 16:16:30,026:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 61
2025-05-07 16:16:30,026:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:30,180:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001359 seconds.
2025-05-07 16:16:30,180:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:30,181:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:30,181:INFO:[LightGBM] [Info] Total Bins 1102
2025-05-07 16:16:30,181:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:16:30,181:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:30,334:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001363 seconds.
2025-05-07 16:16:30,334:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:30,335:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:30,335:INFO:[LightGBM] [Info] Total Bins 1102
2025-05-07 16:16:30,335:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:16:30,336:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:30,485:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000967 seconds.
2025-05-07 16:16:30,485:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:30,485:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:30,486:INFO:[LightGBM] [Info] Total Bins 1102
2025-05-07 16:16:30,486:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:16:30,487:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:30,638:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001291 seconds.
2025-05-07 16:16:30,639:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:30,639:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:30,639:INFO:[LightGBM] [Info] Total Bins 1102
2025-05-07 16:16:30,640:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:16:30,640:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:30,796:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001151 seconds.
2025-05-07 16:16:30,796:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:30,796:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:30,797:INFO:[LightGBM] [Info] Total Bins 1100
2025-05-07 16:16:30,797:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:16:30,797:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:30,985:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001420 seconds.
2025-05-07 16:16:30,986:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:30,986:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:30,986:INFO:[LightGBM] [Info] Total Bins 1100
2025-05-07 16:16:30,987:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:16:30,987:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:31,148:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001356 seconds.
2025-05-07 16:16:31,149:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:31,149:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:31,149:INFO:[LightGBM] [Info] Total Bins 1098
2025-05-07 16:16:31,150:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 58
2025-05-07 16:16:31,150:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:31,312:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001466 seconds.
2025-05-07 16:16:31,313:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:31,313:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:31,313:INFO:[LightGBM] [Info] Total Bins 1096
2025-05-07 16:16:31,313:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 57
2025-05-07 16:16:31,314:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:31,496:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000879 seconds.
2025-05-07 16:16:31,496:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:31,496:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:31,496:INFO:[LightGBM] [Info] Total Bins 1094
2025-05-07 16:16:31,496:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 56
2025-05-07 16:16:31,496:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:31,664:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001376 seconds.
2025-05-07 16:16:31,665:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:31,665:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:31,665:INFO:[LightGBM] [Info] Total Bins 1092
2025-05-07 16:16:31,666:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 55
2025-05-07 16:16:31,666:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:31,823:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001283 seconds.
2025-05-07 16:16:31,824:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:31,824:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:31,824:INFO:[LightGBM] [Info] Total Bins 1090
2025-05-07 16:16:31,824:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:16:31,825:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:31,998:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001468 seconds.
2025-05-07 16:16:31,998:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:31,999:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:31,999:INFO:[LightGBM] [Info] Total Bins 1088
2025-05-07 16:16:31,999:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 53
2025-05-07 16:16:32,000:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:32,158:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001419 seconds.
2025-05-07 16:16:32,159:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:32,159:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:32,159:INFO:[LightGBM] [Info] Total Bins 1086
2025-05-07 16:16:32,159:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 52
2025-05-07 16:16:32,160:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:32,300:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000955 seconds.
2025-05-07 16:16:32,300:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:32,300:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:32,300:INFO:[LightGBM] [Info] Total Bins 1084
2025-05-07 16:16:32,300:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 51
2025-05-07 16:16:32,301:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:32,462:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001018 seconds.
2025-05-07 16:16:32,462:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:32,462:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:32,463:INFO:[LightGBM] [Info] Total Bins 1082
2025-05-07 16:16:32,463:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 50
2025-05-07 16:16:32,463:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:32,620:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001664 seconds.
2025-05-07 16:16:32,620:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:32,621:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:32,621:INFO:[LightGBM] [Info] Total Bins 1080
2025-05-07 16:16:32,621:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 49
2025-05-07 16:16:32,621:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:32,761:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001118 seconds.
2025-05-07 16:16:32,761:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:32,761:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:32,761:INFO:[LightGBM] [Info] Total Bins 1078
2025-05-07 16:16:32,761:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 48
2025-05-07 16:16:32,763:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:32,903:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001136 seconds.
2025-05-07 16:16:32,903:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:32,904:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:32,904:INFO:[LightGBM] [Info] Total Bins 1076
2025-05-07 16:16:32,904:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 47
2025-05-07 16:16:32,905:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:33,049:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000904 seconds.
2025-05-07 16:16:33,049:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:33,049:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:33,050:INFO:[LightGBM] [Info] Total Bins 1074
2025-05-07 16:16:33,050:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 46
2025-05-07 16:16:33,051:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:33,201:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001093 seconds.
2025-05-07 16:16:33,201:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:33,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:33,203:INFO:[LightGBM] [Info] Total Bins 1072
2025-05-07 16:16:33,203:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 45
2025-05-07 16:16:33,205:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:33,342:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001369 seconds.
2025-05-07 16:16:33,343:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:33,343:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:33,343:INFO:[LightGBM] [Info] Total Bins 1070
2025-05-07 16:16:33,344:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 44
2025-05-07 16:16:33,344:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:33,517:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,004361 seconds.
2025-05-07 16:16:33,518:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:16:33,518:INFO:[LightGBM] [Info] Total Bins 1068
2025-05-07 16:16:33,518:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 43
2025-05-07 16:16:33,519:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:33,689:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001256 seconds.
2025-05-07 16:16:33,690:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:33,690:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:33,690:INFO:[LightGBM] [Info] Total Bins 1066
2025-05-07 16:16:33,690:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 42
2025-05-07 16:16:33,691:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:33,876:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001078 seconds.
2025-05-07 16:16:33,877:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:33,877:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:33,877:INFO:[LightGBM] [Info] Total Bins 1064
2025-05-07 16:16:33,877:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 41
2025-05-07 16:16:33,878:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:34,019:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001158 seconds.
2025-05-07 16:16:34,020:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:34,020:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:34,020:INFO:[LightGBM] [Info] Total Bins 1062
2025-05-07 16:16:34,020:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 40
2025-05-07 16:16:34,020:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:34,171:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001436 seconds.
2025-05-07 16:16:34,171:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:34,171:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:34,172:INFO:[LightGBM] [Info] Total Bins 1060
2025-05-07 16:16:34,172:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 39
2025-05-07 16:16:34,172:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:34,326:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001057 seconds.
2025-05-07 16:16:34,326:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:34,327:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:34,327:INFO:[LightGBM] [Info] Total Bins 1058
2025-05-07 16:16:34,327:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 38
2025-05-07 16:16:34,328:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:34,469:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000940 seconds.
2025-05-07 16:16:34,469:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:34,470:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:34,470:INFO:[LightGBM] [Info] Total Bins 1056
2025-05-07 16:16:34,470:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 37
2025-05-07 16:16:34,471:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:34,608:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001071 seconds.
2025-05-07 16:16:34,608:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:34,608:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:34,609:INFO:[LightGBM] [Info] Total Bins 1054
2025-05-07 16:16:34,609:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 36
2025-05-07 16:16:34,609:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:34,758:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001158 seconds.
2025-05-07 16:16:34,758:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:34,758:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:34,759:INFO:[LightGBM] [Info] Total Bins 1052
2025-05-07 16:16:34,759:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 35
2025-05-07 16:16:34,759:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:34,898:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001053 seconds.
2025-05-07 16:16:34,898:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:34,898:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:34,923:INFO:[LightGBM] [Info] Total Bins 1050
2025-05-07 16:16:34,924:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 34
2025-05-07 16:16:34,924:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:35,074:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,003644 seconds.
2025-05-07 16:16:35,074:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:16:35,075:INFO:[LightGBM] [Info] Total Bins 1048
2025-05-07 16:16:35,075:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 33
2025-05-07 16:16:35,075:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:35,247:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000917 seconds.
2025-05-07 16:16:35,247:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:35,247:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:35,248:INFO:[LightGBM] [Info] Total Bins 1046
2025-05-07 16:16:35,248:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 32
2025-05-07 16:16:35,248:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:35,407:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001296 seconds.
2025-05-07 16:16:35,408:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:35,408:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:35,408:INFO:[LightGBM] [Info] Total Bins 1044
2025-05-07 16:16:35,408:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 31
2025-05-07 16:16:35,409:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:35,570:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000807 seconds.
2025-05-07 16:16:35,571:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:35,571:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:35,571:INFO:[LightGBM] [Info] Total Bins 1042
2025-05-07 16:16:35,571:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 30
2025-05-07 16:16:35,571:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:35,748:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001060 seconds.
2025-05-07 16:16:35,748:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:35,748:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:35,748:INFO:[LightGBM] [Info] Total Bins 1040
2025-05-07 16:16:35,749:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 29
2025-05-07 16:16:35,749:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:35,879:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000908 seconds.
2025-05-07 16:16:35,879:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:35,879:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:35,879:INFO:[LightGBM] [Info] Total Bins 1038
2025-05-07 16:16:35,880:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 28
2025-05-07 16:16:35,880:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:36,025:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,003015 seconds.
2025-05-07 16:16:36,025:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:16:36,025:INFO:[LightGBM] [Info] Total Bins 1036
2025-05-07 16:16:36,026:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 27
2025-05-07 16:16:36,026:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:36,173:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001095 seconds.
2025-05-07 16:16:36,173:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:36,173:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:36,173:INFO:[LightGBM] [Info] Total Bins 1034
2025-05-07 16:16:36,174:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 26
2025-05-07 16:16:36,174:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:36,358:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000896 seconds.
2025-05-07 16:16:36,358:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:36,358:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:36,359:INFO:[LightGBM] [Info] Total Bins 1032
2025-05-07 16:16:36,359:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 25
2025-05-07 16:16:36,359:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:36,497:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001605 seconds.
2025-05-07 16:16:36,497:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:36,497:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:36,497:INFO:[LightGBM] [Info] Total Bins 1030
2025-05-07 16:16:36,498:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 24
2025-05-07 16:16:36,498:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:36,660:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001126 seconds.
2025-05-07 16:16:36,660:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:36,661:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:36,661:INFO:[LightGBM] [Info] Total Bins 1028
2025-05-07 16:16:36,661:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 23
2025-05-07 16:16:36,661:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:36,847:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001128 seconds.
2025-05-07 16:16:36,847:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:36,847:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:36,848:INFO:[LightGBM] [Info] Total Bins 1026
2025-05-07 16:16:36,848:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 22
2025-05-07 16:16:36,848:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:37,030:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001039 seconds.
2025-05-07 16:16:37,030:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:37,032:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:37,032:INFO:[LightGBM] [Info] Total Bins 1024
2025-05-07 16:16:37,033:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 21
2025-05-07 16:16:37,034:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:37,232:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000783 seconds.
2025-05-07 16:16:37,232:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:37,232:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:37,232:INFO:[LightGBM] [Info] Total Bins 1022
2025-05-07 16:16:37,232:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 20
2025-05-07 16:16:37,232:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:37,360:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001102 seconds.
2025-05-07 16:16:37,360:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:37,360:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:37,360:INFO:[LightGBM] [Info] Total Bins 1020
2025-05-07 16:16:37,361:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 19
2025-05-07 16:16:37,361:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:37,488:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000914 seconds.
2025-05-07 16:16:37,489:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:37,489:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:37,489:INFO:[LightGBM] [Info] Total Bins 1018
2025-05-07 16:16:37,489:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 18
2025-05-07 16:16:37,490:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:37,650:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000835 seconds.
2025-05-07 16:16:37,651:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:37,651:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:37,651:INFO:[LightGBM] [Info] Total Bins 1016
2025-05-07 16:16:37,651:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 17
2025-05-07 16:16:37,652:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:37,797:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000853 seconds.
2025-05-07 16:16:37,797:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:37,797:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:37,798:INFO:[LightGBM] [Info] Total Bins 1014
2025-05-07 16:16:37,798:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 16
2025-05-07 16:16:37,798:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:37,924:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001424 seconds.
2025-05-07 16:16:37,924:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:37,924:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:37,925:INFO:[LightGBM] [Info] Total Bins 1012
2025-05-07 16:16:37,925:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 15
2025-05-07 16:16:37,925:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:38,071:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000849 seconds.
2025-05-07 16:16:38,071:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:38,071:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:38,072:INFO:[LightGBM] [Info] Total Bins 1010
2025-05-07 16:16:38,072:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 14
2025-05-07 16:16:38,073:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:38,189:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000972 seconds.
2025-05-07 16:16:38,189:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:38,189:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:38,189:INFO:[LightGBM] [Info] Total Bins 1008
2025-05-07 16:16:38,190:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 13
2025-05-07 16:16:38,190:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:38,316:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000943 seconds.
2025-05-07 16:16:38,317:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:38,317:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:38,317:INFO:[LightGBM] [Info] Total Bins 1006
2025-05-07 16:16:38,317:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 12
2025-05-07 16:16:38,318:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:38,441:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001597 seconds.
2025-05-07 16:16:38,441:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:38,441:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:38,442:INFO:[LightGBM] [Info] Total Bins 1004
2025-05-07 16:16:38,442:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 11
2025-05-07 16:16:38,442:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:38,557:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000662 seconds.
2025-05-07 16:16:38,558:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:38,558:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:38,558:INFO:[LightGBM] [Info] Total Bins 1002
2025-05-07 16:16:38,559:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 10
2025-05-07 16:16:38,560:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:38,665:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000641 seconds.
2025-05-07 16:16:38,665:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:38,665:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:38,666:INFO:[LightGBM] [Info] Total Bins 1000
2025-05-07 16:16:38,666:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 9
2025-05-07 16:16:38,666:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:38,776:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000685 seconds.
2025-05-07 16:16:38,776:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:38,776:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:38,776:INFO:[LightGBM] [Info] Total Bins 994
2025-05-07 16:16:38,777:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 8
2025-05-07 16:16:38,777:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:38,888:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000229 seconds.
2025-05-07 16:16:38,888:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:38,888:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:38,888:INFO:[LightGBM] [Info] Total Bins 992
2025-05-07 16:16:38,889:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 7
2025-05-07 16:16:38,889:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:38,996:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000236 seconds.
2025-05-07 16:16:38,996:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:38,997:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:38,997:INFO:[LightGBM] [Info] Total Bins 975
2025-05-07 16:16:38,997:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 6
2025-05-07 16:16:38,997:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:39,108:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000099 seconds.
2025-05-07 16:16:39,108:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:39,108:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:39,109:INFO:[LightGBM] [Info] Total Bins 961
2025-05-07 16:16:39,109:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 5
2025-05-07 16:16:39,109:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:39,195:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000091 seconds.
2025-05-07 16:16:39,196:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:39,196:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:39,196:INFO:[LightGBM] [Info] Total Bins 938
2025-05-07 16:16:39,196:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 4
2025-05-07 16:16:39,197:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:39,293:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000117 seconds.
2025-05-07 16:16:39,293:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:39,293:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:39,293:INFO:[LightGBM] [Info] Total Bins 684
2025-05-07 16:16:39,294:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 3
2025-05-07 16:16:39,294:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:39,419:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000100 seconds.
2025-05-07 16:16:39,420:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:39,420:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:39,420:INFO:[LightGBM] [Info] Total Bins 508
2025-05-07 16:16:39,420:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 2
2025-05-07 16:16:39,421:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:39,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000058 seconds.
2025-05-07 16:16:39,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:39,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:39,506:INFO:[LightGBM] [Info] Total Bins 253
2025-05-07 16:16:39,506:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 1
2025-05-07 16:16:39,506:INFO:[LightGBM] [Info] Start training from score 438100,989724
2025-05-07 16:16:39,645:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001357 seconds.
2025-05-07 16:16:39,646:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:39,646:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:39,646:INFO:[LightGBM] [Info] Total Bins 1117
2025-05-07 16:16:39,647:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 68
2025-05-07 16:16:39,647:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:39,815:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001266 seconds.
2025-05-07 16:16:39,815:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:39,815:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:39,815:INFO:[LightGBM] [Info] Total Bins 1115
2025-05-07 16:16:39,816:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:16:39,816:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:39,997:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001334 seconds.
2025-05-07 16:16:39,997:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:39,997:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:39,998:INFO:[LightGBM] [Info] Total Bins 1115
2025-05-07 16:16:39,998:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:16:39,999:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:40,175:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001334 seconds.
2025-05-07 16:16:40,175:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:40,176:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:40,176:INFO:[LightGBM] [Info] Total Bins 1115
2025-05-07 16:16:40,176:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:16:40,177:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:40,330:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001172 seconds.
2025-05-07 16:16:40,332:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:40,332:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:40,332:INFO:[LightGBM] [Info] Total Bins 1113
2025-05-07 16:16:40,332:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:16:40,333:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:40,485:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001348 seconds.
2025-05-07 16:16:40,485:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:40,485:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:40,485:INFO:[LightGBM] [Info] Total Bins 1113
2025-05-07 16:16:40,486:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:16:40,486:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:40,641:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001457 seconds.
2025-05-07 16:16:40,641:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:40,642:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:40,642:INFO:[LightGBM] [Info] Total Bins 1111
2025-05-07 16:16:40,642:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:16:40,642:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:40,799:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000767 seconds.
2025-05-07 16:16:40,799:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:40,799:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:40,800:INFO:[LightGBM] [Info] Total Bins 1109
2025-05-07 16:16:40,800:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:16:40,801:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:41,014:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001255 seconds.
2025-05-07 16:16:41,014:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:41,014:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:41,015:INFO:[LightGBM] [Info] Total Bins 1109
2025-05-07 16:16:41,015:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:16:41,016:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:41,194:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001391 seconds.
2025-05-07 16:16:41,195:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:41,195:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:41,195:INFO:[LightGBM] [Info] Total Bins 1107
2025-05-07 16:16:41,195:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:16:41,196:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:41,352:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001326 seconds.
2025-05-07 16:16:41,352:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:41,353:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:41,353:INFO:[LightGBM] [Info] Total Bins 1107
2025-05-07 16:16:41,353:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:16:41,354:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:41,527:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001672 seconds.
2025-05-07 16:16:41,528:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:41,528:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:41,528:INFO:[LightGBM] [Info] Total Bins 1107
2025-05-07 16:16:41,529:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:16:41,529:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:41,690:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001400 seconds.
2025-05-07 16:16:41,690:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:41,690:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:41,691:INFO:[LightGBM] [Info] Total Bins 1107
2025-05-07 16:16:41,691:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:16:41,691:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:41,872:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001372 seconds.
2025-05-07 16:16:41,873:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:41,873:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:41,873:INFO:[LightGBM] [Info] Total Bins 1107
2025-05-07 16:16:41,874:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:16:41,875:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:42,030:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001069 seconds.
2025-05-07 16:16:42,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:42,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:42,031:INFO:[LightGBM] [Info] Total Bins 1105
2025-05-07 16:16:42,032:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:16:42,032:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:42,186:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001467 seconds.
2025-05-07 16:16:42,186:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:42,187:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:42,187:INFO:[LightGBM] [Info] Total Bins 1103
2025-05-07 16:16:42,187:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 61
2025-05-07 16:16:42,188:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:42,339:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001507 seconds.
2025-05-07 16:16:42,339:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:42,339:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:42,340:INFO:[LightGBM] [Info] Total Bins 1101
2025-05-07 16:16:42,340:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:16:42,341:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:42,512:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001508 seconds.
2025-05-07 16:16:42,513:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:42,513:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:42,513:INFO:[LightGBM] [Info] Total Bins 1099
2025-05-07 16:16:42,513:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:16:42,514:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:42,677:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000937 seconds.
2025-05-07 16:16:42,677:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:42,677:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:42,678:INFO:[LightGBM] [Info] Total Bins 1097
2025-05-07 16:16:42,678:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 58
2025-05-07 16:16:42,678:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:42,825:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001185 seconds.
2025-05-07 16:16:42,826:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:42,826:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:42,826:INFO:[LightGBM] [Info] Total Bins 1095
2025-05-07 16:16:42,827:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 57
2025-05-07 16:16:42,827:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:42,970:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001615 seconds.
2025-05-07 16:16:42,970:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:42,970:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:42,971:INFO:[LightGBM] [Info] Total Bins 1093
2025-05-07 16:16:42,971:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 56
2025-05-07 16:16:42,972:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:43,120:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001365 seconds.
2025-05-07 16:16:43,121:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:43,121:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:43,121:INFO:[LightGBM] [Info] Total Bins 1091
2025-05-07 16:16:43,122:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 55
2025-05-07 16:16:43,122:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:43,287:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001432 seconds.
2025-05-07 16:16:43,287:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:43,287:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:43,288:INFO:[LightGBM] [Info] Total Bins 1089
2025-05-07 16:16:43,288:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:16:43,289:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:43,477:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001178 seconds.
2025-05-07 16:16:43,478:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:43,478:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:43,478:INFO:[LightGBM] [Info] Total Bins 1087
2025-05-07 16:16:43,478:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 53
2025-05-07 16:16:43,479:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:43,635:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001299 seconds.
2025-05-07 16:16:43,636:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:43,636:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:43,637:INFO:[LightGBM] [Info] Total Bins 1085
2025-05-07 16:16:43,637:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 52
2025-05-07 16:16:43,637:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:43,788:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001402 seconds.
2025-05-07 16:16:43,789:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:43,789:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:43,789:INFO:[LightGBM] [Info] Total Bins 1083
2025-05-07 16:16:43,790:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 51
2025-05-07 16:16:43,790:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:43,955:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001256 seconds.
2025-05-07 16:16:43,956:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:43,956:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:43,956:INFO:[LightGBM] [Info] Total Bins 1081
2025-05-07 16:16:43,956:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 50
2025-05-07 16:16:43,957:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:44,102:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000780 seconds.
2025-05-07 16:16:44,103:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:44,103:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:44,103:INFO:[LightGBM] [Info] Total Bins 1079
2025-05-07 16:16:44,104:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 49
2025-05-07 16:16:44,104:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:44,248:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001051 seconds.
2025-05-07 16:16:44,248:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:44,248:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:44,249:INFO:[LightGBM] [Info] Total Bins 1077
2025-05-07 16:16:44,249:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 48
2025-05-07 16:16:44,250:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:44,386:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001222 seconds.
2025-05-07 16:16:44,386:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:44,387:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:44,387:INFO:[LightGBM] [Info] Total Bins 1075
2025-05-07 16:16:44,387:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 47
2025-05-07 16:16:44,388:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:44,527:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001079 seconds.
2025-05-07 16:16:44,527:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:44,527:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:44,527:INFO:[LightGBM] [Info] Total Bins 1073
2025-05-07 16:16:44,528:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 46
2025-05-07 16:16:44,528:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:44,666:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001601 seconds.
2025-05-07 16:16:44,667:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:44,667:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:44,667:INFO:[LightGBM] [Info] Total Bins 1071
2025-05-07 16:16:44,668:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 45
2025-05-07 16:16:44,668:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:44,805:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001181 seconds.
2025-05-07 16:16:44,806:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:44,806:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:44,806:INFO:[LightGBM] [Info] Total Bins 1069
2025-05-07 16:16:44,807:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 44
2025-05-07 16:16:44,807:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:44,947:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001133 seconds.
2025-05-07 16:16:44,948:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:44,948:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:44,948:INFO:[LightGBM] [Info] Total Bins 1067
2025-05-07 16:16:44,948:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 43
2025-05-07 16:16:44,949:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:45,110:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000853 seconds.
2025-05-07 16:16:45,111:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:45,111:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:45,111:INFO:[LightGBM] [Info] Total Bins 1065
2025-05-07 16:16:45,112:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 42
2025-05-07 16:16:45,113:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:45,265:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000912 seconds.
2025-05-07 16:16:45,265:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:45,266:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:45,266:INFO:[LightGBM] [Info] Total Bins 1063
2025-05-07 16:16:45,267:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 41
2025-05-07 16:16:45,267:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:45,418:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001290 seconds.
2025-05-07 16:16:45,418:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:45,419:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:45,419:INFO:[LightGBM] [Info] Total Bins 1061
2025-05-07 16:16:45,419:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 40
2025-05-07 16:16:45,420:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:45,581:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000977 seconds.
2025-05-07 16:16:45,582:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:45,582:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:45,583:INFO:[LightGBM] [Info] Total Bins 1059
2025-05-07 16:16:45,583:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 39
2025-05-07 16:16:45,584:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:45,737:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001320 seconds.
2025-05-07 16:16:45,737:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:45,737:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:45,738:INFO:[LightGBM] [Info] Total Bins 1057
2025-05-07 16:16:45,738:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 38
2025-05-07 16:16:45,738:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:45,884:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001113 seconds.
2025-05-07 16:16:45,885:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:45,885:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:45,885:INFO:[LightGBM] [Info] Total Bins 1055
2025-05-07 16:16:45,885:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 37
2025-05-07 16:16:45,886:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:46,044:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000907 seconds.
2025-05-07 16:16:46,044:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:46,045:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:46,045:INFO:[LightGBM] [Info] Total Bins 1053
2025-05-07 16:16:46,045:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 36
2025-05-07 16:16:46,045:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:46,199:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001186 seconds.
2025-05-07 16:16:46,200:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:46,200:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:46,200:INFO:[LightGBM] [Info] Total Bins 1051
2025-05-07 16:16:46,201:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 35
2025-05-07 16:16:46,201:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:46,343:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000934 seconds.
2025-05-07 16:16:46,343:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:46,343:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:46,344:INFO:[LightGBM] [Info] Total Bins 1049
2025-05-07 16:16:46,344:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 34
2025-05-07 16:16:46,344:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:46,480:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000737 seconds.
2025-05-07 16:16:46,480:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:46,481:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:46,481:INFO:[LightGBM] [Info] Total Bins 1047
2025-05-07 16:16:46,481:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 33
2025-05-07 16:16:46,481:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:46,628:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000769 seconds.
2025-05-07 16:16:46,628:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:46,629:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:46,629:INFO:[LightGBM] [Info] Total Bins 1045
2025-05-07 16:16:46,629:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 32
2025-05-07 16:16:46,630:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:46,749:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001696 seconds.
2025-05-07 16:16:46,750:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:46,750:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:46,750:INFO:[LightGBM] [Info] Total Bins 1043
2025-05-07 16:16:46,750:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 31
2025-05-07 16:16:46,751:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:46,874:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000957 seconds.
2025-05-07 16:16:46,875:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:46,875:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:46,877:INFO:[LightGBM] [Info] Total Bins 1041
2025-05-07 16:16:46,877:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 30
2025-05-07 16:16:46,877:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:47,097:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001096 seconds.
2025-05-07 16:16:47,097:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:47,098:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:47,099:INFO:[LightGBM] [Info] Total Bins 1039
2025-05-07 16:16:47,099:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 29
2025-05-07 16:16:47,100:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:47,248:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001158 seconds.
2025-05-07 16:16:47,248:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:47,249:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:47,249:INFO:[LightGBM] [Info] Total Bins 1037
2025-05-07 16:16:47,249:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 28
2025-05-07 16:16:47,249:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:47,428:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001154 seconds.
2025-05-07 16:16:47,428:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:47,429:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:47,429:INFO:[LightGBM] [Info] Total Bins 1035
2025-05-07 16:16:47,429:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 27
2025-05-07 16:16:47,430:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:47,580:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000833 seconds.
2025-05-07 16:16:47,581:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:47,581:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:47,581:INFO:[LightGBM] [Info] Total Bins 1033
2025-05-07 16:16:47,582:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 26
2025-05-07 16:16:47,582:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:47,711:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001061 seconds.
2025-05-07 16:16:47,711:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:47,711:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:47,712:INFO:[LightGBM] [Info] Total Bins 1031
2025-05-07 16:16:47,712:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 25
2025-05-07 16:16:47,712:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:47,833:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001099 seconds.
2025-05-07 16:16:47,833:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:47,835:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:47,835:INFO:[LightGBM] [Info] Total Bins 1029
2025-05-07 16:16:47,835:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 24
2025-05-07 16:16:47,836:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:47,958:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001140 seconds.
2025-05-07 16:16:47,958:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:47,958:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:47,959:INFO:[LightGBM] [Info] Total Bins 1027
2025-05-07 16:16:47,959:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 23
2025-05-07 16:16:47,959:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:48,101:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000893 seconds.
2025-05-07 16:16:48,102:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:48,102:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:48,102:INFO:[LightGBM] [Info] Total Bins 1025
2025-05-07 16:16:48,103:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 22
2025-05-07 16:16:48,103:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:48,269:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001319 seconds.
2025-05-07 16:16:48,269:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:48,270:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:48,271:INFO:[LightGBM] [Info] Total Bins 1023
2025-05-07 16:16:48,271:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 21
2025-05-07 16:16:48,271:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:48,433:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001264 seconds.
2025-05-07 16:16:48,433:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:48,434:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:48,434:INFO:[LightGBM] [Info] Total Bins 1021
2025-05-07 16:16:48,434:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 20
2025-05-07 16:16:48,435:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:48,560:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001366 seconds.
2025-05-07 16:16:48,560:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:48,560:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:48,560:INFO:[LightGBM] [Info] Total Bins 1019
2025-05-07 16:16:48,561:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 19
2025-05-07 16:16:48,561:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:48,678:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000646 seconds.
2025-05-07 16:16:48,678:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:48,679:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:48,679:INFO:[LightGBM] [Info] Total Bins 1017
2025-05-07 16:16:48,679:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 18
2025-05-07 16:16:48,679:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:48,793:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000986 seconds.
2025-05-07 16:16:48,793:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:48,794:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:48,794:INFO:[LightGBM] [Info] Total Bins 1015
2025-05-07 16:16:48,794:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 17
2025-05-07 16:16:48,795:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:48,909:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001218 seconds.
2025-05-07 16:16:48,909:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:48,909:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:48,910:INFO:[LightGBM] [Info] Total Bins 1013
2025-05-07 16:16:48,910:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 16
2025-05-07 16:16:48,910:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:49,026:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001266 seconds.
2025-05-07 16:16:49,027:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:49,027:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:49,027:INFO:[LightGBM] [Info] Total Bins 1011
2025-05-07 16:16:49,027:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 15
2025-05-07 16:16:49,028:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:49,141:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001100 seconds.
2025-05-07 16:16:49,141:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:49,141:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:49,142:INFO:[LightGBM] [Info] Total Bins 1009
2025-05-07 16:16:49,142:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 14
2025-05-07 16:16:49,142:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:49,254:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001087 seconds.
2025-05-07 16:16:49,255:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:49,255:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:49,255:INFO:[LightGBM] [Info] Total Bins 1007
2025-05-07 16:16:49,255:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 13
2025-05-07 16:16:49,256:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:49,375:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001139 seconds.
2025-05-07 16:16:49,376:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:49,376:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:49,376:INFO:[LightGBM] [Info] Total Bins 1005
2025-05-07 16:16:49,376:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 12
2025-05-07 16:16:49,377:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:49,487:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000597 seconds.
2025-05-07 16:16:49,488:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:49,488:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:49,488:INFO:[LightGBM] [Info] Total Bins 1003
2025-05-07 16:16:49,488:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 11
2025-05-07 16:16:49,489:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:49,597:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000697 seconds.
2025-05-07 16:16:49,598:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:49,598:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:49,598:INFO:[LightGBM] [Info] Total Bins 1001
2025-05-07 16:16:49,598:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 10
2025-05-07 16:16:49,599:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:49,714:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000196 seconds.
2025-05-07 16:16:49,714:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:49,714:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:49,714:INFO:[LightGBM] [Info] Total Bins 999
2025-05-07 16:16:49,715:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 9
2025-05-07 16:16:49,715:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:49,818:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000148 seconds.
2025-05-07 16:16:49,819:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:49,819:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:49,819:INFO:[LightGBM] [Info] Total Bins 997
2025-05-07 16:16:49,820:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 8
2025-05-07 16:16:49,820:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:49,923:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,001004 seconds.
2025-05-07 16:16:49,924:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:16:49,924:INFO:[LightGBM] [Info] Total Bins 991
2025-05-07 16:16:49,924:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 7
2025-05-07 16:16:49,925:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:50,026:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000166 seconds.
2025-05-07 16:16:50,027:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:50,027:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:50,027:INFO:[LightGBM] [Info] Total Bins 974
2025-05-07 16:16:50,027:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 6
2025-05-07 16:16:50,028:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:50,156:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000112 seconds.
2025-05-07 16:16:50,157:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:50,157:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:50,157:INFO:[LightGBM] [Info] Total Bins 959
2025-05-07 16:16:50,157:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 5
2025-05-07 16:16:50,158:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:50,253:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000091 seconds.
2025-05-07 16:16:50,253:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:50,253:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:50,254:INFO:[LightGBM] [Info] Total Bins 935
2025-05-07 16:16:50,255:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 4
2025-05-07 16:16:50,255:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:50,350:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000431 seconds.
2025-05-07 16:16:50,350:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:16:50,350:INFO:[LightGBM] [Info] Total Bins 681
2025-05-07 16:16:50,350:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 3
2025-05-07 16:16:50,351:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:50,434:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000081 seconds.
2025-05-07 16:16:50,434:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:50,435:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:50,435:INFO:[LightGBM] [Info] Total Bins 508
2025-05-07 16:16:50,435:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 2
2025-05-07 16:16:50,435:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:50,516:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000072 seconds.
2025-05-07 16:16:50,517:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:50,517:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:50,517:INFO:[LightGBM] [Info] Total Bins 253
2025-05-07 16:16:50,518:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 1
2025-05-07 16:16:50,518:INFO:[LightGBM] [Info] Start training from score 437990,407469
2025-05-07 16:16:50,661:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001301 seconds.
2025-05-07 16:16:50,661:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:50,661:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:50,661:INFO:[LightGBM] [Info] Total Bins 1119
2025-05-07 16:16:50,662:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 68
2025-05-07 16:16:50,662:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:50,816:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001115 seconds.
2025-05-07 16:16:50,817:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:50,817:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:50,817:INFO:[LightGBM] [Info] Total Bins 1117
2025-05-07 16:16:50,818:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:16:50,818:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:50,968:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001090 seconds.
2025-05-07 16:16:50,968:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:50,969:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:50,969:INFO:[LightGBM] [Info] Total Bins 1115
2025-05-07 16:16:50,970:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:16:50,970:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:51,125:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001178 seconds.
2025-05-07 16:16:51,126:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:51,126:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:51,126:INFO:[LightGBM] [Info] Total Bins 1113
2025-05-07 16:16:51,127:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:16:51,127:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:51,297:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001192 seconds.
2025-05-07 16:16:51,297:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:51,297:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:51,298:INFO:[LightGBM] [Info] Total Bins 1111
2025-05-07 16:16:51,298:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:16:51,298:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:51,486:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001693 seconds.
2025-05-07 16:16:51,487:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:51,487:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:51,487:INFO:[LightGBM] [Info] Total Bins 1109
2025-05-07 16:16:51,488:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:16:51,488:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:51,638:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001657 seconds.
2025-05-07 16:16:51,639:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:51,639:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:51,639:INFO:[LightGBM] [Info] Total Bins 1107
2025-05-07 16:16:51,640:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:16:51,640:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:51,789:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001363 seconds.
2025-05-07 16:16:51,790:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:51,790:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:51,790:INFO:[LightGBM] [Info] Total Bins 1107
2025-05-07 16:16:51,790:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:16:51,791:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:51,944:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001138 seconds.
2025-05-07 16:16:51,944:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:51,945:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:51,945:INFO:[LightGBM] [Info] Total Bins 1107
2025-05-07 16:16:51,945:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:16:51,946:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:52,096:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000932 seconds.
2025-05-07 16:16:52,096:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:52,097:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:52,097:INFO:[LightGBM] [Info] Total Bins 1105
2025-05-07 16:16:52,097:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 61
2025-05-07 16:16:52,098:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:52,283:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001398 seconds.
2025-05-07 16:16:52,283:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:52,283:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:52,284:INFO:[LightGBM] [Info] Total Bins 1103
2025-05-07 16:16:52,284:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:16:52,285:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:52,473:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001301 seconds.
2025-05-07 16:16:52,473:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:52,473:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:52,474:INFO:[LightGBM] [Info] Total Bins 1101
2025-05-07 16:16:52,474:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:16:52,474:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:52,665:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001290 seconds.
2025-05-07 16:16:52,666:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:52,666:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:52,666:INFO:[LightGBM] [Info] Total Bins 1101
2025-05-07 16:16:52,667:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:16:52,667:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:52,835:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001223 seconds.
2025-05-07 16:16:52,836:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:52,836:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:52,836:INFO:[LightGBM] [Info] Total Bins 1101
2025-05-07 16:16:52,837:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:16:52,837:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:52,991:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001264 seconds.
2025-05-07 16:16:52,991:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:52,992:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:52,992:INFO:[LightGBM] [Info] Total Bins 1101
2025-05-07 16:16:52,993:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:16:52,993:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:53,161:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001304 seconds.
2025-05-07 16:16:53,161:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:53,161:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:53,162:INFO:[LightGBM] [Info] Total Bins 1099
2025-05-07 16:16:53,162:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 58
2025-05-07 16:16:53,162:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:53,315:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001051 seconds.
2025-05-07 16:16:53,315:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:53,315:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:53,316:INFO:[LightGBM] [Info] Total Bins 1097
2025-05-07 16:16:53,316:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 57
2025-05-07 16:16:53,317:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:53,479:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001361 seconds.
2025-05-07 16:16:53,479:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:53,480:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:53,480:INFO:[LightGBM] [Info] Total Bins 1095
2025-05-07 16:16:53,480:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 56
2025-05-07 16:16:53,481:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:53,628:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001620 seconds.
2025-05-07 16:16:53,628:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:53,628:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:53,629:INFO:[LightGBM] [Info] Total Bins 1093
2025-05-07 16:16:53,629:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 55
2025-05-07 16:16:53,629:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:53,788:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001555 seconds.
2025-05-07 16:16:53,788:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:53,788:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:53,788:INFO:[LightGBM] [Info] Total Bins 1091
2025-05-07 16:16:53,789:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:16:53,789:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:54,000:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001263 seconds.
2025-05-07 16:16:54,001:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:54,001:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:54,001:INFO:[LightGBM] [Info] Total Bins 1091
2025-05-07 16:16:54,002:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:16:54,002:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:54,171:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,004982 seconds.
2025-05-07 16:16:54,172:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:16:54,173:INFO:[LightGBM] [Info] Total Bins 1091
2025-05-07 16:16:54,173:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:16:54,174:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:54,366:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001264 seconds.
2025-05-07 16:16:54,366:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:54,367:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:54,367:INFO:[LightGBM] [Info] Total Bins 1091
2025-05-07 16:16:54,367:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:16:54,368:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:54,527:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001403 seconds.
2025-05-07 16:16:54,527:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:54,528:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:54,528:INFO:[LightGBM] [Info] Total Bins 1089
2025-05-07 16:16:54,528:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 53
2025-05-07 16:16:54,529:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:54,685:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001299 seconds.
2025-05-07 16:16:54,685:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:54,686:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:54,686:INFO:[LightGBM] [Info] Total Bins 1087
2025-05-07 16:16:54,686:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 52
2025-05-07 16:16:54,687:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:54,842:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001462 seconds.
2025-05-07 16:16:54,842:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:54,842:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:54,842:INFO:[LightGBM] [Info] Total Bins 1085
2025-05-07 16:16:54,842:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 51
2025-05-07 16:16:54,843:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:54,999:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001625 seconds.
2025-05-07 16:16:55,000:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:55,000:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:55,000:INFO:[LightGBM] [Info] Total Bins 1083
2025-05-07 16:16:55,001:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 50
2025-05-07 16:16:55,001:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:55,160:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001344 seconds.
2025-05-07 16:16:55,161:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:55,161:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:55,161:INFO:[LightGBM] [Info] Total Bins 1081
2025-05-07 16:16:55,161:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 49
2025-05-07 16:16:55,161:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:55,325:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001655 seconds.
2025-05-07 16:16:55,326:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:55,326:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:55,326:INFO:[LightGBM] [Info] Total Bins 1079
2025-05-07 16:16:55,326:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 48
2025-05-07 16:16:55,327:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:55,506:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001214 seconds.
2025-05-07 16:16:55,506:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:55,506:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:55,506:INFO:[LightGBM] [Info] Total Bins 1077
2025-05-07 16:16:55,507:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 47
2025-05-07 16:16:55,507:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:55,652:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001136 seconds.
2025-05-07 16:16:55,653:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:55,653:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:55,653:INFO:[LightGBM] [Info] Total Bins 1075
2025-05-07 16:16:55,654:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 46
2025-05-07 16:16:55,654:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:55,792:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001403 seconds.
2025-05-07 16:16:55,792:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:55,792:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:55,793:INFO:[LightGBM] [Info] Total Bins 1073
2025-05-07 16:16:55,793:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 45
2025-05-07 16:16:55,793:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:55,934:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,004647 seconds.
2025-05-07 16:16:55,934:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:16:55,935:INFO:[LightGBM] [Info] Total Bins 1071
2025-05-07 16:16:55,935:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 44
2025-05-07 16:16:55,936:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:56,111:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,005401 seconds.
2025-05-07 16:16:56,111:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:16:56,111:INFO:[LightGBM] [Info] Total Bins 1069
2025-05-07 16:16:56,112:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 43
2025-05-07 16:16:56,112:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:56,284:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001137 seconds.
2025-05-07 16:16:56,284:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:56,284:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:56,285:INFO:[LightGBM] [Info] Total Bins 1067
2025-05-07 16:16:56,285:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 42
2025-05-07 16:16:56,286:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:56,454:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001182 seconds.
2025-05-07 16:16:56,454:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:56,454:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:56,455:INFO:[LightGBM] [Info] Total Bins 1065
2025-05-07 16:16:56,455:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 41
2025-05-07 16:16:56,455:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:56,594:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000982 seconds.
2025-05-07 16:16:56,594:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:56,595:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:56,595:INFO:[LightGBM] [Info] Total Bins 1063
2025-05-07 16:16:56,595:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 40
2025-05-07 16:16:56,596:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:56,731:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000845 seconds.
2025-05-07 16:16:56,731:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:56,731:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:56,732:INFO:[LightGBM] [Info] Total Bins 1061
2025-05-07 16:16:56,732:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 39
2025-05-07 16:16:56,732:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:56,864:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001020 seconds.
2025-05-07 16:16:56,865:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:56,865:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:56,865:INFO:[LightGBM] [Info] Total Bins 1059
2025-05-07 16:16:56,865:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 38
2025-05-07 16:16:56,866:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:57,005:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001294 seconds.
2025-05-07 16:16:57,005:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:57,005:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:57,006:INFO:[LightGBM] [Info] Total Bins 1057
2025-05-07 16:16:57,006:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 37
2025-05-07 16:16:57,006:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:57,147:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000859 seconds.
2025-05-07 16:16:57,147:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:57,148:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:57,148:INFO:[LightGBM] [Info] Total Bins 1055
2025-05-07 16:16:57,148:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 36
2025-05-07 16:16:57,148:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:57,282:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000962 seconds.
2025-05-07 16:16:57,283:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:57,284:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:57,284:INFO:[LightGBM] [Info] Total Bins 1053
2025-05-07 16:16:57,284:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 35
2025-05-07 16:16:57,285:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:57,431:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000957 seconds.
2025-05-07 16:16:57,431:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:57,431:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:57,431:INFO:[LightGBM] [Info] Total Bins 1051
2025-05-07 16:16:57,431:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 34
2025-05-07 16:16:57,432:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:57,576:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000945 seconds.
2025-05-07 16:16:57,576:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:57,576:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:57,577:INFO:[LightGBM] [Info] Total Bins 1049
2025-05-07 16:16:57,577:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 33
2025-05-07 16:16:57,577:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:57,730:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000935 seconds.
2025-05-07 16:16:57,730:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:57,730:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:57,730:INFO:[LightGBM] [Info] Total Bins 1047
2025-05-07 16:16:57,731:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 32
2025-05-07 16:16:57,731:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:57,867:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000941 seconds.
2025-05-07 16:16:57,867:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:57,867:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:57,867:INFO:[LightGBM] [Info] Total Bins 1045
2025-05-07 16:16:57,868:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 31
2025-05-07 16:16:57,868:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:58,058:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001529 seconds.
2025-05-07 16:16:58,059:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:58,059:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:58,059:INFO:[LightGBM] [Info] Total Bins 1043
2025-05-07 16:16:58,059:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 30
2025-05-07 16:16:58,060:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:58,200:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001114 seconds.
2025-05-07 16:16:58,200:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:58,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:58,201:INFO:[LightGBM] [Info] Total Bins 1041
2025-05-07 16:16:58,201:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 29
2025-05-07 16:16:58,201:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:58,331:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000868 seconds.
2025-05-07 16:16:58,332:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:58,333:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:58,333:INFO:[LightGBM] [Info] Total Bins 1039
2025-05-07 16:16:58,333:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 28
2025-05-07 16:16:58,334:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:58,482:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001191 seconds.
2025-05-07 16:16:58,482:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:58,482:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:58,482:INFO:[LightGBM] [Info] Total Bins 1037
2025-05-07 16:16:58,484:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 27
2025-05-07 16:16:58,484:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:58,611:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000861 seconds.
2025-05-07 16:16:58,611:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:58,611:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:58,611:INFO:[LightGBM] [Info] Total Bins 1035
2025-05-07 16:16:58,612:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 26
2025-05-07 16:16:58,612:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:58,737:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001215 seconds.
2025-05-07 16:16:58,738:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:58,738:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:58,738:INFO:[LightGBM] [Info] Total Bins 1033
2025-05-07 16:16:58,738:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 25
2025-05-07 16:16:58,739:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:58,860:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000859 seconds.
2025-05-07 16:16:58,860:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:58,861:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:58,861:INFO:[LightGBM] [Info] Total Bins 1031
2025-05-07 16:16:58,861:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 24
2025-05-07 16:16:58,861:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:58,982:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001018 seconds.
2025-05-07 16:16:58,984:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:58,984:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:58,984:INFO:[LightGBM] [Info] Total Bins 1029
2025-05-07 16:16:58,985:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 23
2025-05-07 16:16:58,985:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:59,111:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001060 seconds.
2025-05-07 16:16:59,111:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:59,111:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:59,111:INFO:[LightGBM] [Info] Total Bins 1027
2025-05-07 16:16:59,111:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 22
2025-05-07 16:16:59,112:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:59,239:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000854 seconds.
2025-05-07 16:16:59,239:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:59,239:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:59,240:INFO:[LightGBM] [Info] Total Bins 1025
2025-05-07 16:16:59,240:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 21
2025-05-07 16:16:59,240:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:59,376:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000947 seconds.
2025-05-07 16:16:59,377:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:59,377:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:59,377:INFO:[LightGBM] [Info] Total Bins 1023
2025-05-07 16:16:59,377:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 20
2025-05-07 16:16:59,378:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:59,542:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001264 seconds.
2025-05-07 16:16:59,542:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:59,542:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:59,542:INFO:[LightGBM] [Info] Total Bins 1021
2025-05-07 16:16:59,544:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 19
2025-05-07 16:16:59,544:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:59,677:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001066 seconds.
2025-05-07 16:16:59,677:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:59,678:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:59,678:INFO:[LightGBM] [Info] Total Bins 1019
2025-05-07 16:16:59,678:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 18
2025-05-07 16:16:59,678:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:59,791:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001291 seconds.
2025-05-07 16:16:59,791:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:59,792:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:59,792:INFO:[LightGBM] [Info] Total Bins 1017
2025-05-07 16:16:59,792:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 17
2025-05-07 16:16:59,792:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:16:59,904:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001022 seconds.
2025-05-07 16:16:59,904:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:16:59,904:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:16:59,904:INFO:[LightGBM] [Info] Total Bins 1015
2025-05-07 16:16:59,905:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 16
2025-05-07 16:16:59,905:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:17:00,022:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001271 seconds.
2025-05-07 16:17:00,022:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:00,022:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:00,022:INFO:[LightGBM] [Info] Total Bins 1013
2025-05-07 16:17:00,024:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 15
2025-05-07 16:17:00,024:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:17:00,140:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001153 seconds.
2025-05-07 16:17:00,141:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:00,141:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:00,141:INFO:[LightGBM] [Info] Total Bins 1011
2025-05-07 16:17:00,141:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 14
2025-05-07 16:17:00,142:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:17:00,258:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000893 seconds.
2025-05-07 16:17:00,258:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:00,258:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:00,259:INFO:[LightGBM] [Info] Total Bins 1009
2025-05-07 16:17:00,259:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 13
2025-05-07 16:17:00,259:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:17:00,377:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001124 seconds.
2025-05-07 16:17:00,377:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:00,378:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:00,378:INFO:[LightGBM] [Info] Total Bins 1007
2025-05-07 16:17:00,379:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 12
2025-05-07 16:17:00,380:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:17:00,543:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000784 seconds.
2025-05-07 16:17:00,543:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:00,543:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:00,543:INFO:[LightGBM] [Info] Total Bins 1005
2025-05-07 16:17:00,544:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 11
2025-05-07 16:17:00,544:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:17:00,657:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000685 seconds.
2025-05-07 16:17:00,657:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:00,657:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:00,657:INFO:[LightGBM] [Info] Total Bins 1003
2025-05-07 16:17:00,658:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 10
2025-05-07 16:17:00,658:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:17:00,776:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000615 seconds.
2025-05-07 16:17:00,776:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:00,776:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:00,777:INFO:[LightGBM] [Info] Total Bins 997
2025-05-07 16:17:00,777:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 9
2025-05-07 16:17:00,777:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:17:00,875:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000150 seconds.
2025-05-07 16:17:00,876:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:00,876:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:00,876:INFO:[LightGBM] [Info] Total Bins 995
2025-05-07 16:17:00,876:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 8
2025-05-07 16:17:00,877:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:17:00,981:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000225 seconds.
2025-05-07 16:17:00,981:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:00,981:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:00,982:INFO:[LightGBM] [Info] Total Bins 993
2025-05-07 16:17:00,982:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 7
2025-05-07 16:17:00,982:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:17:01,080:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000148 seconds.
2025-05-07 16:17:01,080:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:01,081:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:01,081:INFO:[LightGBM] [Info] Total Bins 976
2025-05-07 16:17:01,081:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 6
2025-05-07 16:17:01,081:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:17:01,171:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000114 seconds.
2025-05-07 16:17:01,172:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:01,172:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:01,172:INFO:[LightGBM] [Info] Total Bins 962
2025-05-07 16:17:01,172:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 5
2025-05-07 16:17:01,173:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:17:01,270:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000120 seconds.
2025-05-07 16:17:01,270:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:01,270:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:01,270:INFO:[LightGBM] [Info] Total Bins 938
2025-05-07 16:17:01,270:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 4
2025-05-07 16:17:01,270:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:17:01,353:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000112 seconds.
2025-05-07 16:17:01,353:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:01,353:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:01,354:INFO:[LightGBM] [Info] Total Bins 684
2025-05-07 16:17:01,354:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 3
2025-05-07 16:17:01,354:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:17:01,470:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000080 seconds.
2025-05-07 16:17:01,471:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:01,471:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:01,471:INFO:[LightGBM] [Info] Total Bins 508
2025-05-07 16:17:01,472:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 2
2025-05-07 16:17:01,473:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:17:01,561:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000074 seconds.
2025-05-07 16:17:01,561:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:01,561:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:01,562:INFO:[LightGBM] [Info] Total Bins 253
2025-05-07 16:17:01,562:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 1
2025-05-07 16:17:01,563:INFO:[LightGBM] [Info] Start training from score 437125,172103
2025-05-07 16:17:01,712:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001542 seconds.
2025-05-07 16:17:01,713:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:01,713:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:01,713:INFO:[LightGBM] [Info] Total Bins 1121
2025-05-07 16:17:01,714:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 69
2025-05-07 16:17:01,714:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:01,875:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001089 seconds.
2025-05-07 16:17:01,876:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:01,876:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:01,876:INFO:[LightGBM] [Info] Total Bins 1119
2025-05-07 16:17:01,876:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 68
2025-05-07 16:17:01,877:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:02,044:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001606 seconds.
2025-05-07 16:17:02,044:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:02,045:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:02,045:INFO:[LightGBM] [Info] Total Bins 1117
2025-05-07 16:17:02,045:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:17:02,046:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:02,218:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001040 seconds.
2025-05-07 16:17:02,219:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:02,219:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:02,219:INFO:[LightGBM] [Info] Total Bins 1117
2025-05-07 16:17:02,220:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:17:02,221:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:02,389:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001666 seconds.
2025-05-07 16:17:02,389:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:02,389:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:02,390:INFO:[LightGBM] [Info] Total Bins 1115
2025-05-07 16:17:02,390:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:17:02,391:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:02,544:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001214 seconds.
2025-05-07 16:17:02,545:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:02,545:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:02,545:INFO:[LightGBM] [Info] Total Bins 1115
2025-05-07 16:17:02,545:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:17:02,546:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:02,721:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001699 seconds.
2025-05-07 16:17:02,722:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:02,723:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:02,723:INFO:[LightGBM] [Info] Total Bins 1115
2025-05-07 16:17:02,723:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:17:02,723:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:02,878:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001038 seconds.
2025-05-07 16:17:02,878:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:02,879:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:02,879:INFO:[LightGBM] [Info] Total Bins 1113
2025-05-07 16:17:02,879:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:17:02,880:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:03,030:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,004639 seconds.
2025-05-07 16:17:03,030:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:17:03,031:INFO:[LightGBM] [Info] Total Bins 1111
2025-05-07 16:17:03,031:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:17:03,031:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:03,194:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000780 seconds.
2025-05-07 16:17:03,195:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:03,195:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:03,195:INFO:[LightGBM] [Info] Total Bins 1111
2025-05-07 16:17:03,195:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:17:03,196:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:03,356:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001572 seconds.
2025-05-07 16:17:03,357:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:03,357:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:03,357:INFO:[LightGBM] [Info] Total Bins 1111
2025-05-07 16:17:03,358:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:17:03,358:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:03,529:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001118 seconds.
2025-05-07 16:17:03,529:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:03,529:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:03,530:INFO:[LightGBM] [Info] Total Bins 1109
2025-05-07 16:17:03,530:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:17:03,531:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:03,699:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000970 seconds.
2025-05-07 16:17:03,700:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:03,700:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:03,700:INFO:[LightGBM] [Info] Total Bins 1107
2025-05-07 16:17:03,702:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:17:03,703:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:03,860:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001064 seconds.
2025-05-07 16:17:03,860:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:03,860:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:03,860:INFO:[LightGBM] [Info] Total Bins 1105
2025-05-07 16:17:03,862:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 61
2025-05-07 16:17:03,862:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:04,014:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001211 seconds.
2025-05-07 16:17:04,015:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:04,015:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:04,016:INFO:[LightGBM] [Info] Total Bins 1105
2025-05-07 16:17:04,016:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 61
2025-05-07 16:17:04,017:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:04,210:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001015 seconds.
2025-05-07 16:17:04,211:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:04,211:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:04,211:INFO:[LightGBM] [Info] Total Bins 1103
2025-05-07 16:17:04,211:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:17:04,212:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:04,364:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001173 seconds.
2025-05-07 16:17:04,364:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:04,364:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:04,365:INFO:[LightGBM] [Info] Total Bins 1103
2025-05-07 16:17:04,365:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:17:04,366:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:04,513:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001114 seconds.
2025-05-07 16:17:04,514:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:04,514:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:04,514:INFO:[LightGBM] [Info] Total Bins 1101
2025-05-07 16:17:04,514:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:17:04,515:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:04,668:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001406 seconds.
2025-05-07 16:17:04,670:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:04,670:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:04,670:INFO:[LightGBM] [Info] Total Bins 1099
2025-05-07 16:17:04,671:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 58
2025-05-07 16:17:04,671:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:04,859:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001410 seconds.
2025-05-07 16:17:04,859:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:04,860:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:04,860:INFO:[LightGBM] [Info] Total Bins 1097
2025-05-07 16:17:04,860:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 57
2025-05-07 16:17:04,861:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:05,027:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001029 seconds.
2025-05-07 16:17:05,028:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:05,028:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:05,028:INFO:[LightGBM] [Info] Total Bins 1095
2025-05-07 16:17:05,029:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 56
2025-05-07 16:17:05,029:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:05,190:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001191 seconds.
2025-05-07 16:17:05,190:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:05,190:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:05,191:INFO:[LightGBM] [Info] Total Bins 1093
2025-05-07 16:17:05,191:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 55
2025-05-07 16:17:05,191:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:05,350:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001234 seconds.
2025-05-07 16:17:05,350:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:05,350:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:05,351:INFO:[LightGBM] [Info] Total Bins 1091
2025-05-07 16:17:05,351:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:17:05,352:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:05,509:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001405 seconds.
2025-05-07 16:17:05,510:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:05,510:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:05,510:INFO:[LightGBM] [Info] Total Bins 1089
2025-05-07 16:17:05,511:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 53
2025-05-07 16:17:05,511:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:05,664:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001196 seconds.
2025-05-07 16:17:05,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:05,665:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:05,665:INFO:[LightGBM] [Info] Total Bins 1087
2025-05-07 16:17:05,665:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 52
2025-05-07 16:17:05,666:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:05,823:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001846 seconds.
2025-05-07 16:17:05,823:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:05,823:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:05,824:INFO:[LightGBM] [Info] Total Bins 1085
2025-05-07 16:17:05,824:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 51
2025-05-07 16:17:05,825:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:05,970:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001287 seconds.
2025-05-07 16:17:05,970:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:05,971:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:05,971:INFO:[LightGBM] [Info] Total Bins 1083
2025-05-07 16:17:05,971:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 50
2025-05-07 16:17:05,972:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:06,122:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001098 seconds.
2025-05-07 16:17:06,122:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:06,122:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:06,123:INFO:[LightGBM] [Info] Total Bins 1081
2025-05-07 16:17:06,123:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 49
2025-05-07 16:17:06,123:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:06,260:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001000 seconds.
2025-05-07 16:17:06,261:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:06,261:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:06,261:INFO:[LightGBM] [Info] Total Bins 1079
2025-05-07 16:17:06,262:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 48
2025-05-07 16:17:06,262:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:06,409:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001629 seconds.
2025-05-07 16:17:06,409:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:06,409:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:06,409:INFO:[LightGBM] [Info] Total Bins 1077
2025-05-07 16:17:06,410:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 47
2025-05-07 16:17:06,410:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:06,572:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001251 seconds.
2025-05-07 16:17:06,573:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:06,573:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:06,574:INFO:[LightGBM] [Info] Total Bins 1075
2025-05-07 16:17:06,574:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 46
2025-05-07 16:17:06,574:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:06,710:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001138 seconds.
2025-05-07 16:17:06,710:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:06,710:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:06,710:INFO:[LightGBM] [Info] Total Bins 1073
2025-05-07 16:17:06,711:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 45
2025-05-07 16:17:06,711:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:06,886:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001234 seconds.
2025-05-07 16:17:06,886:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:06,886:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:06,887:INFO:[LightGBM] [Info] Total Bins 1071
2025-05-07 16:17:06,888:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 44
2025-05-07 16:17:06,888:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:07,026:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001149 seconds.
2025-05-07 16:17:07,026:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:07,026:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:07,026:INFO:[LightGBM] [Info] Total Bins 1069
2025-05-07 16:17:07,027:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 43
2025-05-07 16:17:07,027:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:07,166:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001158 seconds.
2025-05-07 16:17:07,167:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:07,167:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:07,168:INFO:[LightGBM] [Info] Total Bins 1067
2025-05-07 16:17:07,168:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 42
2025-05-07 16:17:07,169:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:07,302:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001075 seconds.
2025-05-07 16:17:07,302:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:07,303:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:07,303:INFO:[LightGBM] [Info] Total Bins 1065
2025-05-07 16:17:07,303:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 41
2025-05-07 16:17:07,303:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:07,477:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001260 seconds.
2025-05-07 16:17:07,478:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:07,478:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:07,478:INFO:[LightGBM] [Info] Total Bins 1063
2025-05-07 16:17:07,479:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 40
2025-05-07 16:17:07,479:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:07,627:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001116 seconds.
2025-05-07 16:17:07,627:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:07,627:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:07,627:INFO:[LightGBM] [Info] Total Bins 1061
2025-05-07 16:17:07,628:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 39
2025-05-07 16:17:07,628:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:07,766:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000822 seconds.
2025-05-07 16:17:07,766:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:07,766:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:07,767:INFO:[LightGBM] [Info] Total Bins 1059
2025-05-07 16:17:07,767:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 38
2025-05-07 16:17:07,767:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:07,907:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001406 seconds.
2025-05-07 16:17:07,907:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:07,907:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:07,908:INFO:[LightGBM] [Info] Total Bins 1057
2025-05-07 16:17:07,908:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 37
2025-05-07 16:17:07,908:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:08,063:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000919 seconds.
2025-05-07 16:17:08,063:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:08,064:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:08,064:INFO:[LightGBM] [Info] Total Bins 1055
2025-05-07 16:17:08,064:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 36
2025-05-07 16:17:08,065:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:08,201:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000976 seconds.
2025-05-07 16:17:08,201:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:08,201:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:08,201:INFO:[LightGBM] [Info] Total Bins 1053
2025-05-07 16:17:08,202:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 35
2025-05-07 16:17:08,202:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:08,333:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001146 seconds.
2025-05-07 16:17:08,333:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:08,333:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:08,333:INFO:[LightGBM] [Info] Total Bins 1051
2025-05-07 16:17:08,335:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 34
2025-05-07 16:17:08,335:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:08,476:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000861 seconds.
2025-05-07 16:17:08,476:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:08,476:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:08,477:INFO:[LightGBM] [Info] Total Bins 1049
2025-05-07 16:17:08,477:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 33
2025-05-07 16:17:08,477:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:08,615:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000616 seconds.
2025-05-07 16:17:08,616:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:08,616:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:08,616:INFO:[LightGBM] [Info] Total Bins 1047
2025-05-07 16:17:08,617:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 32
2025-05-07 16:17:08,617:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:08,741:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001103 seconds.
2025-05-07 16:17:08,742:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:08,742:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:08,742:INFO:[LightGBM] [Info] Total Bins 1045
2025-05-07 16:17:08,742:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 31
2025-05-07 16:17:08,743:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:08,887:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001234 seconds.
2025-05-07 16:17:08,887:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:08,888:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:08,888:INFO:[LightGBM] [Info] Total Bins 1043
2025-05-07 16:17:08,888:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 30
2025-05-07 16:17:08,888:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:09,043:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000984 seconds.
2025-05-07 16:17:09,043:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:09,043:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:09,045:INFO:[LightGBM] [Info] Total Bins 1041
2025-05-07 16:17:09,045:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 29
2025-05-07 16:17:09,045:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:09,190:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001213 seconds.
2025-05-07 16:17:09,190:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:09,191:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:09,191:INFO:[LightGBM] [Info] Total Bins 1039
2025-05-07 16:17:09,191:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 28
2025-05-07 16:17:09,191:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:09,326:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001145 seconds.
2025-05-07 16:17:09,326:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:09,326:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:09,327:INFO:[LightGBM] [Info] Total Bins 1037
2025-05-07 16:17:09,327:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 27
2025-05-07 16:17:09,327:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:09,458:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001440 seconds.
2025-05-07 16:17:09,458:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:09,458:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:09,459:INFO:[LightGBM] [Info] Total Bins 1035
2025-05-07 16:17:09,459:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 26
2025-05-07 16:17:09,459:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:09,578:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000964 seconds.
2025-05-07 16:17:09,578:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:09,578:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:09,578:INFO:[LightGBM] [Info] Total Bins 1033
2025-05-07 16:17:09,579:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 25
2025-05-07 16:17:09,579:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:09,703:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001220 seconds.
2025-05-07 16:17:09,703:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:09,703:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:09,703:INFO:[LightGBM] [Info] Total Bins 1031
2025-05-07 16:17:09,703:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 24
2025-05-07 16:17:09,705:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:09,838:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001017 seconds.
2025-05-07 16:17:09,838:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:09,838:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:09,839:INFO:[LightGBM] [Info] Total Bins 1029
2025-05-07 16:17:09,839:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 23
2025-05-07 16:17:09,839:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:09,962:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000884 seconds.
2025-05-07 16:17:09,962:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:09,962:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:09,962:INFO:[LightGBM] [Info] Total Bins 1027
2025-05-07 16:17:09,962:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 22
2025-05-07 16:17:09,962:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:10,091:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000687 seconds.
2025-05-07 16:17:10,091:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:10,091:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:10,091:INFO:[LightGBM] [Info] Total Bins 1025
2025-05-07 16:17:10,092:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 21
2025-05-07 16:17:10,092:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:10,215:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000770 seconds.
2025-05-07 16:17:10,216:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:10,216:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:10,216:INFO:[LightGBM] [Info] Total Bins 1023
2025-05-07 16:17:10,217:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 20
2025-05-07 16:17:10,217:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:10,329:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000986 seconds.
2025-05-07 16:17:10,329:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:10,329:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:10,329:INFO:[LightGBM] [Info] Total Bins 1021
2025-05-07 16:17:10,330:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 19
2025-05-07 16:17:10,330:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:10,451:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001050 seconds.
2025-05-07 16:17:10,451:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:10,451:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:10,451:INFO:[LightGBM] [Info] Total Bins 1019
2025-05-07 16:17:10,451:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 18
2025-05-07 16:17:10,452:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:10,565:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001128 seconds.
2025-05-07 16:17:10,566:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:10,566:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:10,566:INFO:[LightGBM] [Info] Total Bins 1017
2025-05-07 16:17:10,566:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 17
2025-05-07 16:17:10,567:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:10,676:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000809 seconds.
2025-05-07 16:17:10,676:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:10,676:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:10,677:INFO:[LightGBM] [Info] Total Bins 1015
2025-05-07 16:17:10,677:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 16
2025-05-07 16:17:10,677:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:10,788:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001329 seconds.
2025-05-07 16:17:10,788:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:10,788:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:10,788:INFO:[LightGBM] [Info] Total Bins 1013
2025-05-07 16:17:10,789:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 15
2025-05-07 16:17:10,789:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:10,898:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000595 seconds.
2025-05-07 16:17:10,898:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:10,898:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:10,899:INFO:[LightGBM] [Info] Total Bins 1011
2025-05-07 16:17:10,899:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 14
2025-05-07 16:17:10,899:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:11,041:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001153 seconds.
2025-05-07 16:17:11,042:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:11,042:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:11,042:INFO:[LightGBM] [Info] Total Bins 1009
2025-05-07 16:17:11,042:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 13
2025-05-07 16:17:11,043:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:11,155:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000671 seconds.
2025-05-07 16:17:11,156:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:11,156:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:11,156:INFO:[LightGBM] [Info] Total Bins 1007
2025-05-07 16:17:11,156:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 12
2025-05-07 16:17:11,157:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:11,267:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000781 seconds.
2025-05-07 16:17:11,267:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:11,267:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:11,268:INFO:[LightGBM] [Info] Total Bins 1005
2025-05-07 16:17:11,268:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 11
2025-05-07 16:17:11,268:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:11,397:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000598 seconds.
2025-05-07 16:17:11,397:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:11,397:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:11,398:INFO:[LightGBM] [Info] Total Bins 1003
2025-05-07 16:17:11,398:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 10
2025-05-07 16:17:11,398:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:11,528:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000606 seconds.
2025-05-07 16:17:11,529:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:11,529:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:11,529:INFO:[LightGBM] [Info] Total Bins 1001
2025-05-07 16:17:11,529:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 9
2025-05-07 16:17:11,530:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:11,663:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000155 seconds.
2025-05-07 16:17:11,663:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:11,663:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:11,663:INFO:[LightGBM] [Info] Total Bins 999
2025-05-07 16:17:11,663:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 8
2025-05-07 16:17:11,665:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:11,771:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000588 seconds.
2025-05-07 16:17:11,771:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:17:11,772:INFO:[LightGBM] [Info] Total Bins 993
2025-05-07 16:17:11,773:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 7
2025-05-07 16:17:11,773:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:11,882:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,000485 seconds.
2025-05-07 16:17:11,882:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:17:11,882:INFO:[LightGBM] [Info] Total Bins 976
2025-05-07 16:17:11,883:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 6
2025-05-07 16:17:11,883:INFO:[LightGBM] [Info] Start training from score 435293,929605
2025-05-07 16:17:13,357:INFO:Initializing plot_model()
2025-05-07 16:17:13,357:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), plot=rfe, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-07 16:17:13,357:INFO:Checking exceptions
2025-05-07 16:17:13,365:INFO:Preloading libraries
2025-05-07 16:17:13,369:INFO:Copying training dataset
2025-05-07 16:17:13,369:INFO:Plot type: rfe
2025-05-07 16:17:13,599:INFO:Fitting Model
2025-05-07 16:17:13,675:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001235 seconds.
2025-05-07 16:17:13,675:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:13,675:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:13,676:INFO:[LightGBM] [Info] Total Bins 1120
2025-05-07 16:17:13,676:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 68
2025-05-07 16:17:13,677:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:13,830:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001126 seconds.
2025-05-07 16:17:13,830:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:13,830:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:13,830:INFO:[LightGBM] [Info] Total Bins 1118
2025-05-07 16:17:13,832:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 67
2025-05-07 16:17:13,832:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:14,008:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001595 seconds.
2025-05-07 16:17:14,008:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:14,008:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:14,009:INFO:[LightGBM] [Info] Total Bins 1116
2025-05-07 16:17:14,009:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:17:14,010:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:14,185:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001438 seconds.
2025-05-07 16:17:14,185:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:14,185:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:14,186:INFO:[LightGBM] [Info] Total Bins 1116
2025-05-07 16:17:14,186:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 66
2025-05-07 16:17:14,188:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:14,385:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001131 seconds.
2025-05-07 16:17:14,386:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:14,386:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:14,386:INFO:[LightGBM] [Info] Total Bins 1114
2025-05-07 16:17:14,387:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:17:14,387:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:14,580:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001308 seconds.
2025-05-07 16:17:14,580:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:14,581:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:14,581:INFO:[LightGBM] [Info] Total Bins 1114
2025-05-07 16:17:14,581:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 65
2025-05-07 16:17:14,582:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:14,744:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001490 seconds.
2025-05-07 16:17:14,744:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:14,744:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:14,744:INFO:[LightGBM] [Info] Total Bins 1112
2025-05-07 16:17:14,744:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:17:14,745:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:14,919:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,003602 seconds.
2025-05-07 16:17:14,919:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:17:14,920:INFO:[LightGBM] [Info] Total Bins 1112
2025-05-07 16:17:14,920:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:17:14,920:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:15,102:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001673 seconds.
2025-05-07 16:17:15,102:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:15,103:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:15,103:INFO:[LightGBM] [Info] Total Bins 1112
2025-05-07 16:17:15,103:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 64
2025-05-07 16:17:15,104:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:15,274:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001379 seconds.
2025-05-07 16:17:15,274:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:15,274:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:15,276:INFO:[LightGBM] [Info] Total Bins 1110
2025-05-07 16:17:15,276:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:17:15,277:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:15,479:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001468 seconds.
2025-05-07 16:17:15,480:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:15,480:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:15,480:INFO:[LightGBM] [Info] Total Bins 1110
2025-05-07 16:17:15,481:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 63
2025-05-07 16:17:15,481:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:15,644:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001286 seconds.
2025-05-07 16:17:15,644:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:15,646:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:15,646:INFO:[LightGBM] [Info] Total Bins 1108
2025-05-07 16:17:15,646:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:17:15,647:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:15,796:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001421 seconds.
2025-05-07 16:17:15,796:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:15,797:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:15,797:INFO:[LightGBM] [Info] Total Bins 1108
2025-05-07 16:17:15,797:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 62
2025-05-07 16:17:15,798:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:15,963:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001185 seconds.
2025-05-07 16:17:15,963:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:15,964:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:15,964:INFO:[LightGBM] [Info] Total Bins 1106
2025-05-07 16:17:15,964:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 61
2025-05-07 16:17:15,965:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:16,127:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001449 seconds.
2025-05-07 16:17:16,127:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:16,127:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:16,128:INFO:[LightGBM] [Info] Total Bins 1104
2025-05-07 16:17:16,128:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 60
2025-05-07 16:17:16,128:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:16,280:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001070 seconds.
2025-05-07 16:17:16,282:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:16,282:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:16,282:INFO:[LightGBM] [Info] Total Bins 1102
2025-05-07 16:17:16,283:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 59
2025-05-07 16:17:16,283:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:16,440:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001712 seconds.
2025-05-07 16:17:16,440:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:16,440:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:16,440:INFO:[LightGBM] [Info] Total Bins 1100
2025-05-07 16:17:16,442:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 58
2025-05-07 16:17:16,442:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:16,623:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001646 seconds.
2025-05-07 16:17:16,623:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:16,624:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:16,624:INFO:[LightGBM] [Info] Total Bins 1098
2025-05-07 16:17:16,624:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 57
2025-05-07 16:17:16,624:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:16,794:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001271 seconds.
2025-05-07 16:17:16,795:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:16,795:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:16,795:INFO:[LightGBM] [Info] Total Bins 1096
2025-05-07 16:17:16,796:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 56
2025-05-07 16:17:16,796:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:16,953:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001622 seconds.
2025-05-07 16:17:16,953:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:16,953:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:16,953:INFO:[LightGBM] [Info] Total Bins 1096
2025-05-07 16:17:16,954:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 56
2025-05-07 16:17:16,954:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:17,123:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001276 seconds.
2025-05-07 16:17:17,123:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:17,124:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:17,124:INFO:[LightGBM] [Info] Total Bins 1094
2025-05-07 16:17:17,124:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 55
2025-05-07 16:17:17,124:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:17,297:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001218 seconds.
2025-05-07 16:17:17,297:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:17,298:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:17,298:INFO:[LightGBM] [Info] Total Bins 1092
2025-05-07 16:17:17,298:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:17:17,299:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:17,444:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001154 seconds.
2025-05-07 16:17:17,446:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:17,446:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:17,446:INFO:[LightGBM] [Info] Total Bins 1092
2025-05-07 16:17:17,446:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 54
2025-05-07 16:17:17,447:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:17,609:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001258 seconds.
2025-05-07 16:17:17,609:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:17,609:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:17,609:INFO:[LightGBM] [Info] Total Bins 1090
2025-05-07 16:17:17,610:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 53
2025-05-07 16:17:17,610:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:17,772:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001266 seconds.
2025-05-07 16:17:17,773:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:17,773:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:17,774:INFO:[LightGBM] [Info] Total Bins 1088
2025-05-07 16:17:17,774:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 52
2025-05-07 16:17:17,774:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:17,917:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001198 seconds.
2025-05-07 16:17:17,918:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:17,918:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:17,918:INFO:[LightGBM] [Info] Total Bins 1086
2025-05-07 16:17:17,918:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 51
2025-05-07 16:17:17,919:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:18,069:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001368 seconds.
2025-05-07 16:17:18,070:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:18,070:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:18,070:INFO:[LightGBM] [Info] Total Bins 1084
2025-05-07 16:17:18,070:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 50
2025-05-07 16:17:18,071:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:18,216:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001077 seconds.
2025-05-07 16:17:18,217:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:18,217:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:18,217:INFO:[LightGBM] [Info] Total Bins 1082
2025-05-07 16:17:18,217:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 49
2025-05-07 16:17:18,218:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:18,362:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001264 seconds.
2025-05-07 16:17:18,362:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:18,362:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:18,363:INFO:[LightGBM] [Info] Total Bins 1080
2025-05-07 16:17:18,363:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 48
2025-05-07 16:17:18,363:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:18,574:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000970 seconds.
2025-05-07 16:17:18,574:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:18,575:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:18,575:INFO:[LightGBM] [Info] Total Bins 1078
2025-05-07 16:17:18,575:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 47
2025-05-07 16:17:18,576:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:18,722:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001497 seconds.
2025-05-07 16:17:18,722:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:18,722:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:18,723:INFO:[LightGBM] [Info] Total Bins 1076
2025-05-07 16:17:18,723:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 46
2025-05-07 16:17:18,723:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:18,868:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001069 seconds.
2025-05-07 16:17:18,869:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:18,869:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:18,869:INFO:[LightGBM] [Info] Total Bins 1074
2025-05-07 16:17:18,870:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 45
2025-05-07 16:17:18,870:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:19,028:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000922 seconds.
2025-05-07 16:17:19,029:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:19,029:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:19,029:INFO:[LightGBM] [Info] Total Bins 1072
2025-05-07 16:17:19,029:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 44
2025-05-07 16:17:19,030:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:19,176:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001369 seconds.
2025-05-07 16:17:19,177:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:19,177:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:19,177:INFO:[LightGBM] [Info] Total Bins 1070
2025-05-07 16:17:19,177:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 43
2025-05-07 16:17:19,178:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:19,373:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001655 seconds.
2025-05-07 16:17:19,373:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:19,373:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:19,374:INFO:[LightGBM] [Info] Total Bins 1068
2025-05-07 16:17:19,374:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 42
2025-05-07 16:17:19,374:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:19,543:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001048 seconds.
2025-05-07 16:17:19,543:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:19,543:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:19,543:INFO:[LightGBM] [Info] Total Bins 1066
2025-05-07 16:17:19,544:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 41
2025-05-07 16:17:19,544:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:19,699:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001161 seconds.
2025-05-07 16:17:19,699:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:19,699:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:19,700:INFO:[LightGBM] [Info] Total Bins 1064
2025-05-07 16:17:19,700:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 40
2025-05-07 16:17:19,700:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:19,837:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000997 seconds.
2025-05-07 16:17:19,837:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:19,838:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:19,838:INFO:[LightGBM] [Info] Total Bins 1062
2025-05-07 16:17:19,838:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 39
2025-05-07 16:17:19,839:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:19,971:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000989 seconds.
2025-05-07 16:17:19,971:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:19,971:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:19,971:INFO:[LightGBM] [Info] Total Bins 1060
2025-05-07 16:17:19,971:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 38
2025-05-07 16:17:19,972:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:20,120:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001328 seconds.
2025-05-07 16:17:20,121:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:20,121:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:20,121:INFO:[LightGBM] [Info] Total Bins 1058
2025-05-07 16:17:20,122:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 37
2025-05-07 16:17:20,122:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:20,276:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000941 seconds.
2025-05-07 16:17:20,276:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:20,277:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:20,277:INFO:[LightGBM] [Info] Total Bins 1056
2025-05-07 16:17:20,277:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 36
2025-05-07 16:17:20,278:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:20,409:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000797 seconds.
2025-05-07 16:17:20,409:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:20,409:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:20,410:INFO:[LightGBM] [Info] Total Bins 1054
2025-05-07 16:17:20,410:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 35
2025-05-07 16:17:20,410:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:20,556:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000993 seconds.
2025-05-07 16:17:20,557:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:20,557:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:20,557:INFO:[LightGBM] [Info] Total Bins 1052
2025-05-07 16:17:20,557:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 34
2025-05-07 16:17:20,558:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:20,700:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001276 seconds.
2025-05-07 16:17:20,700:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:20,700:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:20,701:INFO:[LightGBM] [Info] Total Bins 1050
2025-05-07 16:17:20,701:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 33
2025-05-07 16:17:20,701:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:20,846:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000873 seconds.
2025-05-07 16:17:20,846:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:20,846:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:20,847:INFO:[LightGBM] [Info] Total Bins 1048
2025-05-07 16:17:20,847:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 32
2025-05-07 16:17:20,847:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:20,977:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000892 seconds.
2025-05-07 16:17:20,978:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:20,978:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:20,978:INFO:[LightGBM] [Info] Total Bins 1046
2025-05-07 16:17:20,979:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 31
2025-05-07 16:17:20,979:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:21,125:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001187 seconds.
2025-05-07 16:17:21,126:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:21,126:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:21,126:INFO:[LightGBM] [Info] Total Bins 1044
2025-05-07 16:17:21,126:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 30
2025-05-07 16:17:21,127:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:21,263:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001004 seconds.
2025-05-07 16:17:21,264:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:21,264:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:21,264:INFO:[LightGBM] [Info] Total Bins 1042
2025-05-07 16:17:21,264:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 29
2025-05-07 16:17:21,264:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:21,414:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001113 seconds.
2025-05-07 16:17:21,414:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:21,414:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:21,414:INFO:[LightGBM] [Info] Total Bins 1040
2025-05-07 16:17:21,414:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 28
2025-05-07 16:17:21,416:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:21,553:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001341 seconds.
2025-05-07 16:17:21,554:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:21,554:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:21,554:INFO:[LightGBM] [Info] Total Bins 1038
2025-05-07 16:17:21,555:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 27
2025-05-07 16:17:21,555:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:21,676:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000816 seconds.
2025-05-07 16:17:21,676:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:21,677:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:21,677:INFO:[LightGBM] [Info] Total Bins 1036
2025-05-07 16:17:21,677:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 26
2025-05-07 16:17:21,678:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:21,820:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001197 seconds.
2025-05-07 16:17:21,821:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:21,821:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:21,821:INFO:[LightGBM] [Info] Total Bins 1034
2025-05-07 16:17:21,822:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 25
2025-05-07 16:17:21,822:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:21,945:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001055 seconds.
2025-05-07 16:17:21,945:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:21,945:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:21,945:INFO:[LightGBM] [Info] Total Bins 1032
2025-05-07 16:17:21,945:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 24
2025-05-07 16:17:21,946:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:22,071:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001000 seconds.
2025-05-07 16:17:22,071:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:22,072:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:22,072:INFO:[LightGBM] [Info] Total Bins 1030
2025-05-07 16:17:22,072:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 23
2025-05-07 16:17:22,072:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:22,214:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000792 seconds.
2025-05-07 16:17:22,214:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:22,214:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:22,214:INFO:[LightGBM] [Info] Total Bins 1028
2025-05-07 16:17:22,214:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 22
2025-05-07 16:17:22,216:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:22,336:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000830 seconds.
2025-05-07 16:17:22,337:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:22,337:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:22,337:INFO:[LightGBM] [Info] Total Bins 1026
2025-05-07 16:17:22,337:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 21
2025-05-07 16:17:22,337:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:22,452:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0,003418 seconds.
2025-05-07 16:17:22,452:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-07 16:17:22,452:INFO:[LightGBM] [Info] Total Bins 1024
2025-05-07 16:17:22,453:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 20
2025-05-07 16:17:22,453:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:22,605:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000741 seconds.
2025-05-07 16:17:22,605:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:22,606:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:22,606:INFO:[LightGBM] [Info] Total Bins 1022
2025-05-07 16:17:22,606:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 19
2025-05-07 16:17:22,606:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:22,726:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001158 seconds.
2025-05-07 16:17:22,726:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:22,726:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:22,726:INFO:[LightGBM] [Info] Total Bins 1020
2025-05-07 16:17:22,727:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 18
2025-05-07 16:17:22,727:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:22,867:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000886 seconds.
2025-05-07 16:17:22,868:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:22,868:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:22,868:INFO:[LightGBM] [Info] Total Bins 1018
2025-05-07 16:17:22,869:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 17
2025-05-07 16:17:22,869:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:23,023:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000850 seconds.
2025-05-07 16:17:23,023:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:23,024:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:23,024:INFO:[LightGBM] [Info] Total Bins 1016
2025-05-07 16:17:23,024:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 16
2025-05-07 16:17:23,024:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:23,207:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000832 seconds.
2025-05-07 16:17:23,207:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:23,207:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:23,208:INFO:[LightGBM] [Info] Total Bins 1014
2025-05-07 16:17:23,208:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 15
2025-05-07 16:17:23,208:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:23,346:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,000964 seconds.
2025-05-07 16:17:23,346:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:23,347:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:23,347:INFO:[LightGBM] [Info] Total Bins 1012
2025-05-07 16:17:23,347:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 14
2025-05-07 16:17:23,347:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:23,496:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,001176 seconds.
2025-05-07 16:17:23,497:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-07 16:17:23,497:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-07 16:17:23,497:INFO:[LightGBM] [Info] Total Bins 1010
2025-05-07 16:17:23,497:INFO:[LightGBM] [Info] Number of data points in the train set: 39122, number of used features: 13
2025-05-07 16:17:23,498:INFO:[LightGBM] [Info] Start training from score 437526,391417
2025-05-07 16:17:30,160:INFO:Initializing predict_model()
2025-05-07 16:17:30,160:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002671DF135D0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000026729D880E0>)
2025-05-07 16:17:30,160:INFO:Checking exceptions
2025-05-07 16:17:30,160:INFO:Preloading libraries
2025-05-07 16:17:30,289:WARNING:c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-05-07 16:18:09,505:INFO:Initializing save_model()
2025-05-07 16:18:09,506:INFO:save_model(model=LGBMRegressor(n_jobs=-1, random_state=123), model_name=random_forest_regressor_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\LINW~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['bedroomCount', 'bathroomCount',
                                             'postCode', 'habitableSurface',
                                             'buildingConstructionYear',
                                             'facedeCount', 'toiletCount'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['type', 'subtype',...
                                             'floodZoneType', 'heatingType',
                                             'kitchenType', 'epcScore'],
                                    transformer=OneHotEncoder(cols=['subtype',
                                                                    'buildingCondition',
                                                                    'floodZoneType',
                                                                    'heatingType',
                                                                    'kitchenType',
                                                                    'epcScore'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['locality'],
                                    transformer=TargetEncoder(cols=['locality'],
                                                              handle_missing='return_nan')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-05-07 16:18:09,506:INFO:Adding model into prep_pipe
2025-05-07 16:18:09,554:INFO:random_forest_regressor_pipeline.pkl saved in current working directory
2025-05-07 16:18:09,577:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['bedroomCount', 'bathroomCount',
                                             'postCode', 'habitableSurface',
                                             'buildingConstructionYear',
                                             'facedeCount', 'toiletCount'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['type', 'subtype', 'locality',
                                             'buildingCondition',
                                             'floodZone...
                                    transformer=OneHotEncoder(cols=['subtype',
                                                                    'buildingCondition',
                                                                    'floodZoneType',
                                                                    'heatingType',
                                                                    'kitchenType',
                                                                    'epcScore'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['locality'],
                                    transformer=TargetEncoder(cols=['locality'],
                                                              handle_missing='return_nan'))),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=123))])
2025-05-07 16:18:09,577:INFO:save_model() successfully completed......................................
2025-05-07 16:18:33,238:INFO:Initializing save_model()
2025-05-07 16:18:33,239:INFO:save_model(model=LGBMRegressor(n_jobs=-1, random_state=123), model_name=Light Gradient Boosting Machine, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\LINW~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['bedroomCount', 'bathroomCount',
                                             'postCode', 'habitableSurface',
                                             'buildingConstructionYear',
                                             'facedeCount', 'toiletCount'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['type', 'subtype',...
                                             'floodZoneType', 'heatingType',
                                             'kitchenType', 'epcScore'],
                                    transformer=OneHotEncoder(cols=['subtype',
                                                                    'buildingCondition',
                                                                    'floodZoneType',
                                                                    'heatingType',
                                                                    'kitchenType',
                                                                    'epcScore'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['locality'],
                                    transformer=TargetEncoder(cols=['locality'],
                                                              handle_missing='return_nan')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-05-07 16:18:33,239:INFO:Adding model into prep_pipe
2025-05-07 16:18:33,263:INFO:Light Gradient Boosting Machine.pkl saved in current working directory
2025-05-07 16:18:33,287:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['bedroomCount', 'bathroomCount',
                                             'postCode', 'habitableSurface',
                                             'buildingConstructionYear',
                                             'facedeCount', 'toiletCount'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['type', 'subtype', 'locality',
                                             'buildingCondition',
                                             'floodZone...
                                    transformer=OneHotEncoder(cols=['subtype',
                                                                    'buildingCondition',
                                                                    'floodZoneType',
                                                                    'heatingType',
                                                                    'kitchenType',
                                                                    'epcScore'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['locality'],
                                    transformer=TargetEncoder(cols=['locality'],
                                                              handle_missing='return_nan'))),
                ('trained_model', LGBMRegressor(n_jobs=-1, random_state=123))])
2025-05-07 16:18:33,288:INFO:save_model() successfully completed......................................
2025-05-08 17:39:24,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-08 17:39:24,127:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-08 17:39:24,127:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-08 17:39:24,127:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-08 17:39:24,350:INFO:PyCaret RegressionExperiment
2025-05-08 17:39:24,561:INFO:Logging name: reg-default-name
2025-05-08 17:39:24,561:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-08 17:39:24,561:INFO:version 3.3.2
2025-05-08 17:39:24,570:INFO:Initializing setup()
2025-05-08 17:39:24,571:INFO:self.USI: a7f6
2025-05-08 17:39:24,571:INFO:self._variable_keys: {'pipeline', 'html_param', 'n_jobs_param', 'transform_target_param', 'X_train', 'memory', 'y_train', 'USI', 'exp_name_log', 'data', '_available_plots', 'idx', 'logging_param', 'y_test', 'target_param', 'log_plots_param', 'fold_groups_param', 'exp_id', 'X', 'seed', 'y', 'fold_shuffle_param', 'X_test', 'fold_generator', 'gpu_param', 'gpu_n_jobs_param', '_ml_usecase'}
2025-05-08 17:39:24,571:INFO:Checking environment
2025-05-08 17:39:24,571:INFO:python_version: 3.11.7
2025-05-08 17:39:24,571:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2025-05-08 17:39:24,571:INFO:machine: AMD64
2025-05-08 17:39:24,571:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-08 17:39:24,578:INFO:Memory: svmem(total=8274710528, available=538361856, percent=93.5, used=7736348672, free=538361856)
2025-05-08 17:39:24,578:INFO:Physical Core: 10
2025-05-08 17:39:24,586:INFO:Logical Core: 12
2025-05-08 17:39:24,586:INFO:Checking libraries
2025-05-08 17:39:24,586:INFO:System:
2025-05-08 17:39:24,589:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2025-05-08 17:39:24,589:INFO:executable: c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Scripts\python.exe
2025-05-08 17:39:24,589:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-08 17:39:24,589:INFO:PyCaret required dependencies:
2025-05-08 17:39:24,677:INFO:                 pip: 23.2.1
2025-05-08 17:39:24,677:INFO:          setuptools: 65.5.0
2025-05-08 17:39:24,677:INFO:             pycaret: 3.3.2
2025-05-08 17:39:24,677:INFO:             IPython: 9.2.0
2025-05-08 17:39:24,677:INFO:          ipywidgets: 8.1.7
2025-05-08 17:39:24,677:INFO:                tqdm: 4.67.1
2025-05-08 17:39:24,684:INFO:               numpy: 1.26.4
2025-05-08 17:39:24,684:INFO:              pandas: 2.1.4
2025-05-08 17:39:24,684:INFO:              jinja2: 3.1.6
2025-05-08 17:39:24,684:INFO:               scipy: 1.11.4
2025-05-08 17:39:24,684:INFO:              joblib: 1.3.2
2025-05-08 17:39:24,684:INFO:             sklearn: 1.4.2
2025-05-08 17:39:24,684:INFO:                pyod: 2.0.5
2025-05-08 17:39:24,684:INFO:            imblearn: 0.13.0
2025-05-08 17:39:24,689:INFO:   category_encoders: 2.7.0
2025-05-08 17:39:24,689:INFO:            lightgbm: 4.6.0
2025-05-08 17:39:24,689:INFO:               numba: 0.61.2
2025-05-08 17:39:24,689:INFO:            requests: 2.32.3
2025-05-08 17:39:24,692:INFO:          matplotlib: 3.7.5
2025-05-08 17:39:24,694:INFO:          scikitplot: 0.3.7
2025-05-08 17:39:24,694:INFO:         yellowbrick: 1.5
2025-05-08 17:39:24,694:INFO:              plotly: 5.24.1
2025-05-08 17:39:24,694:INFO:    plotly-resampler: Not installed
2025-05-08 17:39:24,694:INFO:             kaleido: 0.2.1
2025-05-08 17:39:24,694:INFO:           schemdraw: 0.15
2025-05-08 17:39:24,694:INFO:         statsmodels: 0.14.4
2025-05-08 17:39:24,694:INFO:              sktime: 0.26.0
2025-05-08 17:39:24,694:INFO:               tbats: 1.1.3
2025-05-08 17:39:24,694:INFO:            pmdarima: 2.0.4
2025-05-08 17:39:24,694:INFO:              psutil: 7.0.0
2025-05-08 17:39:24,694:INFO:          markupsafe: 3.0.2
2025-05-08 17:39:24,694:INFO:             pickle5: Not installed
2025-05-08 17:39:24,694:INFO:         cloudpickle: 3.1.1
2025-05-08 17:39:24,701:INFO:         deprecation: 2.1.0
2025-05-08 17:39:24,701:INFO:              xxhash: 3.5.0
2025-05-08 17:39:24,701:INFO:           wurlitzer: Not installed
2025-05-08 17:39:24,701:INFO:PyCaret optional dependencies:
2025-05-08 17:39:24,758:INFO:                shap: Not installed
2025-05-08 17:39:24,758:INFO:           interpret: Not installed
2025-05-08 17:39:24,758:INFO:                umap: Not installed
2025-05-08 17:39:24,758:INFO:     ydata_profiling: Not installed
2025-05-08 17:39:24,758:INFO:  explainerdashboard: Not installed
2025-05-08 17:39:24,758:INFO:             autoviz: Not installed
2025-05-08 17:39:24,758:INFO:           fairlearn: Not installed
2025-05-08 17:39:24,758:INFO:          deepchecks: Not installed
2025-05-08 17:39:24,758:INFO:             xgboost: Not installed
2025-05-08 17:39:24,758:INFO:            catboost: Not installed
2025-05-08 17:39:24,767:INFO:              kmodes: Not installed
2025-05-08 17:39:24,767:INFO:             mlxtend: Not installed
2025-05-08 17:39:24,768:INFO:       statsforecast: Not installed
2025-05-08 17:39:24,768:INFO:        tune_sklearn: Not installed
2025-05-08 17:39:24,768:INFO:                 ray: Not installed
2025-05-08 17:39:24,768:INFO:            hyperopt: Not installed
2025-05-08 17:39:24,768:INFO:              optuna: Not installed
2025-05-08 17:39:24,768:INFO:               skopt: Not installed
2025-05-08 17:39:24,768:INFO:              mlflow: Not installed
2025-05-08 17:39:24,768:INFO:              gradio: Not installed
2025-05-08 17:39:24,768:INFO:             fastapi: Not installed
2025-05-08 17:39:24,775:INFO:             uvicorn: Not installed
2025-05-08 17:39:24,775:INFO:              m2cgen: Not installed
2025-05-08 17:39:24,775:INFO:           evidently: Not installed
2025-05-08 17:39:24,775:INFO:               fugue: Not installed
2025-05-08 17:39:24,775:INFO:           streamlit: 1.45.0
2025-05-08 17:39:24,775:INFO:             prophet: Not installed
2025-05-08 17:39:24,775:INFO:None
2025-05-08 17:39:24,775:INFO:Set up data.
2025-05-08 17:39:24,923:INFO:Set up folding strategy.
2025-05-08 17:39:24,925:INFO:Set up train/test split.
2025-05-08 17:39:24,965:INFO:Set up index.
2025-05-08 17:39:24,974:INFO:Assigning column types.
2025-05-08 17:39:24,989:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-08 17:39:24,989:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-08 17:39:24,998:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,006:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,067:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,097:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:25,097:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:25,097:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,103:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,106:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,147:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,189:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,189:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:25,189:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:25,189:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-08 17:39:25,197:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,197:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,280:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,313:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,317:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:25,318:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:25,318:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,321:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,362:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,389:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,390:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:25,390:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:25,390:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-08 17:39:25,396:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,437:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,462:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,470:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:25,470:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:25,476:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,525:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,560:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,564:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:25,565:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:25,566:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-08 17:39:25,626:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,688:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,690:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:25,690:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:25,768:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,817:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:25,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:25,817:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-08 17:39:25,885:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-08 17:39:25,912:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:25,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:25,988:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-08 17:39:26,011:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:26,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:26,011:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-08 17:39:26,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:26,087:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:26,167:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:26,167:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:26,175:INFO:Preparing preprocessing pipeline...
2025-05-08 17:39:26,175:INFO:Set up iterative imputation.
2025-05-08 17:39:26,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:26,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:26,293:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-08 17:39:26,317:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:26,317:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:26,378:INFO:Set up encoding of ordinal features.
2025-05-08 17:39:26,385:INFO:Set up encoding of categorical features.
2025-05-08 17:39:27,168:INFO:Finished creating preprocessing pipeline.
2025-05-08 17:39:27,192:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LINW~1\AppData\Local\Temp\joblib),
         steps=[('iterative_imputer',
                 TransformerWrapper(transformer=IterativeImputer(cat_estimator=LGBMClassifier(n_jobs=-1,
                                                                                              random_state=123),
                                                                 cat_estimator_prepare_for_categoricals_type='fit_params_categorical_feature',
                                                                 categorical_indices=[0,
                                                                                      1,
                                                                                      4,
                                                                                      7,
                                                                                      10,
                                                                                      11,
                                                                                      12,
                                                                                      18],
                                                                 max_iter=5,
                                                                 num_esti...
                                             'floodZoneType', 'heatingType',
                                             'kitchenType', 'epcScore'],
                                    transformer=OneHotEncoder(cols=['subtype',
                                                                    'buildingCondition',
                                                                    'floodZoneType',
                                                                    'heatingType',
                                                                    'kitchenType',
                                                                    'epcScore'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['locality'],
                                    transformer=TargetEncoder(cols=['locality'],
                                                              handle_missing='return_nan')))])
2025-05-08 17:39:27,192:INFO:Creating final display dataframe.
2025-05-08 17:39:28,600:INFO:Setup _display_container:                         Description             Value
0                        Session id               123
1                            Target             price
2                       Target type        Regression
3               Original data shape       (62099, 20)
4            Transformed data shape       (62099, 77)
5       Transformed train set shape       (43469, 77)
6        Transformed test set shape       (18630, 77)
7                  Numeric features                 7
8              Categorical features                 8
9                        Preprocess              True
10                  Imputation type         iterative
11  Iterative imputation iterations                 5
12        Numeric iterative imputer          lightgbm
13    Categorical iterative imputer          lightgbm
14         Maximum one-hot encoding                25
15                  Encoding method              None
16                   Fold Generator             KFold
17                      Fold Number                10
18                         CPU Jobs                -1
19                          Use GPU             False
20                   Log Experiment             False
21                  Experiment Name  reg-default-name
22                              USI              a7f6
2025-05-08 17:39:28,706:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:28,706:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:28,780:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:28,781:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-08 17:39:28,782:INFO:setup() successfully completed in 4.44s...............
2025-05-08 17:39:50,414:INFO:Initializing compare_models()
2025-05-08 17:39:50,415:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-08 17:39:50,416:INFO:Checking exceptions
2025-05-08 17:39:50,437:INFO:Preparing display monitor
2025-05-08 17:39:50,465:INFO:Initializing Linear Regression
2025-05-08 17:39:50,465:INFO:Total runtime is 0.0 minutes
2025-05-08 17:39:50,473:INFO:SubProcess create_model() called ==================================
2025-05-08 17:39:50,473:INFO:Initializing create_model()
2025-05-08 17:39:50,473:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D4F9FBFF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-08 17:39:50,473:INFO:Checking exceptions
2025-05-08 17:39:50,473:INFO:Importing libraries
2025-05-08 17:39:50,473:INFO:Copying training dataset
2025-05-08 17:39:50,516:INFO:Defining folds
2025-05-08 17:39:50,518:INFO:Declaring metric variables
2025-05-08 17:39:50,524:INFO:Importing untrained model
2025-05-08 17:39:50,530:INFO:Linear Regression Imported successfully
2025-05-08 17:39:50,543:INFO:Starting cross validation
2025-05-08 17:39:50,549:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-08 17:39:59,723:INFO:Calculating mean and std
2025-05-08 17:39:59,791:INFO:Creating metrics dataframe
2025-05-08 17:39:59,832:INFO:Uploading results into container
2025-05-08 17:39:59,832:INFO:Uploading model into container now
2025-05-08 17:39:59,840:INFO:_master_model_container: 1
2025-05-08 17:39:59,840:INFO:_display_container: 2
2025-05-08 17:39:59,849:INFO:LinearRegression(n_jobs=-1)
2025-05-08 17:39:59,849:INFO:create_model() successfully completed......................................
2025-05-08 17:40:00,188:INFO:SubProcess create_model() end ==================================
2025-05-08 17:40:00,188:INFO:Creating metrics dataframe
2025-05-08 17:40:00,193:INFO:Initializing Lasso Regression
2025-05-08 17:40:00,193:INFO:Total runtime is 0.16213583548863728 minutes
2025-05-08 17:40:00,204:INFO:SubProcess create_model() called ==================================
2025-05-08 17:40:00,204:INFO:Initializing create_model()
2025-05-08 17:40:00,204:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D4F9FBFF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-08 17:40:00,204:INFO:Checking exceptions
2025-05-08 17:40:00,204:INFO:Importing libraries
2025-05-08 17:40:00,209:INFO:Copying training dataset
2025-05-08 17:40:00,233:INFO:Defining folds
2025-05-08 17:40:00,233:INFO:Declaring metric variables
2025-05-08 17:40:00,233:INFO:Importing untrained model
2025-05-08 17:40:00,241:INFO:Lasso Regression Imported successfully
2025-05-08 17:40:00,249:INFO:Starting cross validation
2025-05-08 17:40:00,258:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-08 17:40:14,197:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+15, tolerance: 9.937e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-08 17:40:14,274:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.900e+15, tolerance: 9.796e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-08 17:40:14,595:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.575e+15, tolerance: 9.769e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-08 17:40:14,623:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.087e+15, tolerance: 1.006e+12
  model = cd_fast.enet_coordinate_descent(

2025-05-08 17:40:14,682:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.211e+15, tolerance: 9.820e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-08 17:40:14,721:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.228e+15, tolerance: 9.959e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-08 17:40:16,744:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.235e+15, tolerance: 9.867e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-08 17:40:17,029:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.928e+14, tolerance: 9.979e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-08 17:40:17,111:INFO:Calculating mean and std
2025-05-08 17:40:17,114:INFO:Creating metrics dataframe
2025-05-08 17:40:17,114:INFO:Uploading results into container
2025-05-08 17:40:17,114:INFO:Uploading model into container now
2025-05-08 17:40:17,114:INFO:_master_model_container: 2
2025-05-08 17:40:17,119:INFO:_display_container: 2
2025-05-08 17:40:17,119:INFO:Lasso(random_state=123)
2025-05-08 17:40:17,119:INFO:create_model() successfully completed......................................
2025-05-08 17:40:17,188:INFO:SubProcess create_model() end ==================================
2025-05-08 17:40:17,195:INFO:Creating metrics dataframe
2025-05-08 17:40:17,195:INFO:Initializing Ridge Regression
2025-05-08 17:40:17,195:INFO:Total runtime is 0.44549913803736363 minutes
2025-05-08 17:40:17,205:INFO:SubProcess create_model() called ==================================
2025-05-08 17:40:17,206:INFO:Initializing create_model()
2025-05-08 17:40:17,206:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D4F9FBFF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-08 17:40:17,207:INFO:Checking exceptions
2025-05-08 17:40:17,207:INFO:Importing libraries
2025-05-08 17:40:17,207:INFO:Copying training dataset
2025-05-08 17:40:17,220:INFO:Defining folds
2025-05-08 17:40:17,227:INFO:Declaring metric variables
2025-05-08 17:40:17,228:INFO:Importing untrained model
2025-05-08 17:40:17,235:INFO:Ridge Regression Imported successfully
2025-05-08 17:40:17,244:INFO:Starting cross validation
2025-05-08 17:40:17,252:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-08 17:40:19,160:INFO:Calculating mean and std
2025-05-08 17:40:19,160:INFO:Creating metrics dataframe
2025-05-08 17:40:19,166:INFO:Uploading results into container
2025-05-08 17:40:19,166:INFO:Uploading model into container now
2025-05-08 17:40:19,166:INFO:_master_model_container: 3
2025-05-08 17:40:19,166:INFO:_display_container: 2
2025-05-08 17:40:19,166:INFO:Ridge(random_state=123)
2025-05-08 17:40:19,166:INFO:create_model() successfully completed......................................
2025-05-08 17:40:19,248:INFO:SubProcess create_model() end ==================================
2025-05-08 17:40:19,248:INFO:Creating metrics dataframe
2025-05-08 17:40:19,257:INFO:Initializing Elastic Net
2025-05-08 17:40:19,257:INFO:Total runtime is 0.4798654754956563 minutes
2025-05-08 17:40:19,257:INFO:SubProcess create_model() called ==================================
2025-05-08 17:40:19,257:INFO:Initializing create_model()
2025-05-08 17:40:19,257:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D4F9FBFF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-08 17:40:19,257:INFO:Checking exceptions
2025-05-08 17:40:19,257:INFO:Importing libraries
2025-05-08 17:40:19,265:INFO:Copying training dataset
2025-05-08 17:40:19,303:INFO:Defining folds
2025-05-08 17:40:19,303:INFO:Declaring metric variables
2025-05-08 17:40:19,310:INFO:Importing untrained model
2025-05-08 17:40:19,318:INFO:Elastic Net Imported successfully
2025-05-08 17:40:19,327:INFO:Starting cross validation
2025-05-08 17:40:19,330:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-08 17:40:21,511:INFO:Calculating mean and std
2025-05-08 17:40:21,515:INFO:Creating metrics dataframe
2025-05-08 17:40:21,515:INFO:Uploading results into container
2025-05-08 17:40:21,515:INFO:Uploading model into container now
2025-05-08 17:40:21,515:INFO:_master_model_container: 4
2025-05-08 17:40:21,515:INFO:_display_container: 2
2025-05-08 17:40:21,523:INFO:ElasticNet(random_state=123)
2025-05-08 17:40:21,523:INFO:create_model() successfully completed......................................
2025-05-08 17:40:21,606:INFO:SubProcess create_model() end ==================================
2025-05-08 17:40:21,606:INFO:Creating metrics dataframe
2025-05-08 17:40:21,614:INFO:Initializing Least Angle Regression
2025-05-08 17:40:21,614:INFO:Total runtime is 0.5191585183143616 minutes
2025-05-08 17:40:21,618:INFO:SubProcess create_model() called ==================================
2025-05-08 17:40:21,618:INFO:Initializing create_model()
2025-05-08 17:40:21,621:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D4F9FBFF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-08 17:40:21,621:INFO:Checking exceptions
2025-05-08 17:40:21,622:INFO:Importing libraries
2025-05-08 17:40:21,623:INFO:Copying training dataset
2025-05-08 17:40:21,638:INFO:Defining folds
2025-05-08 17:40:21,646:INFO:Declaring metric variables
2025-05-08 17:40:21,654:INFO:Importing untrained model
2025-05-08 17:40:21,660:INFO:Least Angle Regression Imported successfully
2025-05-08 17:40:21,670:INFO:Starting cross validation
2025-05-08 17:40:21,678:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-08 17:40:23,278:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=3.438e+02, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-08 17:40:23,282:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=1.059e+03, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-08 17:40:23,284:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=7.755e+02, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-08 17:40:23,305:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:812: RuntimeWarning: overflow encountered in multiply
  coef[active] = prev_coef[active] + gamma_ * least_squares

2025-05-08 17:40:23,308:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:771: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2025-05-08 17:40:23,311:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:775: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2025-05-08 17:40:23,312:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:776: RuntimeWarning: overflow encountered in scalar divide
  gamma_ = min(g1, g2, C / AA)

2025-05-08 17:40:23,315:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:780: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2025-05-08 17:40:23,537:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\extmath.py:208: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b

2025-05-08 17:40:23,635:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py:501: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2025-05-08 17:40:23,635:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py:501: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2025-05-08 17:40:23,635:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py:1196: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2025-05-08 17:40:23,678:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-08 17:40:23,685:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-08 17:40:23,743:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-08 17:40:23,743:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-08 17:40:23,743:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-08 17:40:23,746:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-08 17:40:23,750:INFO:Calculating mean and std
2025-05-08 17:40:23,766:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\numpy\core\_methods.py:176: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-05-08 17:40:23,766:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\numpy\core\_methods.py:173: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)

2025-05-08 17:40:23,774:INFO:Creating metrics dataframe
2025-05-08 17:40:23,778:INFO:Uploading results into container
2025-05-08 17:40:23,778:INFO:Uploading model into container now
2025-05-08 17:40:23,783:INFO:_master_model_container: 5
2025-05-08 17:40:23,783:INFO:_display_container: 2
2025-05-08 17:40:23,783:INFO:Lars(random_state=123)
2025-05-08 17:40:23,783:INFO:create_model() successfully completed......................................
2025-05-08 17:40:23,856:WARNING:create_model() for Lars(random_state=123) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-05-08 17:40:23,874:WARNING:Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-05-08 17:40:23,874:INFO:Initializing create_model()
2025-05-08 17:40:23,874:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D4F9FBFF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-08 17:40:23,878:INFO:Checking exceptions
2025-05-08 17:40:23,878:INFO:Importing libraries
2025-05-08 17:40:23,878:INFO:Copying training dataset
2025-05-08 17:40:23,898:INFO:Defining folds
2025-05-08 17:40:23,898:INFO:Declaring metric variables
2025-05-08 17:40:23,900:INFO:Importing untrained model
2025-05-08 17:40:23,910:INFO:Least Angle Regression Imported successfully
2025-05-08 17:40:23,916:INFO:Starting cross validation
2025-05-08 17:40:23,923:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-08 17:40:25,549:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=3.438e+02, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-08 17:40:25,552:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=1.059e+03, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-08 17:40:25,556:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=7.755e+02, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-08 17:40:25,680:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:812: RuntimeWarning: overflow encountered in multiply
  coef[active] = prev_coef[active] + gamma_ * least_squares

2025-05-08 17:40:25,686:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:771: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2025-05-08 17:40:25,687:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:775: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2025-05-08 17:40:25,689:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:776: RuntimeWarning: overflow encountered in scalar divide
  gamma_ = min(g1, g2, C / AA)

2025-05-08 17:40:25,691:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:780: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2025-05-08 17:40:25,892:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\extmath.py:208: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b

2025-05-08 17:40:25,895:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py:501: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2025-05-08 17:40:25,895:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py:501: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2025-05-08 17:40:25,904:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py:1196: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2025-05-08 17:40:25,907:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-08 17:40:25,907:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-08 17:40:25,912:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-08 17:40:25,913:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-08 17:40:25,913:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-08 17:40:25,913:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-08 17:40:25,923:INFO:Calculating mean and std
2025-05-08 17:40:25,923:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\numpy\core\_methods.py:176: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-05-08 17:40:25,923:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\numpy\core\_methods.py:173: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)

2025-05-08 17:40:25,928:INFO:Creating metrics dataframe
2025-05-08 17:40:25,932:INFO:Uploading results into container
2025-05-08 17:40:25,932:INFO:Uploading model into container now
2025-05-08 17:40:25,936:INFO:_master_model_container: 6
2025-05-08 17:40:25,936:INFO:_display_container: 2
2025-05-08 17:40:25,936:INFO:Lars(random_state=123)
2025-05-08 17:40:25,936:INFO:create_model() successfully completed......................................
2025-05-08 17:40:26,032:ERROR:create_model() for Lars(random_state=123) raised an exception or returned all 0.0:
2025-05-08 17:40:26,036:ERROR:Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-05-08 17:40:26,036:INFO:Initializing Lasso Least Angle Regression
2025-05-08 17:40:26,036:INFO:Total runtime is 0.5928619821866353 minutes
2025-05-08 17:40:26,036:INFO:SubProcess create_model() called ==================================
2025-05-08 17:40:26,045:INFO:Initializing create_model()
2025-05-08 17:40:26,046:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D4F9FBFF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-08 17:40:26,046:INFO:Checking exceptions
2025-05-08 17:40:26,046:INFO:Importing libraries
2025-05-08 17:40:26,046:INFO:Copying training dataset
2025-05-08 17:40:26,080:INFO:Defining folds
2025-05-08 17:40:26,080:INFO:Declaring metric variables
2025-05-08 17:40:26,086:INFO:Importing untrained model
2025-05-08 17:40:26,086:INFO:Lasso Least Angle Regression Imported successfully
2025-05-08 17:40:26,104:INFO:Starting cross validation
2025-05-08 17:40:26,119:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-08 17:40:28,061:INFO:Calculating mean and std
2025-05-08 17:40:28,061:INFO:Creating metrics dataframe
2025-05-08 17:40:28,065:INFO:Uploading results into container
2025-05-08 17:40:28,065:INFO:Uploading model into container now
2025-05-08 17:40:28,065:INFO:_master_model_container: 7
2025-05-08 17:40:28,065:INFO:_display_container: 2
2025-05-08 17:40:28,065:INFO:LassoLars(random_state=123)
2025-05-08 17:40:28,073:INFO:create_model() successfully completed......................................
2025-05-08 17:40:28,147:INFO:SubProcess create_model() end ==================================
2025-05-08 17:40:28,147:INFO:Creating metrics dataframe
2025-05-08 17:40:28,156:INFO:Initializing Orthogonal Matching Pursuit
2025-05-08 17:40:28,164:INFO:Total runtime is 0.6283236543337504 minutes
2025-05-08 17:40:28,165:INFO:SubProcess create_model() called ==================================
2025-05-08 17:40:28,165:INFO:Initializing create_model()
2025-05-08 17:40:28,165:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D4F9FBFF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-08 17:40:28,165:INFO:Checking exceptions
2025-05-08 17:40:28,165:INFO:Importing libraries
2025-05-08 17:40:28,172:INFO:Copying training dataset
2025-05-08 17:40:28,208:INFO:Defining folds
2025-05-08 17:40:28,208:INFO:Declaring metric variables
2025-05-08 17:40:28,216:INFO:Importing untrained model
2025-05-08 17:40:28,222:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-08 17:40:28,239:INFO:Starting cross validation
2025-05-08 17:40:28,251:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-08 17:40:30,115:INFO:Calculating mean and std
2025-05-08 17:40:30,117:INFO:Creating metrics dataframe
2025-05-08 17:40:30,121:INFO:Uploading results into container
2025-05-08 17:40:30,121:INFO:Uploading model into container now
2025-05-08 17:40:30,126:INFO:_master_model_container: 8
2025-05-08 17:40:30,126:INFO:_display_container: 2
2025-05-08 17:40:30,128:INFO:OrthogonalMatchingPursuit()
2025-05-08 17:40:30,128:INFO:create_model() successfully completed......................................
2025-05-08 17:40:30,216:INFO:SubProcess create_model() end ==================================
2025-05-08 17:40:30,224:INFO:Creating metrics dataframe
2025-05-08 17:40:30,232:INFO:Initializing Bayesian Ridge
2025-05-08 17:40:30,232:INFO:Total runtime is 0.6627887368202209 minutes
2025-05-08 17:40:30,232:INFO:SubProcess create_model() called ==================================
2025-05-08 17:40:30,240:INFO:Initializing create_model()
2025-05-08 17:40:30,240:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D4F9FBFF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-08 17:40:30,240:INFO:Checking exceptions
2025-05-08 17:40:30,240:INFO:Importing libraries
2025-05-08 17:40:30,240:INFO:Copying training dataset
2025-05-08 17:40:30,280:INFO:Defining folds
2025-05-08 17:40:30,282:INFO:Declaring metric variables
2025-05-08 17:40:30,288:INFO:Importing untrained model
2025-05-08 17:40:30,297:INFO:Bayesian Ridge Imported successfully
2025-05-08 17:40:30,309:INFO:Starting cross validation
2025-05-08 17:40:30,322:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-08 17:40:33,717:INFO:Calculating mean and std
2025-05-08 17:40:33,719:INFO:Creating metrics dataframe
2025-05-08 17:40:33,719:INFO:Uploading results into container
2025-05-08 17:40:33,719:INFO:Uploading model into container now
2025-05-08 17:40:33,727:INFO:_master_model_container: 9
2025-05-08 17:40:33,727:INFO:_display_container: 2
2025-05-08 17:40:33,727:INFO:BayesianRidge()
2025-05-08 17:40:33,727:INFO:create_model() successfully completed......................................
2025-05-08 17:40:33,826:INFO:SubProcess create_model() end ==================================
2025-05-08 17:40:33,826:INFO:Creating metrics dataframe
2025-05-08 17:40:33,834:INFO:Initializing Passive Aggressive Regressor
2025-05-08 17:40:33,834:INFO:Total runtime is 0.7228259762128193 minutes
2025-05-08 17:40:33,844:INFO:SubProcess create_model() called ==================================
2025-05-08 17:40:33,844:INFO:Initializing create_model()
2025-05-08 17:40:33,844:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D4F9FBFF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-08 17:40:33,844:INFO:Checking exceptions
2025-05-08 17:40:33,844:INFO:Importing libraries
2025-05-08 17:40:33,850:INFO:Copying training dataset
2025-05-08 17:40:33,880:INFO:Defining folds
2025-05-08 17:40:33,880:INFO:Declaring metric variables
2025-05-08 17:40:33,885:INFO:Importing untrained model
2025-05-08 17:40:33,895:INFO:Passive Aggressive Regressor Imported successfully
2025-05-08 17:40:33,909:INFO:Starting cross validation
2025-05-08 17:40:33,915:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-08 17:40:36,826:INFO:Calculating mean and std
2025-05-08 17:40:36,829:INFO:Creating metrics dataframe
2025-05-08 17:40:36,832:INFO:Uploading results into container
2025-05-08 17:40:36,832:INFO:Uploading model into container now
2025-05-08 17:40:36,832:INFO:_master_model_container: 10
2025-05-08 17:40:36,832:INFO:_display_container: 2
2025-05-08 17:40:36,832:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-08 17:40:36,837:INFO:create_model() successfully completed......................................
2025-05-08 17:40:36,904:INFO:SubProcess create_model() end ==================================
2025-05-08 17:40:36,904:INFO:Creating metrics dataframe
2025-05-08 17:40:36,915:INFO:Initializing Huber Regressor
2025-05-08 17:40:36,917:INFO:Total runtime is 0.7742141564687092 minutes
2025-05-08 17:40:36,921:INFO:SubProcess create_model() called ==================================
2025-05-08 17:40:36,921:INFO:Initializing create_model()
2025-05-08 17:40:36,921:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D4F9FBFF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-08 17:40:36,921:INFO:Checking exceptions
2025-05-08 17:40:36,921:INFO:Importing libraries
2025-05-08 17:40:36,924:INFO:Copying training dataset
2025-05-08 17:40:36,945:INFO:Defining folds
2025-05-08 17:40:36,952:INFO:Declaring metric variables
2025-05-08 17:40:36,958:INFO:Importing untrained model
2025-05-08 17:40:36,963:INFO:Huber Regressor Imported successfully
2025-05-08 17:40:36,970:INFO:Starting cross validation
2025-05-08 17:40:36,978:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-08 17:40:41,030:INFO:Calculating mean and std
2025-05-08 17:40:41,030:INFO:Creating metrics dataframe
2025-05-08 17:40:41,030:INFO:Uploading results into container
2025-05-08 17:40:41,037:INFO:Uploading model into container now
2025-05-08 17:40:41,037:INFO:_master_model_container: 11
2025-05-08 17:40:41,037:INFO:_display_container: 2
2025-05-08 17:40:41,037:INFO:HuberRegressor()
2025-05-08 17:40:41,037:INFO:create_model() successfully completed......................................
2025-05-08 17:40:41,121:INFO:SubProcess create_model() end ==================================
2025-05-08 17:40:41,127:INFO:Creating metrics dataframe
2025-05-08 17:40:41,137:INFO:Initializing K Neighbors Regressor
2025-05-08 17:40:41,137:INFO:Total runtime is 0.8445402979850768 minutes
2025-05-08 17:40:41,146:INFO:SubProcess create_model() called ==================================
2025-05-08 17:40:41,146:INFO:Initializing create_model()
2025-05-08 17:40:41,146:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D4F9FBFF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-08 17:40:41,146:INFO:Checking exceptions
2025-05-08 17:40:41,146:INFO:Importing libraries
2025-05-08 17:40:41,146:INFO:Copying training dataset
2025-05-08 17:40:41,170:INFO:Defining folds
2025-05-08 17:40:41,172:INFO:Declaring metric variables
2025-05-08 17:40:41,172:INFO:Importing untrained model
2025-05-08 17:40:41,182:INFO:K Neighbors Regressor Imported successfully
2025-05-08 17:40:41,195:INFO:Starting cross validation
2025-05-08 17:40:41,201:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-08 17:40:47,059:INFO:Calculating mean and std
2025-05-08 17:40:47,061:INFO:Creating metrics dataframe
2025-05-08 17:40:47,066:INFO:Uploading results into container
2025-05-08 17:40:47,067:INFO:Uploading model into container now
2025-05-08 17:40:47,069:INFO:_master_model_container: 12
2025-05-08 17:40:47,070:INFO:_display_container: 2
2025-05-08 17:40:47,070:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-08 17:40:47,071:INFO:create_model() successfully completed......................................
2025-05-08 17:40:47,157:INFO:SubProcess create_model() end ==================================
2025-05-08 17:40:47,158:INFO:Creating metrics dataframe
2025-05-08 17:40:47,164:INFO:Initializing Decision Tree Regressor
2025-05-08 17:40:47,164:INFO:Total runtime is 0.9449941873550414 minutes
2025-05-08 17:40:47,173:INFO:SubProcess create_model() called ==================================
2025-05-08 17:40:47,173:INFO:Initializing create_model()
2025-05-08 17:40:47,173:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D4F9FBFF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-08 17:40:47,173:INFO:Checking exceptions
2025-05-08 17:40:47,173:INFO:Importing libraries
2025-05-08 17:40:47,173:INFO:Copying training dataset
2025-05-08 17:40:47,198:INFO:Defining folds
2025-05-08 17:40:47,198:INFO:Declaring metric variables
2025-05-08 17:40:47,206:INFO:Importing untrained model
2025-05-08 17:40:47,211:INFO:Decision Tree Regressor Imported successfully
2025-05-08 17:40:47,222:INFO:Starting cross validation
2025-05-08 17:40:47,236:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-08 17:40:50,237:INFO:Calculating mean and std
2025-05-08 17:40:50,237:INFO:Creating metrics dataframe
2025-05-08 17:40:50,242:INFO:Uploading results into container
2025-05-08 17:40:50,242:INFO:Uploading model into container now
2025-05-08 17:40:50,244:INFO:_master_model_container: 13
2025-05-08 17:40:50,244:INFO:_display_container: 2
2025-05-08 17:40:50,247:INFO:DecisionTreeRegressor(random_state=123)
2025-05-08 17:40:50,247:INFO:create_model() successfully completed......................................
2025-05-08 17:40:50,328:INFO:SubProcess create_model() end ==================================
2025-05-08 17:40:50,332:INFO:Creating metrics dataframe
2025-05-08 17:40:50,335:INFO:Initializing Random Forest Regressor
2025-05-08 17:40:50,335:INFO:Total runtime is 0.9978474140167235 minutes
2025-05-08 17:40:50,343:INFO:SubProcess create_model() called ==================================
2025-05-08 17:40:50,343:INFO:Initializing create_model()
2025-05-08 17:40:50,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D4F9FBFF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-08 17:40:50,343:INFO:Checking exceptions
2025-05-08 17:40:50,343:INFO:Importing libraries
2025-05-08 17:40:50,343:INFO:Copying training dataset
2025-05-08 17:40:50,385:INFO:Defining folds
2025-05-08 17:40:50,385:INFO:Declaring metric variables
2025-05-08 17:40:50,391:INFO:Importing untrained model
2025-05-08 17:40:50,399:INFO:Random Forest Regressor Imported successfully
2025-05-08 17:40:50,409:INFO:Starting cross validation
2025-05-08 17:40:50,419:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-08 17:42:13,005:INFO:Calculating mean and std
2025-05-08 17:42:13,054:INFO:Creating metrics dataframe
2025-05-08 17:42:13,095:INFO:Uploading results into container
2025-05-08 17:42:13,100:INFO:Uploading model into container now
2025-05-08 17:42:13,107:INFO:_master_model_container: 14
2025-05-08 17:42:13,107:INFO:_display_container: 2
2025-05-08 17:42:13,118:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-08 17:42:13,118:INFO:create_model() successfully completed......................................
2025-05-08 17:42:13,467:INFO:SubProcess create_model() end ==================================
2025-05-08 17:42:13,467:INFO:Creating metrics dataframe
2025-05-08 17:42:13,502:INFO:Initializing Extra Trees Regressor
2025-05-08 17:42:13,504:INFO:Total runtime is 2.3839963595072424 minutes
2025-05-08 17:42:13,514:INFO:SubProcess create_model() called ==================================
2025-05-08 17:42:13,514:INFO:Initializing create_model()
2025-05-08 17:42:13,514:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D4F9FBFF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-08 17:42:13,517:INFO:Checking exceptions
2025-05-08 17:42:13,517:INFO:Importing libraries
2025-05-08 17:42:13,517:INFO:Copying training dataset
2025-05-08 17:42:13,599:INFO:Defining folds
2025-05-08 17:42:13,599:INFO:Declaring metric variables
2025-05-08 17:42:13,611:INFO:Importing untrained model
2025-05-08 17:42:13,622:INFO:Extra Trees Regressor Imported successfully
2025-05-08 17:42:13,647:INFO:Starting cross validation
2025-05-08 17:42:13,671:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-08 17:44:06,781:INFO:Calculating mean and std
2025-05-08 17:44:06,998:INFO:Creating metrics dataframe
2025-05-08 17:44:07,162:INFO:Uploading results into container
2025-05-08 17:44:07,178:INFO:Uploading model into container now
2025-05-08 17:44:07,194:INFO:_master_model_container: 15
2025-05-08 17:44:07,194:INFO:_display_container: 2
2025-05-08 17:44:07,210:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-08 17:44:07,210:INFO:create_model() successfully completed......................................
2025-05-08 17:44:08,523:INFO:SubProcess create_model() end ==================================
2025-05-08 17:44:08,526:INFO:Creating metrics dataframe
2025-05-08 17:44:08,577:INFO:Initializing AdaBoost Regressor
2025-05-08 17:44:08,577:INFO:Total runtime is 4.301866396268208 minutes
2025-05-08 17:44:08,596:INFO:SubProcess create_model() called ==================================
2025-05-08 17:44:08,596:INFO:Initializing create_model()
2025-05-08 17:44:08,600:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D4F9FBFF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-08 17:44:08,600:INFO:Checking exceptions
2025-05-08 17:44:08,600:INFO:Importing libraries
2025-05-08 17:44:08,603:INFO:Copying training dataset
2025-05-08 17:44:08,686:INFO:Defining folds
2025-05-08 17:44:08,686:INFO:Declaring metric variables
2025-05-08 17:44:08,698:INFO:Importing untrained model
2025-05-08 17:44:08,702:INFO:AdaBoost Regressor Imported successfully
2025-05-08 17:44:08,727:INFO:Starting cross validation
2025-05-08 17:44:08,753:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-08 17:44:31,054:INFO:Calculating mean and std
2025-05-08 17:44:31,054:INFO:Creating metrics dataframe
2025-05-08 17:44:31,062:INFO:Uploading results into container
2025-05-08 17:44:31,062:INFO:Uploading model into container now
2025-05-08 17:44:31,062:INFO:_master_model_container: 16
2025-05-08 17:44:31,062:INFO:_display_container: 2
2025-05-08 17:44:31,066:INFO:AdaBoostRegressor(random_state=123)
2025-05-08 17:44:31,066:INFO:create_model() successfully completed......................................
2025-05-08 17:44:31,161:INFO:SubProcess create_model() end ==================================
2025-05-08 17:44:31,161:INFO:Creating metrics dataframe
2025-05-08 17:44:31,178:INFO:Initializing Gradient Boosting Regressor
2025-05-08 17:44:31,178:INFO:Total runtime is 4.678555230299631 minutes
2025-05-08 17:44:31,184:INFO:SubProcess create_model() called ==================================
2025-05-08 17:44:31,186:INFO:Initializing create_model()
2025-05-08 17:44:31,186:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D4F9FBFF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-08 17:44:31,186:INFO:Checking exceptions
2025-05-08 17:44:31,186:INFO:Importing libraries
2025-05-08 17:44:31,186:INFO:Copying training dataset
2025-05-08 17:44:31,228:INFO:Defining folds
2025-05-08 17:44:31,230:INFO:Declaring metric variables
2025-05-08 17:44:31,235:INFO:Importing untrained model
2025-05-08 17:44:31,244:INFO:Gradient Boosting Regressor Imported successfully
2025-05-08 17:44:31,266:INFO:Starting cross validation
2025-05-08 17:44:31,277:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-08 17:44:50,199:INFO:Calculating mean and std
2025-05-08 17:44:50,199:INFO:Creating metrics dataframe
2025-05-08 17:44:50,207:INFO:Uploading results into container
2025-05-08 17:44:50,207:INFO:Uploading model into container now
2025-05-08 17:44:50,207:INFO:_master_model_container: 17
2025-05-08 17:44:50,207:INFO:_display_container: 2
2025-05-08 17:44:50,212:INFO:GradientBoostingRegressor(random_state=123)
2025-05-08 17:44:50,212:INFO:create_model() successfully completed......................................
2025-05-08 17:44:50,295:INFO:SubProcess create_model() end ==================================
2025-05-08 17:44:50,295:INFO:Creating metrics dataframe
2025-05-08 17:44:50,310:INFO:Initializing Light Gradient Boosting Machine
2025-05-08 17:44:50,310:INFO:Total runtime is 4.997430948416391 minutes
2025-05-08 17:44:50,310:INFO:SubProcess create_model() called ==================================
2025-05-08 17:44:50,318:INFO:Initializing create_model()
2025-05-08 17:44:50,318:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D4F9FBFF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-08 17:44:50,318:INFO:Checking exceptions
2025-05-08 17:44:50,318:INFO:Importing libraries
2025-05-08 17:44:50,318:INFO:Copying training dataset
2025-05-08 17:44:50,341:INFO:Defining folds
2025-05-08 17:44:50,341:INFO:Declaring metric variables
2025-05-08 17:44:50,347:INFO:Importing untrained model
2025-05-08 17:44:50,353:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-08 17:44:50,367:INFO:Starting cross validation
2025-05-08 17:44:50,376:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-08 17:44:56,137:INFO:Calculating mean and std
2025-05-08 17:44:56,139:INFO:Creating metrics dataframe
2025-05-08 17:44:56,143:INFO:Uploading results into container
2025-05-08 17:44:56,145:INFO:Uploading model into container now
2025-05-08 17:44:56,151:INFO:_master_model_container: 18
2025-05-08 17:44:56,151:INFO:_display_container: 2
2025-05-08 17:44:56,151:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-08 17:44:56,153:INFO:create_model() successfully completed......................................
2025-05-08 17:44:56,258:INFO:SubProcess create_model() end ==================================
2025-05-08 17:44:56,258:INFO:Creating metrics dataframe
2025-05-08 17:44:56,299:INFO:Initializing Dummy Regressor
2025-05-08 17:44:56,299:INFO:Total runtime is 5.0972472270329785 minutes
2025-05-08 17:44:56,307:INFO:SubProcess create_model() called ==================================
2025-05-08 17:44:56,307:INFO:Initializing create_model()
2025-05-08 17:44:56,307:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D4F9FBFF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-08 17:44:56,312:INFO:Checking exceptions
2025-05-08 17:44:56,312:INFO:Importing libraries
2025-05-08 17:44:56,312:INFO:Copying training dataset
2025-05-08 17:44:56,347:INFO:Defining folds
2025-05-08 17:44:56,349:INFO:Declaring metric variables
2025-05-08 17:44:56,349:INFO:Importing untrained model
2025-05-08 17:44:56,359:INFO:Dummy Regressor Imported successfully
2025-05-08 17:44:56,373:INFO:Starting cross validation
2025-05-08 17:44:56,380:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-08 17:44:58,406:INFO:Calculating mean and std
2025-05-08 17:44:58,414:INFO:Creating metrics dataframe
2025-05-08 17:44:58,419:INFO:Uploading results into container
2025-05-08 17:44:58,421:INFO:Uploading model into container now
2025-05-08 17:44:58,423:INFO:_master_model_container: 19
2025-05-08 17:44:58,423:INFO:_display_container: 2
2025-05-08 17:44:58,423:INFO:DummyRegressor()
2025-05-08 17:44:58,423:INFO:create_model() successfully completed......................................
2025-05-08 17:44:58,527:INFO:SubProcess create_model() end ==================================
2025-05-08 17:44:58,527:INFO:Creating metrics dataframe
2025-05-08 17:44:58,544:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-08 17:44:58,556:INFO:Initializing create_model()
2025-05-08 17:44:58,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D4C398B190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-08 17:44:58,560:INFO:Checking exceptions
2025-05-08 17:44:58,560:INFO:Importing libraries
2025-05-08 17:44:58,566:INFO:Copying training dataset
2025-05-08 17:44:58,606:INFO:Defining folds
2025-05-08 17:44:58,608:INFO:Declaring metric variables
2025-05-08 17:44:58,610:INFO:Importing untrained model
2025-05-08 17:44:58,610:INFO:Declaring custom model
2025-05-08 17:44:58,613:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-08 17:44:58,626:INFO:Cross validation set to False
2025-05-08 17:44:58,626:INFO:Fitting Model
2025-05-08 17:44:59,457:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003718 seconds.
2025-05-08 17:44:59,457:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-08 17:44:59,457:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-08 17:44:59,458:INFO:[LightGBM] [Info] Total Bins 1128
2025-05-08 17:44:59,458:INFO:[LightGBM] [Info] Number of data points in the train set: 43469, number of used features: 71
2025-05-08 17:44:59,458:INFO:[LightGBM] [Info] Start training from score 437115.043893
2025-05-08 17:44:59,611:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-08 17:44:59,611:INFO:create_model() successfully completed......................................
2025-05-08 17:44:59,727:INFO:_master_model_container: 19
2025-05-08 17:44:59,727:INFO:_display_container: 2
2025-05-08 17:44:59,727:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-08 17:44:59,727:INFO:compare_models() successfully completed......................................
2025-05-09 11:32:19,909:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-09 11:32:20,225:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-09 11:32:20,241:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-09 11:32:20,241:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-09 11:32:20,492:INFO:PyCaret RegressionExperiment
2025-05-09 11:32:20,758:INFO:Logging name: reg-default-name
2025-05-09 11:32:20,758:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-09 11:32:20,758:INFO:version 3.3.2
2025-05-09 11:32:20,758:INFO:Initializing setup()
2025-05-09 11:32:20,758:INFO:self.USI: fd0a
2025-05-09 11:32:20,758:INFO:self._variable_keys: {'_available_plots', 'log_plots_param', 'data', 'gpu_param', '_ml_usecase', 'target_param', 'X', 'gpu_n_jobs_param', 'fold_generator', 'y_train', 'exp_name_log', 'USI', 'idx', 'n_jobs_param', 'y_test', 'y', 'fold_shuffle_param', 'transform_target_param', 'pipeline', 'logging_param', 'X_train', 'X_test', 'fold_groups_param', 'seed', 'exp_id', 'memory', 'html_param'}
2025-05-09 11:32:20,758:INFO:Checking environment
2025-05-09 11:32:20,758:INFO:python_version: 3.11.7
2025-05-09 11:32:20,758:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2025-05-09 11:32:20,758:INFO:machine: AMD64
2025-05-09 11:32:20,758:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-09 11:32:20,758:INFO:Memory: svmem(total=8274710528, available=982417408, percent=88.1, used=7292293120, free=982417408)
2025-05-09 11:32:20,758:INFO:Physical Core: 10
2025-05-09 11:32:20,758:INFO:Logical Core: 12
2025-05-09 11:32:20,774:INFO:Checking libraries
2025-05-09 11:32:20,775:INFO:System:
2025-05-09 11:32:20,775:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2025-05-09 11:32:20,775:INFO:executable: c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Scripts\python.exe
2025-05-09 11:32:20,775:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-09 11:32:20,775:INFO:PyCaret required dependencies:
2025-05-09 11:32:20,858:INFO:                 pip: 23.2.1
2025-05-09 11:32:20,858:INFO:          setuptools: 65.5.0
2025-05-09 11:32:20,858:INFO:             pycaret: 3.3.2
2025-05-09 11:32:20,858:INFO:             IPython: 9.2.0
2025-05-09 11:32:20,858:INFO:          ipywidgets: 8.1.7
2025-05-09 11:32:20,858:INFO:                tqdm: 4.67.1
2025-05-09 11:32:20,858:INFO:               numpy: 1.26.4
2025-05-09 11:32:20,858:INFO:              pandas: 2.1.4
2025-05-09 11:32:20,858:INFO:              jinja2: 3.1.6
2025-05-09 11:32:20,858:INFO:               scipy: 1.11.4
2025-05-09 11:32:20,858:INFO:              joblib: 1.3.2
2025-05-09 11:32:20,858:INFO:             sklearn: 1.4.2
2025-05-09 11:32:20,858:INFO:                pyod: 2.0.5
2025-05-09 11:32:20,858:INFO:            imblearn: 0.13.0
2025-05-09 11:32:20,858:INFO:   category_encoders: 2.7.0
2025-05-09 11:32:20,858:INFO:            lightgbm: 4.6.0
2025-05-09 11:32:20,858:INFO:               numba: 0.61.2
2025-05-09 11:32:20,858:INFO:            requests: 2.32.3
2025-05-09 11:32:20,858:INFO:          matplotlib: 3.7.5
2025-05-09 11:32:20,858:INFO:          scikitplot: 0.3.7
2025-05-09 11:32:20,858:INFO:         yellowbrick: 1.5
2025-05-09 11:32:20,858:INFO:              plotly: 5.24.1
2025-05-09 11:32:20,858:INFO:    plotly-resampler: Not installed
2025-05-09 11:32:20,858:INFO:             kaleido: 0.2.1
2025-05-09 11:32:20,858:INFO:           schemdraw: 0.15
2025-05-09 11:32:20,858:INFO:         statsmodels: 0.14.4
2025-05-09 11:32:20,858:INFO:              sktime: 0.26.0
2025-05-09 11:32:20,858:INFO:               tbats: 1.1.3
2025-05-09 11:32:20,858:INFO:            pmdarima: 2.0.4
2025-05-09 11:32:20,858:INFO:              psutil: 7.0.0
2025-05-09 11:32:20,858:INFO:          markupsafe: 3.0.2
2025-05-09 11:32:20,858:INFO:             pickle5: Not installed
2025-05-09 11:32:20,858:INFO:         cloudpickle: 3.1.1
2025-05-09 11:32:20,858:INFO:         deprecation: 2.1.0
2025-05-09 11:32:20,858:INFO:              xxhash: 3.5.0
2025-05-09 11:32:20,858:INFO:           wurlitzer: Not installed
2025-05-09 11:32:20,858:INFO:PyCaret optional dependencies:
2025-05-09 11:32:20,907:INFO:                shap: Not installed
2025-05-09 11:32:20,907:INFO:           interpret: Not installed
2025-05-09 11:32:20,908:INFO:                umap: Not installed
2025-05-09 11:32:20,908:INFO:     ydata_profiling: Not installed
2025-05-09 11:32:20,908:INFO:  explainerdashboard: Not installed
2025-05-09 11:32:20,908:INFO:             autoviz: Not installed
2025-05-09 11:32:20,908:INFO:           fairlearn: Not installed
2025-05-09 11:32:20,908:INFO:          deepchecks: Not installed
2025-05-09 11:32:20,908:INFO:             xgboost: Not installed
2025-05-09 11:32:20,908:INFO:            catboost: Not installed
2025-05-09 11:32:20,908:INFO:              kmodes: Not installed
2025-05-09 11:32:20,908:INFO:             mlxtend: Not installed
2025-05-09 11:32:20,908:INFO:       statsforecast: Not installed
2025-05-09 11:32:20,908:INFO:        tune_sklearn: Not installed
2025-05-09 11:32:20,908:INFO:                 ray: Not installed
2025-05-09 11:32:20,908:INFO:            hyperopt: Not installed
2025-05-09 11:32:20,908:INFO:              optuna: Not installed
2025-05-09 11:32:20,908:INFO:               skopt: Not installed
2025-05-09 11:32:20,908:INFO:              mlflow: Not installed
2025-05-09 11:32:20,908:INFO:              gradio: Not installed
2025-05-09 11:32:20,908:INFO:             fastapi: Not installed
2025-05-09 11:32:20,908:INFO:             uvicorn: Not installed
2025-05-09 11:32:20,908:INFO:              m2cgen: Not installed
2025-05-09 11:32:20,908:INFO:           evidently: Not installed
2025-05-09 11:32:20,908:INFO:               fugue: Not installed
2025-05-09 11:32:20,908:INFO:           streamlit: 1.45.0
2025-05-09 11:32:20,908:INFO:             prophet: Not installed
2025-05-09 11:32:20,908:INFO:None
2025-05-09 11:32:20,908:INFO:Set up data.
2025-05-09 11:32:21,008:INFO:Set up folding strategy.
2025-05-09 11:32:21,008:INFO:Set up train/test split.
2025-05-09 11:32:21,058:INFO:Set up index.
2025-05-09 11:32:21,058:INFO:Assigning column types.
2025-05-09 11:32:21,071:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-09 11:32:21,071:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,078:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,078:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,125:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,143:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,143:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,158:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,158:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,158:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,191:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,225:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,225:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,225:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,225:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-09 11:32:21,225:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,225:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,275:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,291:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,291:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,291:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,291:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,307:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,343:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,376:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,377:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,377:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,378:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-09 11:32:21,384:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,425:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,441:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,458:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,515:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,578:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,579:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,581:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,582:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-09 11:32:21,628:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,654:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,654:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,655:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,699:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,734:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,736:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,736:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-09 11:32:21,790:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,866:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-09 11:32:21,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,896:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,897:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-09 11:32:21,970:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:21,971:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:22,087:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:22,088:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:22,093:INFO:Preparing preprocessing pipeline...
2025-05-09 11:32:22,093:INFO:Set up simple imputation.
2025-05-09 11:32:22,106:INFO:Set up encoding of ordinal features.
2025-05-09 11:32:22,112:INFO:Set up encoding of categorical features.
2025-05-09 11:32:23,062:INFO:Finished creating preprocessing pipeline.
2025-05-09 11:32:23,086:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LINW~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['bedroomCount', 'bathroomCount',
                                             'postCode', 'habitableSurface',
                                             'buildingConstructionYear',
                                             'facedeCount', 'toiletCount'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['type', 'subtype',...
                                             'floodZoneType', 'heatingType',
                                             'kitchenType', 'epcScore'],
                                    transformer=OneHotEncoder(cols=['subtype',
                                                                    'buildingCondition',
                                                                    'floodZoneType',
                                                                    'heatingType',
                                                                    'kitchenType',
                                                                    'epcScore'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['locality'],
                                    transformer=TargetEncoder(cols=['locality'],
                                                              handle_missing='return_nan')))])
2025-05-09 11:32:23,087:INFO:Creating final display dataframe.
2025-05-09 11:32:24,285:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             price
2                   Target type        Regression
3           Original data shape       (62099, 20)
4        Transformed data shape       (62099, 77)
5   Transformed train set shape       (43469, 77)
6    Transformed test set shape       (18630, 77)
7              Numeric features                 7
8          Categorical features                 8
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              fd0a
2025-05-09 11:32:24,405:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:24,405:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:24,481:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:24,482:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-09 11:32:24,483:INFO:setup() successfully completed in 4.01s...............
2025-05-09 11:32:29,463:INFO:Initializing compare_models()
2025-05-09 11:32:29,464:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-09 11:32:29,465:INFO:Checking exceptions
2025-05-09 11:32:29,481:INFO:Preparing display monitor
2025-05-09 11:32:29,522:INFO:Initializing Linear Regression
2025-05-09 11:32:29,522:INFO:Total runtime is 0.0 minutes
2025-05-09 11:32:29,528:INFO:SubProcess create_model() called ==================================
2025-05-09 11:32:29,528:INFO:Initializing create_model()
2025-05-09 11:32:29,529:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E2EA93590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 11:32:29,529:INFO:Checking exceptions
2025-05-09 11:32:29,529:INFO:Importing libraries
2025-05-09 11:32:29,530:INFO:Copying training dataset
2025-05-09 11:32:29,554:INFO:Defining folds
2025-05-09 11:32:29,555:INFO:Declaring metric variables
2025-05-09 11:32:29,560:INFO:Importing untrained model
2025-05-09 11:32:29,565:INFO:Linear Regression Imported successfully
2025-05-09 11:32:29,575:INFO:Starting cross validation
2025-05-09 11:32:29,586:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 11:32:37,698:INFO:Calculating mean and std
2025-05-09 11:32:37,702:INFO:Creating metrics dataframe
2025-05-09 11:32:37,710:INFO:Uploading results into container
2025-05-09 11:32:37,712:INFO:Uploading model into container now
2025-05-09 11:32:37,716:INFO:_master_model_container: 1
2025-05-09 11:32:37,720:INFO:_display_container: 2
2025-05-09 11:32:37,724:INFO:LinearRegression(n_jobs=-1)
2025-05-09 11:32:37,731:INFO:create_model() successfully completed......................................
2025-05-09 11:32:37,860:INFO:SubProcess create_model() end ==================================
2025-05-09 11:32:37,861:INFO:Creating metrics dataframe
2025-05-09 11:32:37,865:INFO:Initializing Lasso Regression
2025-05-09 11:32:37,865:INFO:Total runtime is 0.13905056715011596 minutes
2025-05-09 11:32:37,865:INFO:SubProcess create_model() called ==================================
2025-05-09 11:32:37,865:INFO:Initializing create_model()
2025-05-09 11:32:37,865:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E2EA93590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 11:32:37,865:INFO:Checking exceptions
2025-05-09 11:32:37,865:INFO:Importing libraries
2025-05-09 11:32:37,865:INFO:Copying training dataset
2025-05-09 11:32:37,881:INFO:Defining folds
2025-05-09 11:32:37,881:INFO:Declaring metric variables
2025-05-09 11:32:37,896:INFO:Importing untrained model
2025-05-09 11:32:37,900:INFO:Lasso Regression Imported successfully
2025-05-09 11:32:37,911:INFO:Starting cross validation
2025-05-09 11:32:37,914:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 11:32:51,976:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e+15, tolerance: 9.869e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-09 11:32:52,139:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.900e+15, tolerance: 9.796e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-09 11:32:52,161:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.575e+15, tolerance: 9.769e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-09 11:32:52,223:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.211e+15, tolerance: 9.820e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-09 11:32:52,245:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e+15, tolerance: 9.682e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-09 11:32:53,987:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.928e+14, tolerance: 9.979e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-09 11:32:54,018:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.235e+15, tolerance: 9.867e+11
  model = cd_fast.enet_coordinate_descent(

2025-05-09 11:32:54,102:INFO:Calculating mean and std
2025-05-09 11:32:54,102:INFO:Creating metrics dataframe
2025-05-09 11:32:54,106:INFO:Uploading results into container
2025-05-09 11:32:54,108:INFO:Uploading model into container now
2025-05-09 11:32:54,109:INFO:_master_model_container: 2
2025-05-09 11:32:54,109:INFO:_display_container: 2
2025-05-09 11:32:54,109:INFO:Lasso(random_state=123)
2025-05-09 11:32:54,109:INFO:create_model() successfully completed......................................
2025-05-09 11:32:54,176:INFO:SubProcess create_model() end ==================================
2025-05-09 11:32:54,176:INFO:Creating metrics dataframe
2025-05-09 11:32:54,192:INFO:Initializing Ridge Regression
2025-05-09 11:32:54,192:INFO:Total runtime is 0.4111768722534179 minutes
2025-05-09 11:32:54,192:INFO:SubProcess create_model() called ==================================
2025-05-09 11:32:54,192:INFO:Initializing create_model()
2025-05-09 11:32:54,192:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E2EA93590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 11:32:54,192:INFO:Checking exceptions
2025-05-09 11:32:54,192:INFO:Importing libraries
2025-05-09 11:32:54,192:INFO:Copying training dataset
2025-05-09 11:32:54,225:INFO:Defining folds
2025-05-09 11:32:54,226:INFO:Declaring metric variables
2025-05-09 11:32:54,232:INFO:Importing untrained model
2025-05-09 11:32:54,240:INFO:Ridge Regression Imported successfully
2025-05-09 11:32:54,252:INFO:Starting cross validation
2025-05-09 11:32:54,256:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 11:32:56,026:INFO:Calculating mean and std
2025-05-09 11:32:56,026:INFO:Creating metrics dataframe
2025-05-09 11:32:56,031:INFO:Uploading results into container
2025-05-09 11:32:56,033:INFO:Uploading model into container now
2025-05-09 11:32:56,033:INFO:_master_model_container: 3
2025-05-09 11:32:56,033:INFO:_display_container: 2
2025-05-09 11:32:56,033:INFO:Ridge(random_state=123)
2025-05-09 11:32:56,033:INFO:create_model() successfully completed......................................
2025-05-09 11:32:56,107:INFO:SubProcess create_model() end ==================================
2025-05-09 11:32:56,108:INFO:Creating metrics dataframe
2025-05-09 11:32:56,115:INFO:Initializing Elastic Net
2025-05-09 11:32:56,116:INFO:Total runtime is 0.44323367675145464 minutes
2025-05-09 11:32:56,119:INFO:SubProcess create_model() called ==================================
2025-05-09 11:32:56,120:INFO:Initializing create_model()
2025-05-09 11:32:56,120:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E2EA93590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 11:32:56,120:INFO:Checking exceptions
2025-05-09 11:32:56,121:INFO:Importing libraries
2025-05-09 11:32:56,121:INFO:Copying training dataset
2025-05-09 11:32:56,126:INFO:Defining folds
2025-05-09 11:32:56,126:INFO:Declaring metric variables
2025-05-09 11:32:56,142:INFO:Importing untrained model
2025-05-09 11:32:56,146:INFO:Elastic Net Imported successfully
2025-05-09 11:32:56,159:INFO:Starting cross validation
2025-05-09 11:32:56,162:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 11:32:58,703:INFO:Calculating mean and std
2025-05-09 11:32:58,703:INFO:Creating metrics dataframe
2025-05-09 11:32:58,712:INFO:Uploading results into container
2025-05-09 11:32:58,713:INFO:Uploading model into container now
2025-05-09 11:32:58,715:INFO:_master_model_container: 4
2025-05-09 11:32:58,716:INFO:_display_container: 2
2025-05-09 11:32:58,719:INFO:ElasticNet(random_state=123)
2025-05-09 11:32:58,721:INFO:create_model() successfully completed......................................
2025-05-09 11:32:58,822:INFO:SubProcess create_model() end ==================================
2025-05-09 11:32:58,822:INFO:Creating metrics dataframe
2025-05-09 11:32:58,828:INFO:Initializing Least Angle Regression
2025-05-09 11:32:58,828:INFO:Total runtime is 0.48843379020690914 minutes
2025-05-09 11:32:58,828:INFO:SubProcess create_model() called ==================================
2025-05-09 11:32:58,828:INFO:Initializing create_model()
2025-05-09 11:32:58,828:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E2EA93590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 11:32:58,828:INFO:Checking exceptions
2025-05-09 11:32:58,828:INFO:Importing libraries
2025-05-09 11:32:58,842:INFO:Copying training dataset
2025-05-09 11:32:58,867:INFO:Defining folds
2025-05-09 11:32:58,868:INFO:Declaring metric variables
2025-05-09 11:32:58,873:INFO:Importing untrained model
2025-05-09 11:32:58,879:INFO:Least Angle Regression Imported successfully
2025-05-09 11:32:58,893:INFO:Starting cross validation
2025-05-09 11:32:58,898:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 11:33:00,474:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=3.438e+02, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-09 11:33:00,478:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=1.059e+03, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-09 11:33:00,481:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=7.755e+02, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-09 11:33:00,606:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:812: RuntimeWarning: overflow encountered in multiply
  coef[active] = prev_coef[active] + gamma_ * least_squares

2025-05-09 11:33:00,608:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:771: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2025-05-09 11:33:00,609:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:775: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2025-05-09 11:33:00,611:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:776: RuntimeWarning: overflow encountered in scalar divide
  gamma_ = min(g1, g2, C / AA)

2025-05-09 11:33:00,613:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:780: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2025-05-09 11:33:00,801:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\extmath.py:208: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b

2025-05-09 11:33:00,843:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py:501: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2025-05-09 11:33:00,849:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py:501: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2025-05-09 11:33:00,849:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py:1196: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2025-05-09 11:33:00,911:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-09 11:33:00,913:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-09 11:33:00,947:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-09 11:33:00,949:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-09 11:33:00,949:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-09 11:33:00,949:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-09 11:33:00,958:INFO:Calculating mean and std
2025-05-09 11:33:00,959:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\numpy\core\_methods.py:176: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-05-09 11:33:00,975:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\numpy\core\_methods.py:173: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)

2025-05-09 11:33:00,976:INFO:Creating metrics dataframe
2025-05-09 11:33:00,979:INFO:Uploading results into container
2025-05-09 11:33:00,980:INFO:Uploading model into container now
2025-05-09 11:33:00,981:INFO:_master_model_container: 5
2025-05-09 11:33:00,981:INFO:_display_container: 2
2025-05-09 11:33:00,981:INFO:Lars(random_state=123)
2025-05-09 11:33:00,981:INFO:create_model() successfully completed......................................
2025-05-09 11:33:01,050:WARNING:create_model() for Lars(random_state=123) raised an exception or returned all 0.0, trying without fit_kwargs:
2025-05-09 11:33:01,050:WARNING:Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2025-05-09 11:33:01,050:INFO:Initializing create_model()
2025-05-09 11:33:01,058:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E2EA93590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 11:33:01,059:INFO:Checking exceptions
2025-05-09 11:33:01,059:INFO:Importing libraries
2025-05-09 11:33:01,059:INFO:Copying training dataset
2025-05-09 11:33:01,059:INFO:Defining folds
2025-05-09 11:33:01,075:INFO:Declaring metric variables
2025-05-09 11:33:01,076:INFO:Importing untrained model
2025-05-09 11:33:01,076:INFO:Least Angle Regression Imported successfully
2025-05-09 11:33:01,092:INFO:Starting cross validation
2025-05-09 11:33:01,095:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 11:33:02,503:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=3.438e+02, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-09 11:33:02,506:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=1.059e+03, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-09 11:33:02,509:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=7.755e+02, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-05-09 11:33:02,605:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:812: RuntimeWarning: overflow encountered in multiply
  coef[active] = prev_coef[active] + gamma_ * least_squares

2025-05-09 11:33:02,607:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:771: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2025-05-09 11:33:02,609:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:775: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2025-05-09 11:33:02,610:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:776: RuntimeWarning: overflow encountered in scalar divide
  gamma_ = min(g1, g2, C / AA)

2025-05-09 11:33:02,612:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:780: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2025-05-09 11:33:02,770:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\extmath.py:208: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b

2025-05-09 11:33:02,776:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py:501: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2025-05-09 11:33:02,776:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py:501: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2025-05-09 11:33:02,776:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py:1196: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2025-05-09 11:33:02,783:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\containers\metrics\regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-09 11:33:02,783:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\containers\metrics\regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-09 11:33:02,783:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-09 11:33:02,791:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-09 11:33:02,792:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-09 11:33:02,792:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\metrics\_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-05-09 11:33:02,835:INFO:Calculating mean and std
2025-05-09 11:33:02,835:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\numpy\core\_methods.py:176: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2025-05-09 11:33:02,835:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\numpy\core\_methods.py:173: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)

2025-05-09 11:33:02,835:INFO:Creating metrics dataframe
2025-05-09 11:33:02,835:INFO:Uploading results into container
2025-05-09 11:33:02,841:INFO:Uploading model into container now
2025-05-09 11:33:02,842:INFO:_master_model_container: 6
2025-05-09 11:33:02,844:INFO:_display_container: 2
2025-05-09 11:33:02,845:INFO:Lars(random_state=123)
2025-05-09 11:33:02,845:INFO:create_model() successfully completed......................................
2025-05-09 11:33:02,923:ERROR:create_model() for Lars(random_state=123) raised an exception or returned all 0.0:
2025-05-09 11:33:02,924:ERROR:Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 818, in compare_models
    np.sum(
AssertionError

2025-05-09 11:33:02,925:INFO:Initializing Lasso Least Angle Regression
2025-05-09 11:33:02,926:INFO:Total runtime is 0.5567417383193969 minutes
2025-05-09 11:33:02,926:INFO:SubProcess create_model() called ==================================
2025-05-09 11:33:02,926:INFO:Initializing create_model()
2025-05-09 11:33:02,926:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E2EA93590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 11:33:02,926:INFO:Checking exceptions
2025-05-09 11:33:02,926:INFO:Importing libraries
2025-05-09 11:33:02,926:INFO:Copying training dataset
2025-05-09 11:33:02,951:INFO:Defining folds
2025-05-09 11:33:02,951:INFO:Declaring metric variables
2025-05-09 11:33:02,961:INFO:Importing untrained model
2025-05-09 11:33:02,967:INFO:Lasso Least Angle Regression Imported successfully
2025-05-09 11:33:02,979:INFO:Starting cross validation
2025-05-09 11:33:02,983:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 11:33:04,642:INFO:Calculating mean and std
2025-05-09 11:33:04,643:INFO:Creating metrics dataframe
2025-05-09 11:33:04,648:INFO:Uploading results into container
2025-05-09 11:33:04,650:INFO:Uploading model into container now
2025-05-09 11:33:04,651:INFO:_master_model_container: 7
2025-05-09 11:33:04,651:INFO:_display_container: 2
2025-05-09 11:33:04,653:INFO:LassoLars(random_state=123)
2025-05-09 11:33:04,653:INFO:create_model() successfully completed......................................
2025-05-09 11:33:04,741:INFO:SubProcess create_model() end ==================================
2025-05-09 11:33:04,742:INFO:Creating metrics dataframe
2025-05-09 11:33:04,742:INFO:Initializing Orthogonal Matching Pursuit
2025-05-09 11:33:04,742:INFO:Total runtime is 0.5870136857032775 minutes
2025-05-09 11:33:04,753:INFO:SubProcess create_model() called ==================================
2025-05-09 11:33:04,753:INFO:Initializing create_model()
2025-05-09 11:33:04,753:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E2EA93590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 11:33:04,753:INFO:Checking exceptions
2025-05-09 11:33:04,753:INFO:Importing libraries
2025-05-09 11:33:04,753:INFO:Copying training dataset
2025-05-09 11:33:04,778:INFO:Defining folds
2025-05-09 11:33:04,779:INFO:Declaring metric variables
2025-05-09 11:33:04,783:INFO:Importing untrained model
2025-05-09 11:33:04,792:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-09 11:33:04,805:INFO:Starting cross validation
2025-05-09 11:33:04,809:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 11:33:06,477:INFO:Calculating mean and std
2025-05-09 11:33:06,479:INFO:Creating metrics dataframe
2025-05-09 11:33:06,481:INFO:Uploading results into container
2025-05-09 11:33:06,482:INFO:Uploading model into container now
2025-05-09 11:33:06,484:INFO:_master_model_container: 8
2025-05-09 11:33:06,484:INFO:_display_container: 2
2025-05-09 11:33:06,485:INFO:OrthogonalMatchingPursuit()
2025-05-09 11:33:06,485:INFO:create_model() successfully completed......................................
2025-05-09 11:33:06,560:INFO:SubProcess create_model() end ==================================
2025-05-09 11:33:06,561:INFO:Creating metrics dataframe
2025-05-09 11:33:06,567:INFO:Initializing Bayesian Ridge
2025-05-09 11:33:06,567:INFO:Total runtime is 0.6174192229906718 minutes
2025-05-09 11:33:06,571:INFO:SubProcess create_model() called ==================================
2025-05-09 11:33:06,571:INFO:Initializing create_model()
2025-05-09 11:33:06,571:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E2EA93590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 11:33:06,573:INFO:Checking exceptions
2025-05-09 11:33:06,573:INFO:Importing libraries
2025-05-09 11:33:06,573:INFO:Copying training dataset
2025-05-09 11:33:06,589:INFO:Defining folds
2025-05-09 11:33:06,591:INFO:Declaring metric variables
2025-05-09 11:33:06,595:INFO:Importing untrained model
2025-05-09 11:33:06,602:INFO:Bayesian Ridge Imported successfully
2025-05-09 11:33:06,610:INFO:Starting cross validation
2025-05-09 11:33:06,615:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 11:33:09,640:INFO:Calculating mean and std
2025-05-09 11:33:09,643:INFO:Creating metrics dataframe
2025-05-09 11:33:09,647:INFO:Uploading results into container
2025-05-09 11:33:09,649:INFO:Uploading model into container now
2025-05-09 11:33:09,649:INFO:_master_model_container: 9
2025-05-09 11:33:09,649:INFO:_display_container: 2
2025-05-09 11:33:09,649:INFO:BayesianRidge()
2025-05-09 11:33:09,649:INFO:create_model() successfully completed......................................
2025-05-09 11:33:09,726:INFO:SubProcess create_model() end ==================================
2025-05-09 11:33:09,726:INFO:Creating metrics dataframe
2025-05-09 11:33:09,743:INFO:Initializing Passive Aggressive Regressor
2025-05-09 11:33:09,743:INFO:Total runtime is 0.6703508536020915 minutes
2025-05-09 11:33:09,749:INFO:SubProcess create_model() called ==================================
2025-05-09 11:33:09,749:INFO:Initializing create_model()
2025-05-09 11:33:09,749:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E2EA93590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 11:33:09,749:INFO:Checking exceptions
2025-05-09 11:33:09,749:INFO:Importing libraries
2025-05-09 11:33:09,749:INFO:Copying training dataset
2025-05-09 11:33:09,775:INFO:Defining folds
2025-05-09 11:33:09,775:INFO:Declaring metric variables
2025-05-09 11:33:09,780:INFO:Importing untrained model
2025-05-09 11:33:09,781:INFO:Passive Aggressive Regressor Imported successfully
2025-05-09 11:33:09,795:INFO:Starting cross validation
2025-05-09 11:33:09,800:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 11:33:12,431:INFO:Calculating mean and std
2025-05-09 11:33:12,433:INFO:Creating metrics dataframe
2025-05-09 11:33:12,436:INFO:Uploading results into container
2025-05-09 11:33:12,436:INFO:Uploading model into container now
2025-05-09 11:33:12,436:INFO:_master_model_container: 10
2025-05-09 11:33:12,438:INFO:_display_container: 2
2025-05-09 11:33:12,438:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-09 11:33:12,439:INFO:create_model() successfully completed......................................
2025-05-09 11:33:12,506:INFO:SubProcess create_model() end ==================================
2025-05-09 11:33:12,506:INFO:Creating metrics dataframe
2025-05-09 11:33:12,515:INFO:Initializing Huber Regressor
2025-05-09 11:33:12,516:INFO:Total runtime is 0.7165664275487263 minutes
2025-05-09 11:33:12,519:INFO:SubProcess create_model() called ==================================
2025-05-09 11:33:12,519:INFO:Initializing create_model()
2025-05-09 11:33:12,520:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E2EA93590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 11:33:12,520:INFO:Checking exceptions
2025-05-09 11:33:12,521:INFO:Importing libraries
2025-05-09 11:33:12,522:INFO:Copying training dataset
2025-05-09 11:33:12,541:INFO:Defining folds
2025-05-09 11:33:12,542:INFO:Declaring metric variables
2025-05-09 11:33:12,545:INFO:Importing untrained model
2025-05-09 11:33:12,551:INFO:Huber Regressor Imported successfully
2025-05-09 11:33:12,565:INFO:Starting cross validation
2025-05-09 11:33:12,569:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 11:33:16,731:INFO:Calculating mean and std
2025-05-09 11:33:16,731:INFO:Creating metrics dataframe
2025-05-09 11:33:16,735:INFO:Uploading results into container
2025-05-09 11:33:16,736:INFO:Uploading model into container now
2025-05-09 11:33:16,737:INFO:_master_model_container: 11
2025-05-09 11:33:16,737:INFO:_display_container: 2
2025-05-09 11:33:16,738:INFO:HuberRegressor()
2025-05-09 11:33:16,738:INFO:create_model() successfully completed......................................
2025-05-09 11:33:16,808:INFO:SubProcess create_model() end ==================================
2025-05-09 11:33:16,808:INFO:Creating metrics dataframe
2025-05-09 11:33:16,808:INFO:Initializing K Neighbors Regressor
2025-05-09 11:33:16,808:INFO:Total runtime is 0.7881093899408975 minutes
2025-05-09 11:33:16,808:INFO:SubProcess create_model() called ==================================
2025-05-09 11:33:16,808:INFO:Initializing create_model()
2025-05-09 11:33:16,808:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E2EA93590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 11:33:16,808:INFO:Checking exceptions
2025-05-09 11:33:16,808:INFO:Importing libraries
2025-05-09 11:33:16,824:INFO:Copying training dataset
2025-05-09 11:33:16,824:INFO:Defining folds
2025-05-09 11:33:16,824:INFO:Declaring metric variables
2025-05-09 11:33:16,844:INFO:Importing untrained model
2025-05-09 11:33:16,850:INFO:K Neighbors Regressor Imported successfully
2025-05-09 11:33:16,864:INFO:Starting cross validation
2025-05-09 11:33:16,870:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 11:33:22,943:INFO:Calculating mean and std
2025-05-09 11:33:22,945:INFO:Creating metrics dataframe
2025-05-09 11:33:22,948:INFO:Uploading results into container
2025-05-09 11:33:22,949:INFO:Uploading model into container now
2025-05-09 11:33:22,950:INFO:_master_model_container: 12
2025-05-09 11:33:22,950:INFO:_display_container: 2
2025-05-09 11:33:22,952:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-09 11:33:22,953:INFO:create_model() successfully completed......................................
2025-05-09 11:33:23,054:INFO:SubProcess create_model() end ==================================
2025-05-09 11:33:23,056:INFO:Creating metrics dataframe
2025-05-09 11:33:23,075:INFO:Initializing Decision Tree Regressor
2025-05-09 11:33:23,075:INFO:Total runtime is 0.8925606091817219 minutes
2025-05-09 11:33:23,086:INFO:SubProcess create_model() called ==================================
2025-05-09 11:33:23,087:INFO:Initializing create_model()
2025-05-09 11:33:23,088:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E2EA93590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 11:33:23,088:INFO:Checking exceptions
2025-05-09 11:33:23,089:INFO:Importing libraries
2025-05-09 11:33:23,090:INFO:Copying training dataset
2025-05-09 11:33:23,164:INFO:Defining folds
2025-05-09 11:33:23,166:INFO:Declaring metric variables
2025-05-09 11:33:23,180:INFO:Importing untrained model
2025-05-09 11:33:23,189:INFO:Decision Tree Regressor Imported successfully
2025-05-09 11:33:23,210:INFO:Starting cross validation
2025-05-09 11:33:23,236:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 11:33:26,640:INFO:Calculating mean and std
2025-05-09 11:33:26,643:INFO:Creating metrics dataframe
2025-05-09 11:33:26,648:INFO:Uploading results into container
2025-05-09 11:33:26,649:INFO:Uploading model into container now
2025-05-09 11:33:26,650:INFO:_master_model_container: 13
2025-05-09 11:33:26,651:INFO:_display_container: 2
2025-05-09 11:33:26,651:INFO:DecisionTreeRegressor(random_state=123)
2025-05-09 11:33:26,653:INFO:create_model() successfully completed......................................
2025-05-09 11:33:26,751:INFO:SubProcess create_model() end ==================================
2025-05-09 11:33:26,751:INFO:Creating metrics dataframe
2025-05-09 11:33:26,766:INFO:Initializing Random Forest Regressor
2025-05-09 11:33:26,767:INFO:Total runtime is 0.9540909647941588 minutes
2025-05-09 11:33:26,773:INFO:SubProcess create_model() called ==================================
2025-05-09 11:33:26,774:INFO:Initializing create_model()
2025-05-09 11:33:26,775:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E2EA93590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 11:33:26,775:INFO:Checking exceptions
2025-05-09 11:33:26,776:INFO:Importing libraries
2025-05-09 11:33:26,777:INFO:Copying training dataset
2025-05-09 11:33:26,812:INFO:Defining folds
2025-05-09 11:33:26,812:INFO:Declaring metric variables
2025-05-09 11:33:26,818:INFO:Importing untrained model
2025-05-09 11:33:26,826:INFO:Random Forest Regressor Imported successfully
2025-05-09 11:33:26,840:INFO:Starting cross validation
2025-05-09 11:33:26,846:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 11:34:48,868:INFO:Calculating mean and std
2025-05-09 11:34:48,916:INFO:Creating metrics dataframe
2025-05-09 11:34:48,985:INFO:Uploading results into container
2025-05-09 11:34:48,989:INFO:Uploading model into container now
2025-05-09 11:34:48,995:INFO:_master_model_container: 14
2025-05-09 11:34:48,997:INFO:_display_container: 2
2025-05-09 11:34:49,002:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-09 11:34:49,002:INFO:create_model() successfully completed......................................
2025-05-09 11:34:49,494:INFO:SubProcess create_model() end ==================================
2025-05-09 11:34:49,495:INFO:Creating metrics dataframe
2025-05-09 11:34:49,528:INFO:Initializing Extra Trees Regressor
2025-05-09 11:34:49,529:INFO:Total runtime is 2.333449916044871 minutes
2025-05-09 11:34:49,547:INFO:SubProcess create_model() called ==================================
2025-05-09 11:34:49,551:INFO:Initializing create_model()
2025-05-09 11:34:49,554:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E2EA93590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 11:34:49,555:INFO:Checking exceptions
2025-05-09 11:34:49,555:INFO:Importing libraries
2025-05-09 11:34:49,556:INFO:Copying training dataset
2025-05-09 11:34:49,639:INFO:Defining folds
2025-05-09 11:34:49,640:INFO:Declaring metric variables
2025-05-09 11:34:49,649:INFO:Importing untrained model
2025-05-09 11:34:49,659:INFO:Extra Trees Regressor Imported successfully
2025-05-09 11:34:49,677:INFO:Starting cross validation
2025-05-09 11:34:49,683:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 11:37:01,410:INFO:Calculating mean and std
2025-05-09 11:37:01,602:INFO:Creating metrics dataframe
2025-05-09 11:37:01,719:INFO:Uploading results into container
2025-05-09 11:37:01,727:INFO:Uploading model into container now
2025-05-09 11:37:01,743:INFO:_master_model_container: 15
2025-05-09 11:37:01,743:INFO:_display_container: 2
2025-05-09 11:37:01,753:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-09 11:37:01,753:INFO:create_model() successfully completed......................................
2025-05-09 11:37:02,573:INFO:SubProcess create_model() end ==================================
2025-05-09 11:37:02,574:INFO:Creating metrics dataframe
2025-05-09 11:37:02,599:INFO:Initializing AdaBoost Regressor
2025-05-09 11:37:02,600:INFO:Total runtime is 4.551302671432495 minutes
2025-05-09 11:37:02,612:INFO:SubProcess create_model() called ==================================
2025-05-09 11:37:02,613:INFO:Initializing create_model()
2025-05-09 11:37:02,614:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E2EA93590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 11:37:02,614:INFO:Checking exceptions
2025-05-09 11:37:02,615:INFO:Importing libraries
2025-05-09 11:37:02,617:INFO:Copying training dataset
2025-05-09 11:37:02,679:INFO:Defining folds
2025-05-09 11:37:02,680:INFO:Declaring metric variables
2025-05-09 11:37:02,686:INFO:Importing untrained model
2025-05-09 11:37:02,691:INFO:AdaBoost Regressor Imported successfully
2025-05-09 11:37:02,701:INFO:Starting cross validation
2025-05-09 11:37:02,706:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 11:37:24,299:INFO:Calculating mean and std
2025-05-09 11:37:24,302:INFO:Creating metrics dataframe
2025-05-09 11:37:24,306:INFO:Uploading results into container
2025-05-09 11:37:24,307:INFO:Uploading model into container now
2025-05-09 11:37:24,308:INFO:_master_model_container: 16
2025-05-09 11:37:24,309:INFO:_display_container: 2
2025-05-09 11:37:24,310:INFO:AdaBoostRegressor(random_state=123)
2025-05-09 11:37:24,310:INFO:create_model() successfully completed......................................
2025-05-09 11:37:24,406:INFO:SubProcess create_model() end ==================================
2025-05-09 11:37:24,408:INFO:Creating metrics dataframe
2025-05-09 11:37:24,429:INFO:Initializing Gradient Boosting Regressor
2025-05-09 11:37:24,430:INFO:Total runtime is 4.915144650141398 minutes
2025-05-09 11:37:24,441:INFO:SubProcess create_model() called ==================================
2025-05-09 11:37:24,442:INFO:Initializing create_model()
2025-05-09 11:37:24,443:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E2EA93590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 11:37:24,445:INFO:Checking exceptions
2025-05-09 11:37:24,445:INFO:Importing libraries
2025-05-09 11:37:24,446:INFO:Copying training dataset
2025-05-09 11:37:24,492:INFO:Defining folds
2025-05-09 11:37:24,493:INFO:Declaring metric variables
2025-05-09 11:37:24,500:INFO:Importing untrained model
2025-05-09 11:37:24,505:INFO:Gradient Boosting Regressor Imported successfully
2025-05-09 11:37:24,518:INFO:Starting cross validation
2025-05-09 11:37:24,523:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 11:37:42,852:INFO:Calculating mean and std
2025-05-09 11:37:42,855:INFO:Creating metrics dataframe
2025-05-09 11:37:42,859:INFO:Uploading results into container
2025-05-09 11:37:42,860:INFO:Uploading model into container now
2025-05-09 11:37:42,861:INFO:_master_model_container: 17
2025-05-09 11:37:42,863:INFO:_display_container: 2
2025-05-09 11:37:42,864:INFO:GradientBoostingRegressor(random_state=123)
2025-05-09 11:37:42,865:INFO:create_model() successfully completed......................................
2025-05-09 11:37:42,963:INFO:SubProcess create_model() end ==================================
2025-05-09 11:37:42,964:INFO:Creating metrics dataframe
2025-05-09 11:37:42,981:INFO:Initializing Light Gradient Boosting Machine
2025-05-09 11:37:42,981:INFO:Total runtime is 5.224332320690155 minutes
2025-05-09 11:37:42,987:INFO:SubProcess create_model() called ==================================
2025-05-09 11:37:42,988:INFO:Initializing create_model()
2025-05-09 11:37:42,989:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E2EA93590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 11:37:42,989:INFO:Checking exceptions
2025-05-09 11:37:42,989:INFO:Importing libraries
2025-05-09 11:37:42,990:INFO:Copying training dataset
2025-05-09 11:37:43,027:INFO:Defining folds
2025-05-09 11:37:43,027:INFO:Declaring metric variables
2025-05-09 11:37:43,036:INFO:Importing untrained model
2025-05-09 11:37:43,043:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-09 11:37:43,061:INFO:Starting cross validation
2025-05-09 11:37:43,068:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 11:37:49,129:INFO:Calculating mean and std
2025-05-09 11:37:49,132:INFO:Creating metrics dataframe
2025-05-09 11:37:49,138:INFO:Uploading results into container
2025-05-09 11:37:49,138:INFO:Uploading model into container now
2025-05-09 11:37:49,138:INFO:_master_model_container: 18
2025-05-09 11:37:49,141:INFO:_display_container: 2
2025-05-09 11:37:49,141:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-09 11:37:49,141:INFO:create_model() successfully completed......................................
2025-05-09 11:37:49,253:INFO:SubProcess create_model() end ==================================
2025-05-09 11:37:49,253:INFO:Creating metrics dataframe
2025-05-09 11:37:49,253:INFO:Initializing Dummy Regressor
2025-05-09 11:37:49,253:INFO:Total runtime is 5.328849522272746 minutes
2025-05-09 11:37:49,272:INFO:SubProcess create_model() called ==================================
2025-05-09 11:37:49,272:INFO:Initializing create_model()
2025-05-09 11:37:49,272:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025E2EA93590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 11:37:49,272:INFO:Checking exceptions
2025-05-09 11:37:49,272:INFO:Importing libraries
2025-05-09 11:37:49,272:INFO:Copying training dataset
2025-05-09 11:37:49,311:INFO:Defining folds
2025-05-09 11:37:49,312:INFO:Declaring metric variables
2025-05-09 11:37:49,321:INFO:Importing untrained model
2025-05-09 11:37:49,330:INFO:Dummy Regressor Imported successfully
2025-05-09 11:37:49,344:INFO:Starting cross validation
2025-05-09 11:37:49,348:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-09 11:37:51,384:INFO:Calculating mean and std
2025-05-09 11:37:51,390:INFO:Creating metrics dataframe
2025-05-09 11:37:51,394:INFO:Uploading results into container
2025-05-09 11:37:51,395:INFO:Uploading model into container now
2025-05-09 11:37:51,396:INFO:_master_model_container: 19
2025-05-09 11:37:51,397:INFO:_display_container: 2
2025-05-09 11:37:51,397:INFO:DummyRegressor()
2025-05-09 11:37:51,398:INFO:create_model() successfully completed......................................
2025-05-09 11:37:51,498:INFO:SubProcess create_model() end ==================================
2025-05-09 11:37:51,499:INFO:Creating metrics dataframe
2025-05-09 11:37:51,518:WARNING:c:\ProjectsBecode\ImmoElizaProject\deployment_venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-09 11:37:51,530:INFO:Initializing create_model()
2025-05-09 11:37:51,531:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-09 11:37:51,531:INFO:Checking exceptions
2025-05-09 11:37:51,536:INFO:Importing libraries
2025-05-09 11:37:51,537:INFO:Copying training dataset
2025-05-09 11:37:51,565:INFO:Defining folds
2025-05-09 11:37:51,565:INFO:Declaring metric variables
2025-05-09 11:37:51,566:INFO:Importing untrained model
2025-05-09 11:37:51,567:INFO:Declaring custom model
2025-05-09 11:37:51,569:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-09 11:37:51,572:INFO:Cross validation set to False
2025-05-09 11:37:51,572:INFO:Fitting Model
2025-05-09 11:37:52,352:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003012 seconds.
2025-05-09 11:37:52,352:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-09 11:37:52,352:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-09 11:37:52,353:INFO:[LightGBM] [Info] Total Bins 1128
2025-05-09 11:37:52,353:INFO:[LightGBM] [Info] Number of data points in the train set: 43469, number of used features: 71
2025-05-09 11:37:52,354:INFO:[LightGBM] [Info] Start training from score 437115.043893
2025-05-09 11:37:52,522:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-09 11:37:52,523:INFO:create_model() successfully completed......................................
2025-05-09 11:37:52,643:INFO:_master_model_container: 19
2025-05-09 11:37:52,644:INFO:_display_container: 2
2025-05-09 11:37:52,645:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-09 11:37:52,645:INFO:compare_models() successfully completed......................................
2025-05-09 11:39:24,706:INFO:Initializing evaluate_model()
2025-05-09 11:39:24,707:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-09 11:39:24,726:INFO:Initializing plot_model()
2025-05-09 11:39:24,727:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-09 11:39:24,727:INFO:Checking exceptions
2025-05-09 11:39:24,734:INFO:Preloading libraries
2025-05-09 11:39:24,742:INFO:Copying training dataset
2025-05-09 11:39:24,742:INFO:Plot type: pipeline
2025-05-09 11:39:25,238:INFO:Visual Rendered Successfully
2025-05-09 11:39:25,325:INFO:plot_model() successfully completed......................................
2025-05-09 11:39:33,508:INFO:Initializing plot_model()
2025-05-09 11:39:33,510:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000025E2C9C3410>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), plot=error, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-09 11:39:33,511:INFO:Checking exceptions
2025-05-09 11:39:33,522:INFO:Preloading libraries
2025-05-09 11:39:33,538:INFO:Copying training dataset
2025-05-09 11:39:33,539:INFO:Plot type: error
2025-05-09 11:39:33,871:INFO:Fitting Model
2025-05-09 11:39:33,871:INFO:Scoring test/hold-out set
2025-05-09 11:39:34,291:INFO:Visual Rendered Successfully
2025-05-09 11:39:34,377:INFO:plot_model() successfully completed......................................
2025-05-15 10:19:54,651:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 10:19:54,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 10:19:54,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 10:19:54,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 10:19:54,797:INFO:PyCaret RegressionExperiment
2025-05-15 10:19:54,896:INFO:Logging name: reg-default-name
2025-05-15 10:19:54,896:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-15 10:19:54,897:INFO:version 3.3.2
2025-05-15 10:19:54,897:INFO:Initializing setup()
2025-05-15 10:19:54,897:INFO:self.USI: 9884
2025-05-15 10:19:54,897:INFO:self._variable_keys: {'pipeline', 'fold_generator', 'exp_name_log', 'y_test', 'X_test', 'n_jobs_param', 'transform_target_param', 'y', 'memory', 'USI', 'html_param', 'seed', 'X_train', 'y_train', 'gpu_n_jobs_param', 'fold_groups_param', 'exp_id', 'idx', '_ml_usecase', 'gpu_param', 'fold_shuffle_param', '_available_plots', 'logging_param', 'log_plots_param', 'X', 'target_param', 'data'}
2025-05-15 10:19:54,897:INFO:Checking environment
2025-05-15 10:19:54,897:INFO:python_version: 3.11.7
2025-05-15 10:19:54,898:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2025-05-15 10:19:54,899:INFO:machine: AMD64
2025-05-15 10:19:54,899:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-15 10:19:54,902:INFO:Memory: svmem(total=34281660416, available=22774591488, percent=33.6, used=11507068928, free=22774591488)
2025-05-15 10:19:54,902:INFO:Physical Core: 8
2025-05-15 10:19:54,902:INFO:Logical Core: 16
2025-05-15 10:19:54,903:INFO:Checking libraries
2025-05-15 10:19:54,903:INFO:System:
2025-05-15 10:19:54,903:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2025-05-15 10:19:54,903:INFO:executable: c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Scripts\python.exe
2025-05-15 10:19:54,903:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-15 10:19:54,904:INFO:PyCaret required dependencies:
2025-05-15 10:19:54,958:INFO:                 pip: 25.1.1
2025-05-15 10:19:54,958:INFO:          setuptools: 65.5.0
2025-05-15 10:19:54,958:INFO:             pycaret: 3.3.2
2025-05-15 10:19:54,958:INFO:             IPython: 9.2.0
2025-05-15 10:19:54,959:INFO:          ipywidgets: 8.1.7
2025-05-15 10:19:54,959:INFO:                tqdm: 4.67.1
2025-05-15 10:19:54,959:INFO:               numpy: 1.26.4
2025-05-15 10:19:54,959:INFO:              pandas: 2.1.4
2025-05-15 10:19:54,959:INFO:              jinja2: 3.1.6
2025-05-15 10:19:54,959:INFO:               scipy: 1.11.4
2025-05-15 10:19:54,960:INFO:              joblib: 1.3.2
2025-05-15 10:19:54,960:INFO:             sklearn: 1.4.2
2025-05-15 10:19:54,960:INFO:                pyod: 2.0.5
2025-05-15 10:19:54,960:INFO:            imblearn: 0.13.0
2025-05-15 10:19:54,960:INFO:   category_encoders: 2.7.0
2025-05-15 10:19:54,960:INFO:            lightgbm: 4.6.0
2025-05-15 10:19:54,960:INFO:               numba: 0.61.2
2025-05-15 10:19:54,961:INFO:            requests: 2.32.3
2025-05-15 10:19:54,961:INFO:          matplotlib: 3.7.5
2025-05-15 10:19:54,961:INFO:          scikitplot: 0.3.7
2025-05-15 10:19:54,961:INFO:         yellowbrick: 1.5
2025-05-15 10:19:54,961:INFO:              plotly: 5.24.1
2025-05-15 10:19:54,961:INFO:    plotly-resampler: Not installed
2025-05-15 10:19:54,962:INFO:             kaleido: 0.2.1
2025-05-15 10:19:54,962:INFO:           schemdraw: 0.15
2025-05-15 10:19:54,962:INFO:         statsmodels: 0.14.4
2025-05-15 10:19:54,962:INFO:              sktime: 0.26.0
2025-05-15 10:19:54,962:INFO:               tbats: 1.1.3
2025-05-15 10:19:54,962:INFO:            pmdarima: 2.0.4
2025-05-15 10:19:54,963:INFO:              psutil: 7.0.0
2025-05-15 10:19:54,963:INFO:          markupsafe: 3.0.2
2025-05-15 10:19:54,963:INFO:             pickle5: Not installed
2025-05-15 10:19:54,963:INFO:         cloudpickle: 3.1.1
2025-05-15 10:19:54,963:INFO:         deprecation: 2.1.0
2025-05-15 10:19:54,963:INFO:              xxhash: 3.5.0
2025-05-15 10:19:54,963:INFO:           wurlitzer: Not installed
2025-05-15 10:19:54,964:INFO:PyCaret optional dependencies:
2025-05-15 10:19:54,981:INFO:                shap: Not installed
2025-05-15 10:19:54,981:INFO:           interpret: Not installed
2025-05-15 10:19:54,982:INFO:                umap: Not installed
2025-05-15 10:19:54,982:INFO:     ydata_profiling: Not installed
2025-05-15 10:19:54,982:INFO:  explainerdashboard: Not installed
2025-05-15 10:19:54,982:INFO:             autoviz: Not installed
2025-05-15 10:19:54,982:INFO:           fairlearn: Not installed
2025-05-15 10:19:54,982:INFO:          deepchecks: Not installed
2025-05-15 10:19:54,982:INFO:             xgboost: Not installed
2025-05-15 10:19:54,983:INFO:            catboost: Not installed
2025-05-15 10:19:54,983:INFO:              kmodes: Not installed
2025-05-15 10:19:54,983:INFO:             mlxtend: Not installed
2025-05-15 10:19:54,983:INFO:       statsforecast: Not installed
2025-05-15 10:19:54,983:INFO:        tune_sklearn: Not installed
2025-05-15 10:19:54,983:INFO:                 ray: Not installed
2025-05-15 10:19:54,983:INFO:            hyperopt: Not installed
2025-05-15 10:19:54,984:INFO:              optuna: Not installed
2025-05-15 10:19:54,984:INFO:               skopt: Not installed
2025-05-15 10:19:54,984:INFO:              mlflow: Not installed
2025-05-15 10:19:54,984:INFO:              gradio: Not installed
2025-05-15 10:19:54,984:INFO:             fastapi: Not installed
2025-05-15 10:19:54,984:INFO:             uvicorn: Not installed
2025-05-15 10:19:54,984:INFO:              m2cgen: Not installed
2025-05-15 10:19:54,984:INFO:           evidently: Not installed
2025-05-15 10:19:54,985:INFO:               fugue: Not installed
2025-05-15 10:19:54,985:INFO:           streamlit: 1.45.0
2025-05-15 10:19:54,985:INFO:             prophet: Not installed
2025-05-15 10:19:54,985:INFO:None
2025-05-15 10:19:54,985:INFO:Set up data.
2025-05-15 10:19:55,028:INFO:Set up folding strategy.
2025-05-15 10:19:55,028:INFO:Set up train/test split.
2025-05-15 10:19:55,066:INFO:Set up index.
2025-05-15 10:19:55,068:INFO:Assigning column types.
2025-05-15 10:19:55,079:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 10:19:55,080:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,083:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,086:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,138:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,170:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:55,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:55,172:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,176:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,179:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,230:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,263:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,263:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:55,264:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:55,264:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-15 10:19:55,267:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,270:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,318:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,352:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,352:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:55,353:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:55,357:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,361:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,413:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,442:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,442:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:55,443:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:55,443:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-15 10:19:55,449:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,501:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,535:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,535:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:55,535:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:55,543:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,594:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,627:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,627:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:55,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:55,628:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-15 10:19:55,681:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,714:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,714:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:55,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:55,773:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,802:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:55,803:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:55,804:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 10:19:55,860:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,892:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:55,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:55,949:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 10:19:55,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:55,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:55,984:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-15 10:19:56,070:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:56,070:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:56,157:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:56,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:56,160:INFO:Preparing preprocessing pipeline...
2025-05-15 10:19:56,160:INFO:Set up iterative imputation.
2025-05-15 10:19:56,247:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:56,248:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:56,284:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 10:19:56,312:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:56,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:56,382:INFO:Set up encoding of ordinal features.
2025-05-15 10:19:56,386:INFO:Set up encoding of categorical features.
2025-05-15 10:19:56,978:INFO:Finished creating preprocessing pipeline.
2025-05-15 10:19:57,001:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LINW~1\AppData\Local\Temp\joblib),
         steps=[('iterative_imputer',
                 TransformerWrapper(transformer=IterativeImputer(cat_estimator=LGBMClassifier(n_jobs=-1,
                                                                                              random_state=123),
                                                                 cat_estimator_prepare_for_categoricals_type='fit_params_categorical_feature',
                                                                 categorical_indices=[0,
                                                                                      1,
                                                                                      4,
                                                                                      7,
                                                                                      10,
                                                                                      11,
                                                                                      12,
                                                                                      18],
                                                                 max_iter=5,
                                                                 num_esti...
                                             'floodZoneType', 'heatingType',
                                             'kitchenType', 'epcScore'],
                                    transformer=OneHotEncoder(cols=['subtype',
                                                                    'buildingCondition',
                                                                    'floodZoneType',
                                                                    'heatingType',
                                                                    'kitchenType',
                                                                    'epcScore'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['locality'],
                                    transformer=TargetEncoder(cols=['locality'],
                                                              handle_missing='return_nan')))])
2025-05-15 10:19:57,002:INFO:Creating final display dataframe.
2025-05-15 10:19:58,082:INFO:Setup _display_container:                         Description             Value
0                        Session id               123
1                            Target             price
2                       Target type        Regression
3               Original data shape       (62099, 20)
4            Transformed data shape       (62099, 77)
5       Transformed train set shape       (43469, 77)
6        Transformed test set shape       (18630, 77)
7                  Numeric features                 7
8              Categorical features                 8
9                        Preprocess              True
10                  Imputation type         iterative
11  Iterative imputation iterations                 5
12        Numeric iterative imputer          lightgbm
13    Categorical iterative imputer          lightgbm
14         Maximum one-hot encoding                25
15                  Encoding method              None
16                   Fold Generator             KFold
17                      Fold Number                10
18                         CPU Jobs                -1
19                          Use GPU             False
20                   Log Experiment             False
21                  Experiment Name  reg-default-name
22                              USI              9884
2025-05-15 10:19:58,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:58,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:58,258:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:58,259:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:19:58,259:INFO:setup() successfully completed in 3.47s...............
2025-05-15 10:40:31,877:INFO:PyCaret RegressionExperiment
2025-05-15 10:40:31,972:INFO:Logging name: reg-default-name
2025-05-15 10:40:31,973:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-15 10:40:31,973:INFO:version 3.3.2
2025-05-15 10:40:31,973:INFO:Initializing setup()
2025-05-15 10:40:31,973:INFO:self.USI: eae0
2025-05-15 10:40:31,973:INFO:self._variable_keys: {'pipeline', 'fold_generator', 'exp_name_log', 'y_test', 'X_test', 'n_jobs_param', 'transform_target_param', 'y', 'memory', 'USI', 'html_param', 'seed', 'X_train', 'y_train', 'gpu_n_jobs_param', 'fold_groups_param', 'exp_id', 'idx', '_ml_usecase', 'gpu_param', 'fold_shuffle_param', '_available_plots', 'logging_param', 'log_plots_param', 'X', 'target_param', 'data'}
2025-05-15 10:40:31,974:INFO:Checking environment
2025-05-15 10:40:31,974:INFO:python_version: 3.11.7
2025-05-15 10:40:31,974:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2025-05-15 10:40:31,974:INFO:machine: AMD64
2025-05-15 10:40:31,974:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-15 10:40:31,979:INFO:Memory: svmem(total=34281660416, available=21709008896, percent=36.7, used=12572651520, free=21709008896)
2025-05-15 10:40:31,979:INFO:Physical Core: 8
2025-05-15 10:40:31,979:INFO:Logical Core: 16
2025-05-15 10:40:31,979:INFO:Checking libraries
2025-05-15 10:40:31,979:INFO:System:
2025-05-15 10:40:31,980:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2025-05-15 10:40:31,980:INFO:executable: c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Scripts\python.exe
2025-05-15 10:40:31,980:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-15 10:40:31,980:INFO:PyCaret required dependencies:
2025-05-15 10:40:31,980:INFO:                 pip: 25.1.1
2025-05-15 10:40:31,980:INFO:          setuptools: 65.5.0
2025-05-15 10:40:31,981:INFO:             pycaret: 3.3.2
2025-05-15 10:40:31,981:INFO:             IPython: 9.2.0
2025-05-15 10:40:31,981:INFO:          ipywidgets: 8.1.7
2025-05-15 10:40:31,981:INFO:                tqdm: 4.67.1
2025-05-15 10:40:31,981:INFO:               numpy: 1.26.4
2025-05-15 10:40:31,981:INFO:              pandas: 2.1.4
2025-05-15 10:40:31,982:INFO:              jinja2: 3.1.6
2025-05-15 10:40:31,982:INFO:               scipy: 1.11.4
2025-05-15 10:40:31,982:INFO:              joblib: 1.3.2
2025-05-15 10:40:31,982:INFO:             sklearn: 1.4.2
2025-05-15 10:40:31,982:INFO:                pyod: 2.0.5
2025-05-15 10:40:31,982:INFO:            imblearn: 0.13.0
2025-05-15 10:40:31,982:INFO:   category_encoders: 2.7.0
2025-05-15 10:40:31,982:INFO:            lightgbm: 4.6.0
2025-05-15 10:40:31,983:INFO:               numba: 0.61.2
2025-05-15 10:40:31,983:INFO:            requests: 2.32.3
2025-05-15 10:40:31,983:INFO:          matplotlib: 3.7.5
2025-05-15 10:40:31,983:INFO:          scikitplot: 0.3.7
2025-05-15 10:40:31,983:INFO:         yellowbrick: 1.5
2025-05-15 10:40:31,983:INFO:              plotly: 5.24.1
2025-05-15 10:40:31,983:INFO:    plotly-resampler: Not installed
2025-05-15 10:40:31,983:INFO:             kaleido: 0.2.1
2025-05-15 10:40:31,984:INFO:           schemdraw: 0.15
2025-05-15 10:40:31,984:INFO:         statsmodels: 0.14.4
2025-05-15 10:40:31,984:INFO:              sktime: 0.26.0
2025-05-15 10:40:31,984:INFO:               tbats: 1.1.3
2025-05-15 10:40:31,984:INFO:            pmdarima: 2.0.4
2025-05-15 10:40:31,984:INFO:              psutil: 7.0.0
2025-05-15 10:40:31,984:INFO:          markupsafe: 3.0.2
2025-05-15 10:40:31,985:INFO:             pickle5: Not installed
2025-05-15 10:40:31,985:INFO:         cloudpickle: 3.1.1
2025-05-15 10:40:31,985:INFO:         deprecation: 2.1.0
2025-05-15 10:40:31,985:INFO:              xxhash: 3.5.0
2025-05-15 10:40:31,985:INFO:           wurlitzer: Not installed
2025-05-15 10:40:31,985:INFO:PyCaret optional dependencies:
2025-05-15 10:40:31,985:INFO:                shap: Not installed
2025-05-15 10:40:31,986:INFO:           interpret: Not installed
2025-05-15 10:40:31,986:INFO:                umap: Not installed
2025-05-15 10:40:31,986:INFO:     ydata_profiling: Not installed
2025-05-15 10:40:31,986:INFO:  explainerdashboard: Not installed
2025-05-15 10:40:31,986:INFO:             autoviz: Not installed
2025-05-15 10:40:31,986:INFO:           fairlearn: Not installed
2025-05-15 10:40:31,986:INFO:          deepchecks: Not installed
2025-05-15 10:40:31,987:INFO:             xgboost: Not installed
2025-05-15 10:40:31,987:INFO:            catboost: Not installed
2025-05-15 10:40:31,987:INFO:              kmodes: Not installed
2025-05-15 10:40:31,987:INFO:             mlxtend: Not installed
2025-05-15 10:40:31,988:INFO:       statsforecast: Not installed
2025-05-15 10:40:31,988:INFO:        tune_sklearn: Not installed
2025-05-15 10:40:31,988:INFO:                 ray: Not installed
2025-05-15 10:40:31,988:INFO:            hyperopt: Not installed
2025-05-15 10:40:31,988:INFO:              optuna: Not installed
2025-05-15 10:40:31,988:INFO:               skopt: Not installed
2025-05-15 10:40:31,989:INFO:              mlflow: Not installed
2025-05-15 10:40:31,989:INFO:              gradio: Not installed
2025-05-15 10:40:31,989:INFO:             fastapi: Not installed
2025-05-15 10:40:31,989:INFO:             uvicorn: Not installed
2025-05-15 10:40:31,989:INFO:              m2cgen: Not installed
2025-05-15 10:40:31,990:INFO:           evidently: Not installed
2025-05-15 10:40:31,990:INFO:               fugue: Not installed
2025-05-15 10:40:31,990:INFO:           streamlit: 1.45.0
2025-05-15 10:40:31,990:INFO:             prophet: Not installed
2025-05-15 10:40:31,990:INFO:None
2025-05-15 10:40:31,990:INFO:Set up data.
2025-05-15 10:48:50,822:INFO:PyCaret RegressionExperiment
2025-05-15 10:48:50,920:INFO:Logging name: reg-default-name
2025-05-15 10:48:50,921:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-15 10:48:50,921:INFO:version 3.3.2
2025-05-15 10:48:50,921:INFO:Initializing setup()
2025-05-15 10:48:50,921:INFO:self.USI: c188
2025-05-15 10:48:50,921:INFO:self._variable_keys: {'pipeline', 'fold_generator', 'exp_name_log', 'y_test', 'X_test', 'n_jobs_param', 'transform_target_param', 'y', 'memory', 'USI', 'html_param', 'seed', 'X_train', 'y_train', 'gpu_n_jobs_param', 'fold_groups_param', 'exp_id', 'idx', '_ml_usecase', 'gpu_param', 'fold_shuffle_param', '_available_plots', 'logging_param', 'log_plots_param', 'X', 'target_param', 'data'}
2025-05-15 10:48:50,922:INFO:Checking environment
2025-05-15 10:48:50,922:INFO:python_version: 3.11.7
2025-05-15 10:48:50,922:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2025-05-15 10:48:50,922:INFO:machine: AMD64
2025-05-15 10:48:50,922:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-15 10:48:50,926:INFO:Memory: svmem(total=34281660416, available=21575467008, percent=37.1, used=12706193408, free=21575467008)
2025-05-15 10:48:50,926:INFO:Physical Core: 8
2025-05-15 10:48:50,926:INFO:Logical Core: 16
2025-05-15 10:48:50,926:INFO:Checking libraries
2025-05-15 10:48:50,926:INFO:System:
2025-05-15 10:48:50,926:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2025-05-15 10:48:50,926:INFO:executable: c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Scripts\python.exe
2025-05-15 10:48:50,928:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-15 10:48:50,928:INFO:PyCaret required dependencies:
2025-05-15 10:48:50,928:INFO:                 pip: 25.1.1
2025-05-15 10:48:50,928:INFO:          setuptools: 65.5.0
2025-05-15 10:48:50,928:INFO:             pycaret: 3.3.2
2025-05-15 10:48:50,928:INFO:             IPython: 9.2.0
2025-05-15 10:48:50,928:INFO:          ipywidgets: 8.1.7
2025-05-15 10:48:50,929:INFO:                tqdm: 4.67.1
2025-05-15 10:48:50,929:INFO:               numpy: 1.26.4
2025-05-15 10:48:50,929:INFO:              pandas: 2.1.4
2025-05-15 10:48:50,929:INFO:              jinja2: 3.1.6
2025-05-15 10:48:50,929:INFO:               scipy: 1.11.4
2025-05-15 10:48:50,929:INFO:              joblib: 1.3.2
2025-05-15 10:48:50,930:INFO:             sklearn: 1.4.2
2025-05-15 10:48:50,930:INFO:                pyod: 2.0.5
2025-05-15 10:48:50,930:INFO:            imblearn: 0.13.0
2025-05-15 10:48:50,930:INFO:   category_encoders: 2.7.0
2025-05-15 10:48:50,930:INFO:            lightgbm: 4.6.0
2025-05-15 10:48:50,930:INFO:               numba: 0.61.2
2025-05-15 10:48:50,930:INFO:            requests: 2.32.3
2025-05-15 10:48:50,931:INFO:          matplotlib: 3.7.5
2025-05-15 10:48:50,931:INFO:          scikitplot: 0.3.7
2025-05-15 10:48:50,931:INFO:         yellowbrick: 1.5
2025-05-15 10:48:50,931:INFO:              plotly: 5.24.1
2025-05-15 10:48:50,931:INFO:    plotly-resampler: Not installed
2025-05-15 10:48:50,932:INFO:             kaleido: 0.2.1
2025-05-15 10:48:50,932:INFO:           schemdraw: 0.15
2025-05-15 10:48:50,932:INFO:         statsmodels: 0.14.4
2025-05-15 10:48:50,932:INFO:              sktime: 0.26.0
2025-05-15 10:48:50,932:INFO:               tbats: 1.1.3
2025-05-15 10:48:50,932:INFO:            pmdarima: 2.0.4
2025-05-15 10:48:50,933:INFO:              psutil: 7.0.0
2025-05-15 10:48:50,933:INFO:          markupsafe: 3.0.2
2025-05-15 10:48:50,933:INFO:             pickle5: Not installed
2025-05-15 10:48:50,933:INFO:         cloudpickle: 3.1.1
2025-05-15 10:48:50,933:INFO:         deprecation: 2.1.0
2025-05-15 10:48:50,933:INFO:              xxhash: 3.5.0
2025-05-15 10:48:50,934:INFO:           wurlitzer: Not installed
2025-05-15 10:48:50,934:INFO:PyCaret optional dependencies:
2025-05-15 10:48:50,934:INFO:                shap: Not installed
2025-05-15 10:48:50,934:INFO:           interpret: Not installed
2025-05-15 10:48:50,934:INFO:                umap: Not installed
2025-05-15 10:48:50,934:INFO:     ydata_profiling: Not installed
2025-05-15 10:48:50,935:INFO:  explainerdashboard: Not installed
2025-05-15 10:48:50,935:INFO:             autoviz: Not installed
2025-05-15 10:48:50,935:INFO:           fairlearn: Not installed
2025-05-15 10:48:50,935:INFO:          deepchecks: Not installed
2025-05-15 10:48:50,935:INFO:             xgboost: Not installed
2025-05-15 10:48:50,935:INFO:            catboost: Not installed
2025-05-15 10:48:50,935:INFO:              kmodes: Not installed
2025-05-15 10:48:50,935:INFO:             mlxtend: Not installed
2025-05-15 10:48:50,935:INFO:       statsforecast: Not installed
2025-05-15 10:48:50,935:INFO:        tune_sklearn: Not installed
2025-05-15 10:48:50,936:INFO:                 ray: Not installed
2025-05-15 10:48:50,936:INFO:            hyperopt: Not installed
2025-05-15 10:48:50,936:INFO:              optuna: Not installed
2025-05-15 10:48:50,936:INFO:               skopt: Not installed
2025-05-15 10:48:50,936:INFO:              mlflow: Not installed
2025-05-15 10:48:50,936:INFO:              gradio: Not installed
2025-05-15 10:48:50,936:INFO:             fastapi: Not installed
2025-05-15 10:48:50,936:INFO:             uvicorn: Not installed
2025-05-15 10:48:50,936:INFO:              m2cgen: Not installed
2025-05-15 10:48:50,938:INFO:           evidently: Not installed
2025-05-15 10:48:50,938:INFO:               fugue: Not installed
2025-05-15 10:48:50,938:INFO:           streamlit: 1.45.0
2025-05-15 10:48:50,938:INFO:             prophet: Not installed
2025-05-15 10:48:50,938:INFO:None
2025-05-15 10:48:50,938:INFO:Set up data.
2025-05-15 10:59:44,146:INFO:PyCaret RegressionExperiment
2025-05-15 10:59:44,241:INFO:Logging name: reg-default-name
2025-05-15 10:59:44,241:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-15 10:59:44,241:INFO:version 3.3.2
2025-05-15 10:59:44,242:INFO:Initializing setup()
2025-05-15 10:59:44,242:INFO:self.USI: dbf5
2025-05-15 10:59:44,242:INFO:self._variable_keys: {'pipeline', 'fold_generator', 'exp_name_log', 'y_test', 'X_test', 'n_jobs_param', 'transform_target_param', 'y', 'memory', 'USI', 'html_param', 'seed', 'X_train', 'y_train', 'gpu_n_jobs_param', 'fold_groups_param', 'exp_id', 'idx', '_ml_usecase', 'gpu_param', 'fold_shuffle_param', '_available_plots', 'logging_param', 'log_plots_param', 'X', 'target_param', 'data'}
2025-05-15 10:59:44,242:INFO:Checking environment
2025-05-15 10:59:44,242:INFO:python_version: 3.11.7
2025-05-15 10:59:44,242:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2025-05-15 10:59:44,243:INFO:machine: AMD64
2025-05-15 10:59:44,243:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-15 10:59:44,246:INFO:Memory: svmem(total=34281660416, available=21241839616, percent=38.0, used=13039820800, free=21241839616)
2025-05-15 10:59:44,247:INFO:Physical Core: 8
2025-05-15 10:59:44,247:INFO:Logical Core: 16
2025-05-15 10:59:44,247:INFO:Checking libraries
2025-05-15 10:59:44,247:INFO:System:
2025-05-15 10:59:44,247:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2025-05-15 10:59:44,247:INFO:executable: c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Scripts\python.exe
2025-05-15 10:59:44,248:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-15 10:59:44,248:INFO:PyCaret required dependencies:
2025-05-15 10:59:44,248:INFO:                 pip: 25.1.1
2025-05-15 10:59:44,248:INFO:          setuptools: 65.5.0
2025-05-15 10:59:44,248:INFO:             pycaret: 3.3.2
2025-05-15 10:59:44,248:INFO:             IPython: 9.2.0
2025-05-15 10:59:44,249:INFO:          ipywidgets: 8.1.7
2025-05-15 10:59:44,249:INFO:                tqdm: 4.67.1
2025-05-15 10:59:44,249:INFO:               numpy: 1.26.4
2025-05-15 10:59:44,249:INFO:              pandas: 2.1.4
2025-05-15 10:59:44,249:INFO:              jinja2: 3.1.6
2025-05-15 10:59:44,249:INFO:               scipy: 1.11.4
2025-05-15 10:59:44,249:INFO:              joblib: 1.3.2
2025-05-15 10:59:44,250:INFO:             sklearn: 1.4.2
2025-05-15 10:59:44,250:INFO:                pyod: 2.0.5
2025-05-15 10:59:44,250:INFO:            imblearn: 0.13.0
2025-05-15 10:59:44,250:INFO:   category_encoders: 2.7.0
2025-05-15 10:59:44,250:INFO:            lightgbm: 4.6.0
2025-05-15 10:59:44,250:INFO:               numba: 0.61.2
2025-05-15 10:59:44,250:INFO:            requests: 2.32.3
2025-05-15 10:59:44,251:INFO:          matplotlib: 3.7.5
2025-05-15 10:59:44,251:INFO:          scikitplot: 0.3.7
2025-05-15 10:59:44,251:INFO:         yellowbrick: 1.5
2025-05-15 10:59:44,251:INFO:              plotly: 5.24.1
2025-05-15 10:59:44,251:INFO:    plotly-resampler: Not installed
2025-05-15 10:59:44,251:INFO:             kaleido: 0.2.1
2025-05-15 10:59:44,252:INFO:           schemdraw: 0.15
2025-05-15 10:59:44,252:INFO:         statsmodels: 0.14.4
2025-05-15 10:59:44,252:INFO:              sktime: 0.26.0
2025-05-15 10:59:44,252:INFO:               tbats: 1.1.3
2025-05-15 10:59:44,252:INFO:            pmdarima: 2.0.4
2025-05-15 10:59:44,252:INFO:              psutil: 7.0.0
2025-05-15 10:59:44,253:INFO:          markupsafe: 3.0.2
2025-05-15 10:59:44,253:INFO:             pickle5: Not installed
2025-05-15 10:59:44,253:INFO:         cloudpickle: 3.1.1
2025-05-15 10:59:44,253:INFO:         deprecation: 2.1.0
2025-05-15 10:59:44,253:INFO:              xxhash: 3.5.0
2025-05-15 10:59:44,253:INFO:           wurlitzer: Not installed
2025-05-15 10:59:44,253:INFO:PyCaret optional dependencies:
2025-05-15 10:59:44,254:INFO:                shap: Not installed
2025-05-15 10:59:44,254:INFO:           interpret: Not installed
2025-05-15 10:59:44,254:INFO:                umap: Not installed
2025-05-15 10:59:44,254:INFO:     ydata_profiling: Not installed
2025-05-15 10:59:44,254:INFO:  explainerdashboard: Not installed
2025-05-15 10:59:44,254:INFO:             autoviz: Not installed
2025-05-15 10:59:44,254:INFO:           fairlearn: Not installed
2025-05-15 10:59:44,254:INFO:          deepchecks: Not installed
2025-05-15 10:59:44,255:INFO:             xgboost: Not installed
2025-05-15 10:59:44,255:INFO:            catboost: Not installed
2025-05-15 10:59:44,255:INFO:              kmodes: Not installed
2025-05-15 10:59:44,255:INFO:             mlxtend: Not installed
2025-05-15 10:59:44,256:INFO:       statsforecast: Not installed
2025-05-15 10:59:44,256:INFO:        tune_sklearn: Not installed
2025-05-15 10:59:44,256:INFO:                 ray: Not installed
2025-05-15 10:59:44,256:INFO:            hyperopt: Not installed
2025-05-15 10:59:44,256:INFO:              optuna: Not installed
2025-05-15 10:59:44,256:INFO:               skopt: Not installed
2025-05-15 10:59:44,257:INFO:              mlflow: Not installed
2025-05-15 10:59:44,257:INFO:              gradio: Not installed
2025-05-15 10:59:44,257:INFO:             fastapi: Not installed
2025-05-15 10:59:44,257:INFO:             uvicorn: Not installed
2025-05-15 10:59:44,257:INFO:              m2cgen: Not installed
2025-05-15 10:59:44,258:INFO:           evidently: Not installed
2025-05-15 10:59:44,258:INFO:               fugue: Not installed
2025-05-15 10:59:44,258:INFO:           streamlit: 1.45.0
2025-05-15 10:59:44,258:INFO:             prophet: Not installed
2025-05-15 10:59:44,258:INFO:None
2025-05-15 10:59:44,258:INFO:Set up data.
2025-05-15 10:59:44,317:INFO:Set up folding strategy.
2025-05-15 10:59:44,317:INFO:Set up train/test split.
2025-05-15 10:59:44,339:INFO:Set up index.
2025-05-15 10:59:44,341:INFO:Assigning column types.
2025-05-15 10:59:44,361:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 10:59:44,361:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,364:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,367:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,425:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,454:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,454:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:44,455:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:44,455:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,458:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,462:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,517:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,548:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,549:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:44,549:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:44,549:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-15 10:59:44,552:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,555:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,612:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,642:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,643:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:44,643:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:44,647:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,650:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,705:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,734:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:44,735:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:44,736:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-15 10:59:44,742:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,798:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,828:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,829:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:44,829:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:44,836:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,890:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,923:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 10:59:44,924:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:44,924:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:44,924:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-15 10:59:44,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 10:59:45,015:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 10:59:45,016:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:45,016:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:45,080:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 10:59:45,108:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 10:59:45,109:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:45,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:45,110:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 10:59:45,172:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 10:59:45,201:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:45,201:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:45,264:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 10:59:45,294:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:45,294:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:45,295:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-15 10:59:45,384:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:45,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:45,474:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:45,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:45,476:INFO:Preparing preprocessing pipeline...
2025-05-15 10:59:45,476:INFO:Set up iterative imputation.
2025-05-15 10:59:45,565:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:45,565:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:45,598:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 10:59:45,619:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:45,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 10:59:45,777:INFO:Set up encoding of ordinal features.
2025-05-15 10:59:45,783:INFO:Set up encoding of categorical features.
2025-05-15 10:59:45,784:INFO:Set up column transformation.
2025-05-15 10:59:45,784:INFO:Set up feature normalization.
2025-05-15 11:50:29,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 11:50:29,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 11:50:29,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 11:50:29,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 11:50:35,664:INFO:PyCaret RegressionExperiment
2025-05-15 11:50:35,752:INFO:Logging name: reg-default-name
2025-05-15 11:50:35,752:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-15 11:50:35,752:INFO:version 3.3.2
2025-05-15 11:50:35,752:INFO:Initializing setup()
2025-05-15 11:50:35,752:INFO:self.USI: d511
2025-05-15 11:50:35,752:INFO:self._variable_keys: {'y', 'transform_target_param', 'X_test', 'memory', 'fold_groups_param', 'log_plots_param', 'data', 'gpu_n_jobs_param', 'X_train', '_ml_usecase', 'exp_id', 'pipeline', 'target_param', 'logging_param', 'idx', 'fold_shuffle_param', 'gpu_param', '_available_plots', 'exp_name_log', 'fold_generator', 'y_train', 'X', 'seed', 'html_param', 'USI', 'y_test', 'n_jobs_param'}
2025-05-15 11:50:35,752:INFO:Checking environment
2025-05-15 11:50:35,752:INFO:python_version: 3.11.7
2025-05-15 11:50:35,752:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2025-05-15 11:50:35,752:INFO:machine: AMD64
2025-05-15 11:50:35,752:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-15 11:50:35,767:INFO:Memory: svmem(total=34281660416, available=23170334720, percent=32.4, used=11111325696, free=23170334720)
2025-05-15 11:50:35,767:INFO:Physical Core: 8
2025-05-15 11:50:35,767:INFO:Logical Core: 16
2025-05-15 11:50:35,767:INFO:Checking libraries
2025-05-15 11:50:35,767:INFO:System:
2025-05-15 11:50:35,768:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2025-05-15 11:50:35,768:INFO:executable: c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Scripts\python.exe
2025-05-15 11:50:35,768:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-15 11:50:35,768:INFO:PyCaret required dependencies:
2025-05-15 11:50:35,801:INFO:                 pip: 25.1.1
2025-05-15 11:50:35,817:INFO:          setuptools: 65.5.0
2025-05-15 11:50:35,817:INFO:             pycaret: 3.3.2
2025-05-15 11:50:35,817:INFO:             IPython: 9.2.0
2025-05-15 11:50:35,817:INFO:          ipywidgets: 8.1.7
2025-05-15 11:50:35,818:INFO:                tqdm: 4.67.1
2025-05-15 11:50:35,818:INFO:               numpy: 1.26.4
2025-05-15 11:50:35,818:INFO:              pandas: 2.1.4
2025-05-15 11:50:35,818:INFO:              jinja2: 3.1.6
2025-05-15 11:50:35,818:INFO:               scipy: 1.11.4
2025-05-15 11:50:35,819:INFO:              joblib: 1.3.2
2025-05-15 11:50:35,819:INFO:             sklearn: 1.4.2
2025-05-15 11:50:35,819:INFO:                pyod: 2.0.5
2025-05-15 11:50:35,819:INFO:            imblearn: 0.13.0
2025-05-15 11:50:35,819:INFO:   category_encoders: 2.7.0
2025-05-15 11:50:35,819:INFO:            lightgbm: 4.6.0
2025-05-15 11:50:35,820:INFO:               numba: 0.61.2
2025-05-15 11:50:35,820:INFO:            requests: 2.32.3
2025-05-15 11:50:35,820:INFO:          matplotlib: 3.7.5
2025-05-15 11:50:35,820:INFO:          scikitplot: 0.3.7
2025-05-15 11:50:35,820:INFO:         yellowbrick: 1.5
2025-05-15 11:50:35,820:INFO:              plotly: 5.24.1
2025-05-15 11:50:35,820:INFO:    plotly-resampler: Not installed
2025-05-15 11:50:35,820:INFO:             kaleido: 0.2.1
2025-05-15 11:50:35,820:INFO:           schemdraw: 0.15
2025-05-15 11:50:35,820:INFO:         statsmodels: 0.14.4
2025-05-15 11:50:35,820:INFO:              sktime: 0.26.0
2025-05-15 11:50:35,820:INFO:               tbats: 1.1.3
2025-05-15 11:50:35,820:INFO:            pmdarima: 2.0.4
2025-05-15 11:50:35,820:INFO:              psutil: 7.0.0
2025-05-15 11:50:35,820:INFO:          markupsafe: 3.0.2
2025-05-15 11:50:35,820:INFO:             pickle5: Not installed
2025-05-15 11:50:35,820:INFO:         cloudpickle: 3.1.1
2025-05-15 11:50:35,820:INFO:         deprecation: 2.1.0
2025-05-15 11:50:35,820:INFO:              xxhash: 3.5.0
2025-05-15 11:50:35,820:INFO:           wurlitzer: Not installed
2025-05-15 11:50:35,820:INFO:PyCaret optional dependencies:
2025-05-15 11:50:35,836:INFO:                shap: Not installed
2025-05-15 11:50:35,836:INFO:           interpret: Not installed
2025-05-15 11:50:35,836:INFO:                umap: Not installed
2025-05-15 11:50:35,836:INFO:     ydata_profiling: Not installed
2025-05-15 11:50:35,836:INFO:  explainerdashboard: Not installed
2025-05-15 11:50:35,836:INFO:             autoviz: Not installed
2025-05-15 11:50:35,836:INFO:           fairlearn: Not installed
2025-05-15 11:50:35,836:INFO:          deepchecks: Not installed
2025-05-15 11:50:35,836:INFO:             xgboost: Not installed
2025-05-15 11:50:35,836:INFO:            catboost: Not installed
2025-05-15 11:50:35,836:INFO:              kmodes: Not installed
2025-05-15 11:50:35,836:INFO:             mlxtend: Not installed
2025-05-15 11:50:35,836:INFO:       statsforecast: Not installed
2025-05-15 11:50:35,836:INFO:        tune_sklearn: Not installed
2025-05-15 11:50:35,836:INFO:                 ray: Not installed
2025-05-15 11:50:35,836:INFO:            hyperopt: Not installed
2025-05-15 11:50:35,836:INFO:              optuna: Not installed
2025-05-15 11:50:35,836:INFO:               skopt: Not installed
2025-05-15 11:50:35,836:INFO:              mlflow: Not installed
2025-05-15 11:50:35,836:INFO:              gradio: Not installed
2025-05-15 11:50:35,836:INFO:             fastapi: Not installed
2025-05-15 11:50:35,836:INFO:             uvicorn: Not installed
2025-05-15 11:50:35,836:INFO:              m2cgen: Not installed
2025-05-15 11:50:35,836:INFO:           evidently: Not installed
2025-05-15 11:50:35,836:INFO:               fugue: Not installed
2025-05-15 11:50:35,836:INFO:           streamlit: 1.45.0
2025-05-15 11:50:35,836:INFO:             prophet: Not installed
2025-05-15 11:50:35,836:INFO:None
2025-05-15 11:50:35,836:INFO:Set up data.
2025-05-15 11:50:35,900:INFO:Set up folding strategy.
2025-05-15 11:50:35,901:INFO:Set up train/test split.
2025-05-15 11:50:35,939:INFO:Set up index.
2025-05-15 11:50:35,941:INFO:Assigning column types.
2025-05-15 11:50:35,951:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 11:50:35,951:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-15 11:50:35,951:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-15 11:50:35,951:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,021:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,051:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,051:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,051:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,051:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,051:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,051:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,100:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,133:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,133:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-15 11:50:36,133:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,149:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,200:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,216:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,233:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,233:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,283:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,317:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,317:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,317:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,317:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-15 11:50:36,317:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,385:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,400:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,400:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,419:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,466:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,500:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,500:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,500:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,500:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-15 11:50:36,567:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,600:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,600:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,650:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,683:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,683:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,692:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 11:50:36,750:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,782:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,783:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,836:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 11:50:36,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,867:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,867:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-15 11:50:36,952:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:36,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:37,052:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:37,052:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:37,062:INFO:Preparing preprocessing pipeline...
2025-05-15 11:50:37,062:INFO:Set up iterative imputation.
2025-05-15 11:50:37,151:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:37,152:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:37,183:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 11:50:37,206:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:37,206:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 11:50:37,350:INFO:Set up encoding of ordinal features.
2025-05-15 11:50:37,359:INFO:Set up encoding of categorical features.
2025-05-15 11:50:37,359:INFO:Set up feature normalization.
2025-05-15 12:09:24,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 12:09:24,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 12:09:24,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 12:09:24,192:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 12:09:24,289:INFO:PyCaret RegressionExperiment
2025-05-15 12:09:24,395:INFO:Logging name: reg-default-name
2025-05-15 12:09:24,395:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-15 12:09:24,395:INFO:version 3.3.2
2025-05-15 12:09:24,395:INFO:Initializing setup()
2025-05-15 12:09:24,395:INFO:self.USI: cc7c
2025-05-15 12:09:24,396:INFO:self._variable_keys: {'gpu_param', 'exp_name_log', 'target_param', 'memory', 'log_plots_param', 'seed', 'logging_param', 'fold_generator', 'fold_groups_param', 'y_test', '_available_plots', 'USI', 'y_train', 'X_train', 'pipeline', 'y', 'transform_target_param', 'n_jobs_param', 'fold_shuffle_param', 'gpu_n_jobs_param', 'X', 'html_param', '_ml_usecase', 'data', 'exp_id', 'X_test', 'idx'}
2025-05-15 12:09:24,396:INFO:Checking environment
2025-05-15 12:09:24,396:INFO:python_version: 3.11.7
2025-05-15 12:09:24,396:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2025-05-15 12:09:24,396:INFO:machine: AMD64
2025-05-15 12:09:24,396:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-15 12:09:24,400:INFO:Memory: svmem(total=34281660416, available=22265593856, percent=35.1, used=12016066560, free=22265593856)
2025-05-15 12:09:24,400:INFO:Physical Core: 8
2025-05-15 12:09:24,400:INFO:Logical Core: 16
2025-05-15 12:09:24,400:INFO:Checking libraries
2025-05-15 12:09:24,400:INFO:System:
2025-05-15 12:09:24,401:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2025-05-15 12:09:24,401:INFO:executable: c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Scripts\python.exe
2025-05-15 12:09:24,401:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-15 12:09:24,401:INFO:PyCaret required dependencies:
2025-05-15 12:09:24,422:INFO:                 pip: 25.1.1
2025-05-15 12:09:24,422:INFO:          setuptools: 65.5.0
2025-05-15 12:09:24,422:INFO:             pycaret: 3.3.2
2025-05-15 12:09:24,422:INFO:             IPython: 9.2.0
2025-05-15 12:09:24,422:INFO:          ipywidgets: 8.1.7
2025-05-15 12:09:24,422:INFO:                tqdm: 4.67.1
2025-05-15 12:09:24,423:INFO:               numpy: 1.26.4
2025-05-15 12:09:24,423:INFO:              pandas: 2.1.4
2025-05-15 12:09:24,423:INFO:              jinja2: 3.1.6
2025-05-15 12:09:24,423:INFO:               scipy: 1.11.4
2025-05-15 12:09:24,423:INFO:              joblib: 1.3.2
2025-05-15 12:09:24,423:INFO:             sklearn: 1.4.2
2025-05-15 12:09:24,423:INFO:                pyod: 2.0.5
2025-05-15 12:09:24,424:INFO:            imblearn: 0.13.0
2025-05-15 12:09:24,424:INFO:   category_encoders: 2.7.0
2025-05-15 12:09:24,424:INFO:            lightgbm: 4.6.0
2025-05-15 12:09:24,424:INFO:               numba: 0.61.2
2025-05-15 12:09:24,424:INFO:            requests: 2.32.3
2025-05-15 12:09:24,424:INFO:          matplotlib: 3.7.5
2025-05-15 12:09:24,424:INFO:          scikitplot: 0.3.7
2025-05-15 12:09:24,424:INFO:         yellowbrick: 1.5
2025-05-15 12:09:24,425:INFO:              plotly: 5.24.1
2025-05-15 12:09:24,425:INFO:    plotly-resampler: Not installed
2025-05-15 12:09:24,425:INFO:             kaleido: 0.2.1
2025-05-15 12:09:24,425:INFO:           schemdraw: 0.15
2025-05-15 12:09:24,425:INFO:         statsmodels: 0.14.4
2025-05-15 12:09:24,425:INFO:              sktime: 0.26.0
2025-05-15 12:09:24,426:INFO:               tbats: 1.1.3
2025-05-15 12:09:24,426:INFO:            pmdarima: 2.0.4
2025-05-15 12:09:24,426:INFO:              psutil: 7.0.0
2025-05-15 12:09:24,426:INFO:          markupsafe: 3.0.2
2025-05-15 12:09:24,426:INFO:             pickle5: Not installed
2025-05-15 12:09:24,426:INFO:         cloudpickle: 3.1.1
2025-05-15 12:09:24,426:INFO:         deprecation: 2.1.0
2025-05-15 12:09:24,427:INFO:              xxhash: 3.5.0
2025-05-15 12:09:24,427:INFO:           wurlitzer: Not installed
2025-05-15 12:09:24,427:INFO:PyCaret optional dependencies:
2025-05-15 12:09:24,442:INFO:                shap: Not installed
2025-05-15 12:09:24,443:INFO:           interpret: Not installed
2025-05-15 12:09:24,443:INFO:                umap: Not installed
2025-05-15 12:09:24,443:INFO:     ydata_profiling: Not installed
2025-05-15 12:09:24,443:INFO:  explainerdashboard: Not installed
2025-05-15 12:09:24,443:INFO:             autoviz: Not installed
2025-05-15 12:09:24,443:INFO:           fairlearn: Not installed
2025-05-15 12:09:24,443:INFO:          deepchecks: Not installed
2025-05-15 12:09:24,444:INFO:             xgboost: Not installed
2025-05-15 12:09:24,444:INFO:            catboost: Not installed
2025-05-15 12:09:24,444:INFO:              kmodes: Not installed
2025-05-15 12:09:24,444:INFO:             mlxtend: Not installed
2025-05-15 12:09:24,444:INFO:       statsforecast: Not installed
2025-05-15 12:09:24,444:INFO:        tune_sklearn: Not installed
2025-05-15 12:09:24,445:INFO:                 ray: Not installed
2025-05-15 12:09:24,445:INFO:            hyperopt: Not installed
2025-05-15 12:09:24,445:INFO:              optuna: Not installed
2025-05-15 12:09:24,445:INFO:               skopt: Not installed
2025-05-15 12:09:24,445:INFO:              mlflow: Not installed
2025-05-15 12:09:24,445:INFO:              gradio: Not installed
2025-05-15 12:09:24,445:INFO:             fastapi: Not installed
2025-05-15 12:09:24,445:INFO:             uvicorn: Not installed
2025-05-15 12:09:24,446:INFO:              m2cgen: Not installed
2025-05-15 12:09:24,446:INFO:           evidently: Not installed
2025-05-15 12:09:24,446:INFO:               fugue: Not installed
2025-05-15 12:09:24,446:INFO:           streamlit: 1.45.0
2025-05-15 12:09:24,446:INFO:             prophet: Not installed
2025-05-15 12:09:24,446:INFO:None
2025-05-15 12:09:24,446:INFO:Set up data.
2025-05-15 12:09:24,505:INFO:Set up folding strategy.
2025-05-15 12:09:24,505:INFO:Set up train/test split.
2025-05-15 12:09:24,525:INFO:Set up index.
2025-05-15 12:09:24,527:INFO:Assigning column types.
2025-05-15 12:09:24,546:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 12:09:24,546:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-15 12:09:24,550:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-15 12:09:24,554:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 12:09:24,610:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 12:09:24,640:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:09:24,640:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:24,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:24,641:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-15 12:09:24,644:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-15 12:09:24,647:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 12:09:24,701:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 12:09:24,732:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:09:24,732:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:24,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:24,733:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-15 12:09:24,737:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-15 12:09:24,740:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 12:09:24,794:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 12:09:24,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:09:24,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:24,825:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:24,828:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-15 12:09:24,832:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 12:09:24,887:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 12:09:24,916:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:09:24,916:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:24,917:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:24,917:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-15 12:09:24,924:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 12:09:24,978:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 12:09:25,008:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:09:25,009:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:25,009:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:25,016:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 12:09:25,070:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 12:09:25,099:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:09:25,100:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:25,100:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:25,100:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-15 12:09:25,162:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 12:09:25,192:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:09:25,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:25,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:25,253:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 12:09:25,283:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:09:25,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:25,284:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:25,284:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 12:09:25,346:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 12:09:25,374:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:25,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:25,436:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 12:09:25,466:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:25,466:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:25,467:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-15 12:09:25,558:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:25,558:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:25,647:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:25,648:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:25,650:INFO:Preparing preprocessing pipeline...
2025-05-15 12:09:25,650:INFO:Set up iterative imputation.
2025-05-15 12:09:25,739:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:25,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:25,771:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 12:09:25,795:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:25,795:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:09:25,950:INFO:Set up encoding of ordinal features.
2025-05-15 12:09:25,956:INFO:Set up encoding of categorical features.
2025-05-15 12:09:25,957:INFO:Set up column transformation.
2025-05-15 12:09:25,957:INFO:Set up feature normalization.
2025-05-15 12:10:33,525:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 12:10:33,526:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 12:10:33,527:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 12:10:33,527:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 12:10:33,625:INFO:PyCaret RegressionExperiment
2025-05-15 12:10:33,735:INFO:Logging name: reg-default-name
2025-05-15 12:10:33,735:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-15 12:10:33,735:INFO:version 3.3.2
2025-05-15 12:10:33,736:INFO:Initializing setup()
2025-05-15 12:10:33,736:INFO:self.USI: 7c50
2025-05-15 12:10:33,736:INFO:self._variable_keys: {'fold_shuffle_param', 'y_train', 'y', 'fold_groups_param', '_ml_usecase', 'transform_target_param', 'logging_param', 'log_plots_param', 'gpu_n_jobs_param', 'X', 'X_test', 'X_train', 'target_param', 'USI', 'pipeline', 'seed', 'gpu_param', 'y_test', 'memory', 'exp_id', '_available_plots', 'n_jobs_param', 'html_param', 'idx', 'exp_name_log', 'fold_generator', 'data'}
2025-05-15 12:10:33,736:INFO:Checking environment
2025-05-15 12:10:33,736:INFO:python_version: 3.11.7
2025-05-15 12:10:33,736:INFO:python_build: ('tags/v3.11.7:fa7a6f2', 'Dec  4 2023 19:24:49')
2025-05-15 12:10:33,737:INFO:machine: AMD64
2025-05-15 12:10:33,737:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-15 12:10:33,741:INFO:Memory: svmem(total=34281660416, available=22214057984, percent=35.2, used=12067602432, free=22214057984)
2025-05-15 12:10:33,741:INFO:Physical Core: 8
2025-05-15 12:10:33,741:INFO:Logical Core: 16
2025-05-15 12:10:33,742:INFO:Checking libraries
2025-05-15 12:10:33,742:INFO:System:
2025-05-15 12:10:33,742:INFO:    python: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]
2025-05-15 12:10:33,742:INFO:executable: c:\TechProject_venv\ImmoEliza_venv\machinelearning_venv\Scripts\python.exe
2025-05-15 12:10:33,742:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-15 12:10:33,742:INFO:PyCaret required dependencies:
2025-05-15 12:10:33,763:INFO:                 pip: 25.1.1
2025-05-15 12:10:33,764:INFO:          setuptools: 65.5.0
2025-05-15 12:10:33,764:INFO:             pycaret: 3.3.2
2025-05-15 12:10:33,764:INFO:             IPython: 9.2.0
2025-05-15 12:10:33,764:INFO:          ipywidgets: 8.1.7
2025-05-15 12:10:33,764:INFO:                tqdm: 4.67.1
2025-05-15 12:10:33,765:INFO:               numpy: 1.26.4
2025-05-15 12:10:33,765:INFO:              pandas: 2.1.4
2025-05-15 12:10:33,765:INFO:              jinja2: 3.1.6
2025-05-15 12:10:33,765:INFO:               scipy: 1.11.4
2025-05-15 12:10:33,765:INFO:              joblib: 1.3.2
2025-05-15 12:10:33,766:INFO:             sklearn: 1.4.2
2025-05-15 12:10:33,766:INFO:                pyod: 2.0.5
2025-05-15 12:10:33,766:INFO:            imblearn: 0.13.0
2025-05-15 12:10:33,766:INFO:   category_encoders: 2.7.0
2025-05-15 12:10:33,766:INFO:            lightgbm: 4.6.0
2025-05-15 12:10:33,767:INFO:               numba: 0.61.2
2025-05-15 12:10:33,767:INFO:            requests: 2.32.3
2025-05-15 12:10:33,767:INFO:          matplotlib: 3.7.5
2025-05-15 12:10:33,767:INFO:          scikitplot: 0.3.7
2025-05-15 12:10:33,767:INFO:         yellowbrick: 1.5
2025-05-15 12:10:33,767:INFO:              plotly: 5.24.1
2025-05-15 12:10:33,767:INFO:    plotly-resampler: Not installed
2025-05-15 12:10:33,767:INFO:             kaleido: 0.2.1
2025-05-15 12:10:33,769:INFO:           schemdraw: 0.15
2025-05-15 12:10:33,769:INFO:         statsmodels: 0.14.4
2025-05-15 12:10:33,769:INFO:              sktime: 0.26.0
2025-05-15 12:10:33,769:INFO:               tbats: 1.1.3
2025-05-15 12:10:33,769:INFO:            pmdarima: 2.0.4
2025-05-15 12:10:33,769:INFO:              psutil: 7.0.0
2025-05-15 12:10:33,769:INFO:          markupsafe: 3.0.2
2025-05-15 12:10:33,769:INFO:             pickle5: Not installed
2025-05-15 12:10:33,769:INFO:         cloudpickle: 3.1.1
2025-05-15 12:10:33,769:INFO:         deprecation: 2.1.0
2025-05-15 12:10:33,770:INFO:              xxhash: 3.5.0
2025-05-15 12:10:33,770:INFO:           wurlitzer: Not installed
2025-05-15 12:10:33,770:INFO:PyCaret optional dependencies:
2025-05-15 12:10:33,788:INFO:                shap: Not installed
2025-05-15 12:10:33,788:INFO:           interpret: Not installed
2025-05-15 12:10:33,788:INFO:                umap: Not installed
2025-05-15 12:10:33,788:INFO:     ydata_profiling: Not installed
2025-05-15 12:10:33,788:INFO:  explainerdashboard: Not installed
2025-05-15 12:10:33,788:INFO:             autoviz: Not installed
2025-05-15 12:10:33,788:INFO:           fairlearn: Not installed
2025-05-15 12:10:33,789:INFO:          deepchecks: Not installed
2025-05-15 12:10:33,789:INFO:             xgboost: Not installed
2025-05-15 12:10:33,789:INFO:            catboost: Not installed
2025-05-15 12:10:33,789:INFO:              kmodes: Not installed
2025-05-15 12:10:33,789:INFO:             mlxtend: Not installed
2025-05-15 12:10:33,789:INFO:       statsforecast: Not installed
2025-05-15 12:10:33,789:INFO:        tune_sklearn: Not installed
2025-05-15 12:10:33,789:INFO:                 ray: Not installed
2025-05-15 12:10:33,789:INFO:            hyperopt: Not installed
2025-05-15 12:10:33,789:INFO:              optuna: Not installed
2025-05-15 12:10:33,789:INFO:               skopt: Not installed
2025-05-15 12:10:33,791:INFO:              mlflow: Not installed
2025-05-15 12:10:33,791:INFO:              gradio: Not installed
2025-05-15 12:10:33,791:INFO:             fastapi: Not installed
2025-05-15 12:10:33,791:INFO:             uvicorn: Not installed
2025-05-15 12:10:33,791:INFO:              m2cgen: Not installed
2025-05-15 12:10:33,791:INFO:           evidently: Not installed
2025-05-15 12:10:33,792:INFO:               fugue: Not installed
2025-05-15 12:10:33,792:INFO:           streamlit: 1.45.0
2025-05-15 12:10:33,792:INFO:             prophet: Not installed
2025-05-15 12:10:33,792:INFO:None
2025-05-15 12:10:33,792:INFO:Set up data.
2025-05-15 12:10:33,848:INFO:Set up folding strategy.
2025-05-15 12:10:33,849:INFO:Set up train/test split.
2025-05-15 12:10:33,871:INFO:Set up index.
2025-05-15 12:10:33,873:INFO:Assigning column types.
2025-05-15 12:10:33,891:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-15 12:10:33,892:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-15 12:10:33,895:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-15 12:10:33,898:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 12:10:33,954:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 12:10:33,983:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:10:33,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:33,984:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:33,984:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-15 12:10:33,987:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-15 12:10:33,990:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,046:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,075:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,076:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,076:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,077:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-15 12:10:34,079:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,083:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,137:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,168:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,168:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,169:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,172:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,175:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,232:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,264:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,265:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,266:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-15 12:10:34,272:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,326:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,356:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,356:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,356:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,363:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,417:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,447:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,447:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,447:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-15 12:10:34,508:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,538:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,539:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,539:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,599:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,631:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,631:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,632:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-15 12:10:34,691:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,723:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,783:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-15 12:10:34,813:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,813:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,813:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-15 12:10:34,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,997:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,997:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:34,999:INFO:Preparing preprocessing pipeline...
2025-05-15 12:10:34,999:INFO:Set up iterative imputation.
2025-05-15 12:10:35,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:35,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:35,124:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-15 12:10:35,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:35,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-15 12:10:35,310:INFO:Set up encoding of ordinal features.
2025-05-15 12:10:35,316:INFO:Set up encoding of categorical features.
2025-05-15 12:10:35,317:INFO:Set up column transformation.
2025-05-15 12:10:35,317:INFO:Set up feature normalization.
